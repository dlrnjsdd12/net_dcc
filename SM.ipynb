{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본라이브러리 import\n",
    "#from google.colab import drive\n",
    "#import os, json, pickle\n",
    "#import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# 파이토치 라이브러리 import\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "\n",
    "#Keras Import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import ipaddress\n",
    "\n",
    "# 구글 드라이브 mount\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# 데이터 파일 위치\n",
    "#C:\\Users\\mariu\\내 드라이브\\Colab Notebooks\\Network\n",
    "# colab_path = 'C:/Documents/VM/disk/notebook/'\n",
    "# colab_write_path = \"C:/Users/mariu/Downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e83f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"NF-UQ-NIDS-total.csv\",index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b7ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장판에서 사용\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'DNS_QUERY_ID','Label','Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR_1','IPV4_SRC_ADDR_2','Label','Attack','Dataset', 'Label_1','Attack_1','Dataset_1', 'Label_2','Attack_2','Dataset_2'])  #명목형변수, 레이블 변수 제외\n",
    "cols = df.columns.drop(['Label','Attack'])  #명목형변수, 레이블 변수 제외#cols = df.columns.drop(['Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "X = df[cols]\n",
    "dummies = pd.get_dummies(df['Attack']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "Y = dummies.values\n",
    "\n",
    "#==================\n",
    "dummiesLabel = pd.get_dummies(df['Label']) # Classification\n",
    "y_1_label = df['Label'].values\n",
    "y_label = dummiesLabel.values\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "def extend_sparse(val):\n",
    "    if val in ['Analysis', 'Exploits', 'Fuzzers', 'Shellcode', 'Theft', 'Worms', 'mitm']: return 1\n",
    "    return 0\n",
    "\n",
    "y_1_attack = pd.DataFrame(df['Attack'])\n",
    "\n",
    "is_sparse = y_1_attack.applymap(extend_sparse)\n",
    "y_1_enforce = is_sparse.values\n",
    "y_enforce = pd.get_dummies(is_sparse['Attack']) # Classification\n",
    "\n",
    "#=======================\n",
    "\n",
    "def max_8G(val):\n",
    "    if (val > 1.0e+9): return 1.0e+9\n",
    "    return val\n",
    "\n",
    "#cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT']\n",
    "cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "'DST_TO_SRC_SECOND_BYTES_1', 'SRC_TO_DST_SECOND_BYTES_1', 'SRC_TO_DST_AVG_THROUGHPUT_1', 'DST_TO_SRC_AVG_THROUGHPUT_1',\n",
    "'DST_TO_SRC_SECOND_BYTES_2', 'SRC_TO_DST_SECOND_BYTES_2', 'SRC_TO_DST_AVG_THROUGHPUT_2', 'DST_TO_SRC_AVG_THROUGHPUT_2'] \n",
    "\n",
    "X[cols] = X[cols].applymap(max_8G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10b15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#scaler_train_minmax = preprocessing.MinMaxScaler()\n",
    "\n",
    "scaler_train = preprocessing.StandardScaler()\n",
    "#scaler_train = preprocessing.MinMaxScaler()\n",
    "scaler_train = scaler_train.fit(X)\n",
    "X = pd.DataFrame(scaler_train.transform(X),index=np.arange(0,X.shape[0],1), columns = X.columns)\n",
    "#X = scaler_train.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02392c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_3sigma(val):\n",
    "    if (val < -3): return -3\n",
    "    if (val > 3): return 3\n",
    "    return val\n",
    "\n",
    "X = X.applymap(max_3sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3b5401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 23:29:45.527695: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.argmax(dummies, axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train_label, x_test_label, y_train_label, y_test_label = train_test_split(X, y_label, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train_enforce, x_test_enforce, y_train_enforce, y_test_enforce = train_test_split(X, y_enforce, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(X, y1.numpy(), test_size=0.20, shuffle = True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3e058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_1 = tf.keras.Sequential([\\n  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation=\\'relu\\'),\\n  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation=\\'softmax\\')\\n  ])\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1\n",
    "#initializer = \"glorot_uniform\"\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu',name='dense_1a'),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1b'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1c'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1d'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "  ])\n",
    "'''\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation='softmax')\n",
    "  ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36cf6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20231009232948\n",
      "Epoch 1/100\n",
      "852/852 - 5s - loss: 0.2976 - accuracy: 0.9120 - val_loss: 0.1299 - val_accuracy: 0.9641 - 5s/epoch - 5ms/step\n",
      "Epoch 2/100\n",
      "852/852 - 4s - loss: 0.1294 - accuracy: 0.9653 - val_loss: 0.1030 - val_accuracy: 0.9719 - 4s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "852/852 - 4s - loss: 0.1103 - accuracy: 0.9706 - val_loss: 0.0949 - val_accuracy: 0.9750 - 4s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "852/852 - 4s - loss: 0.1008 - accuracy: 0.9731 - val_loss: 0.0884 - val_accuracy: 0.9768 - 4s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "852/852 - 4s - loss: 0.0954 - accuracy: 0.9748 - val_loss: 0.0845 - val_accuracy: 0.9774 - 4s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "852/852 - 4s - loss: 0.0908 - accuracy: 0.9760 - val_loss: 0.0811 - val_accuracy: 0.9786 - 4s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "852/852 - 4s - loss: 0.0880 - accuracy: 0.9767 - val_loss: 0.0804 - val_accuracy: 0.9788 - 4s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "852/852 - 4s - loss: 0.0850 - accuracy: 0.9772 - val_loss: 0.0802 - val_accuracy: 0.9789 - 4s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "852/852 - 4s - loss: 0.0831 - accuracy: 0.9778 - val_loss: 0.0761 - val_accuracy: 0.9797 - 4s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "852/852 - 4s - loss: 0.0817 - accuracy: 0.9781 - val_loss: 0.0755 - val_accuracy: 0.9797 - 4s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "852/852 - 4s - loss: 0.0804 - accuracy: 0.9784 - val_loss: 0.0759 - val_accuracy: 0.9795 - 4s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "852/852 - 4s - loss: 0.0792 - accuracy: 0.9789 - val_loss: 0.0746 - val_accuracy: 0.9801 - 4s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "852/852 - 4s - loss: 0.0783 - accuracy: 0.9790 - val_loss: 0.0754 - val_accuracy: 0.9802 - 4s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "852/852 - 4s - loss: 0.0772 - accuracy: 0.9793 - val_loss: 0.0723 - val_accuracy: 0.9806 - 4s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "852/852 - 4s - loss: 0.0765 - accuracy: 0.9795 - val_loss: 0.0715 - val_accuracy: 0.9810 - 4s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "852/852 - 4s - loss: 0.0759 - accuracy: 0.9795 - val_loss: 0.0716 - val_accuracy: 0.9806 - 4s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "852/852 - 4s - loss: 0.0748 - accuracy: 0.9797 - val_loss: 0.0723 - val_accuracy: 0.9811 - 4s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "852/852 - 4s - loss: 0.0744 - accuracy: 0.9798 - val_loss: 0.0705 - val_accuracy: 0.9811 - 4s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "852/852 - 4s - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.0704 - val_accuracy: 0.9812 - 4s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "852/852 - 4s - loss: 0.0731 - accuracy: 0.9802 - val_loss: 0.0689 - val_accuracy: 0.9813 - 4s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "852/852 - 4s - loss: 0.0728 - accuracy: 0.9802 - val_loss: 0.0716 - val_accuracy: 0.9803 - 4s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "852/852 - 4s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0690 - val_accuracy: 0.9814 - 4s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "852/852 - 4s - loss: 0.0718 - accuracy: 0.9806 - val_loss: 0.0689 - val_accuracy: 0.9814 - 4s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "852/852 - 4s - loss: 0.0714 - accuracy: 0.9806 - val_loss: 0.0687 - val_accuracy: 0.9815 - 4s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "852/852 - 4s - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.0675 - val_accuracy: 0.9818 - 4s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "852/852 - 4s - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.0678 - val_accuracy: 0.9815 - 4s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "852/852 - 4s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0676 - val_accuracy: 0.9818 - 4s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "852/852 - 4s - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0672 - val_accuracy: 0.9820 - 4s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "852/852 - 4s - loss: 0.0698 - accuracy: 0.9808 - val_loss: 0.0667 - val_accuracy: 0.9821 - 4s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "852/852 - 4s - loss: 0.0694 - accuracy: 0.9811 - val_loss: 0.0667 - val_accuracy: 0.9818 - 4s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "852/852 - 4s - loss: 0.0691 - accuracy: 0.9812 - val_loss: 0.0668 - val_accuracy: 0.9820 - 4s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "852/852 - 4s - loss: 0.0688 - accuracy: 0.9813 - val_loss: 0.0660 - val_accuracy: 0.9820 - 4s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "852/852 - 4s - loss: 0.0686 - accuracy: 0.9813 - val_loss: 0.0663 - val_accuracy: 0.9820 - 4s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "852/852 - 4s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0670 - val_accuracy: 0.9818 - 4s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "852/852 - 4s - loss: 0.0682 - accuracy: 0.9814 - val_loss: 0.0661 - val_accuracy: 0.9823 - 4s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "852/852 - 4s - loss: 0.0679 - accuracy: 0.9816 - val_loss: 0.0663 - val_accuracy: 0.9822 - 4s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "852/852 - 4s - loss: 0.0676 - accuracy: 0.9816 - val_loss: 0.0647 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "852/852 - 4s - loss: 0.0674 - accuracy: 0.9816 - val_loss: 0.0652 - val_accuracy: 0.9823 - 4s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "852/852 - 4s - loss: 0.0676 - accuracy: 0.9816 - val_loss: 0.0657 - val_accuracy: 0.9823 - 4s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "852/852 - 4s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0655 - val_accuracy: 0.9824 - 4s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "852/852 - 4s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0661 - val_accuracy: 0.9822 - 4s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "852/852 - 4s - loss: 0.0669 - accuracy: 0.9818 - val_loss: 0.0656 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "852/852 - 4s - loss: 0.0666 - accuracy: 0.9818 - val_loss: 0.0646 - val_accuracy: 0.9825 - 4s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "852/852 - 4s - loss: 0.0663 - accuracy: 0.9819 - val_loss: 0.0647 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "852/852 - 4s - loss: 0.0662 - accuracy: 0.9819 - val_loss: 0.0645 - val_accuracy: 0.9827 - 4s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "852/852 - 4s - loss: 0.0660 - accuracy: 0.9820 - val_loss: 0.0638 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "852/852 - 4s - loss: 0.0661 - accuracy: 0.9820 - val_loss: 0.0645 - val_accuracy: 0.9828 - 4s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "852/852 - 4s - loss: 0.0658 - accuracy: 0.9820 - val_loss: 0.0658 - val_accuracy: 0.9820 - 4s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "852/852 - 4s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0645 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "852/852 - 4s - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0642 - val_accuracy: 0.9829 - 4s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "852/852 - 4s - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.0647 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "852/852 - 4s - loss: 0.0653 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9827 - 4s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "852/852 - 4s - loss: 0.0656 - accuracy: 0.9821 - val_loss: 0.0642 - val_accuracy: 0.9828 - 4s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "852/852 - 4s - loss: 0.0652 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "852/852 - 4s - loss: 0.0650 - accuracy: 0.9822 - val_loss: 0.0643 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "852/852 - 4s - loss: 0.0647 - accuracy: 0.9823 - val_loss: 0.0637 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "852/852 - 4s - loss: 0.0644 - accuracy: 0.9825 - val_loss: 0.0645 - val_accuracy: 0.9828 - 4s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "852/852 - 4s - loss: 0.0646 - accuracy: 0.9823 - val_loss: 0.0637 - val_accuracy: 0.9829 - 4s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "852/852 - 4s - loss: 0.0646 - accuracy: 0.9823 - val_loss: 0.0654 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "852/852 - 4s - loss: 0.0645 - accuracy: 0.9824 - val_loss: 0.0635 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "852/852 - 4s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0641 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "852/852 - 4s - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.0637 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "852/852 - 4s - loss: 0.0639 - accuracy: 0.9826 - val_loss: 0.0632 - val_accuracy: 0.9831 - 4s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "852/852 - 4s - loss: 0.0641 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9831 - 4s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "852/852 - 4s - loss: 0.0639 - accuracy: 0.9827 - val_loss: 0.0634 - val_accuracy: 0.9832 - 4s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "852/852 - 4s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0629 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "852/852 - 4s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9832 - 4s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "852/852 - 4s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0633 - val_accuracy: 0.9828 - 4s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "852/852 - 4s - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0641 - val_accuracy: 0.9829 - 4s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "852/852 - 4s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0630 - val_accuracy: 0.9831 - 4s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "852/852 - 4s - loss: 0.0639 - accuracy: 0.9826 - val_loss: 0.0623 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "852/852 - 4s - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0623 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "852/852 - 4s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0624 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "852/852 - 4s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0628 - val_accuracy: 0.9831 - 4s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "852/852 - 4s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0633 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "852/852 - 4s - loss: 0.0633 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "852/852 - 4s - loss: 0.0632 - accuracy: 0.9827 - val_loss: 0.0627 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "852/852 - 4s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0621 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "852/852 - 4s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0629 - val_accuracy: 0.9832 - 4s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "852/852 - 4s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0636 - val_accuracy: 0.9826 - 4s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "852/852 - 4s - loss: 0.0626 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "852/852 - 4s - loss: 0.0629 - accuracy: 0.9828 - val_loss: 0.0630 - val_accuracy: 0.9830 - 4s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "852/852 - 4s - loss: 0.0630 - accuracy: 0.9828 - val_loss: 0.0630 - val_accuracy: 0.9831 - 4s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "852/852 - 4s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "852/852 - 4s - loss: 0.0628 - accuracy: 0.9828 - val_loss: 0.0623 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "852/852 - 4s - loss: 0.0624 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "852/852 - 4s - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "852/852 - 4s - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "852/852 - 4s - loss: 0.0624 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "852/852 - 4s - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "852/852 - 4s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0619 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "852/852 - 4s - loss: 0.0624 - accuracy: 0.9830 - val_loss: 0.0618 - val_accuracy: 0.9836 - 4s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "852/852 - 4s - loss: 0.0622 - accuracy: 0.9832 - val_loss: 0.0621 - val_accuracy: 0.9833 - 4s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "852/852 - 4s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "852/852 - 4s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9837 - 4s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "852/852 - 4s - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0618 - val_accuracy: 0.9835 - 4s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "852/852 - 4s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "852/852 - 4s - loss: 0.0622 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "852/852 - 4s - loss: 0.0620 - accuracy: 0.9832 - val_loss: 0.0616 - val_accuracy: 0.9835 - 4s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "852/852 - 4s - loss: 0.0617 - accuracy: 0.9832 - val_loss: 0.0623 - val_accuracy: 0.9834 - 4s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model_1.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_1 = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(log_dir_1)\n",
    "monitor_1 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "#             tf.keras.callbacks.TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "#             tf.keras.callbacks.TensorBoard(histogram_freq=1)\n",
    "            ]\n",
    "history_1  = model_1.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=1024, epochs=100)\n",
    "#history_1  = model_1.fit(x_train,y_train,validation_split=0.2, callbacks=[monitor_1],verbose=2, batch_size=1024, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7dbd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  model 2  with different structure\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=64)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_2a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, activation='relu',name='dense_2b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(256, input_dim=128, kernel_initializer=initializer, activation='relu',name='dense_2c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=256, kernel_initializer=initializer, activation='relu',name='dense_2d'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a9d163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 8s - loss: 0.2040 - accuracy: 0.9397 - val_loss: 0.1090 - val_accuracy: 0.9701 - 8s/epoch - 5ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 7s - loss: 0.1112 - accuracy: 0.9700 - val_loss: 0.0914 - val_accuracy: 0.9750 - 7s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 7s - loss: 0.0984 - accuracy: 0.9735 - val_loss: 0.0859 - val_accuracy: 0.9776 - 7s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 7s - loss: 0.0908 - accuracy: 0.9755 - val_loss: 0.0818 - val_accuracy: 0.9776 - 7s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 7s - loss: 0.0866 - accuracy: 0.9767 - val_loss: 0.0788 - val_accuracy: 0.9790 - 7s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 7s - loss: 0.0833 - accuracy: 0.9775 - val_loss: 0.0762 - val_accuracy: 0.9795 - 7s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 7s - loss: 0.0811 - accuracy: 0.9782 - val_loss: 0.0767 - val_accuracy: 0.9797 - 7s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 7s - loss: 0.0798 - accuracy: 0.9784 - val_loss: 0.0736 - val_accuracy: 0.9803 - 7s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 7s - loss: 0.0783 - accuracy: 0.9788 - val_loss: 0.0734 - val_accuracy: 0.9801 - 7s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 7s - loss: 0.0770 - accuracy: 0.9790 - val_loss: 0.0724 - val_accuracy: 0.9803 - 7s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 7s - loss: 0.0759 - accuracy: 0.9794 - val_loss: 0.0714 - val_accuracy: 0.9804 - 7s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 7s - loss: 0.0752 - accuracy: 0.9795 - val_loss: 0.0715 - val_accuracy: 0.9804 - 7s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 7s - loss: 0.0744 - accuracy: 0.9798 - val_loss: 0.0702 - val_accuracy: 0.9811 - 7s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 7s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0698 - val_accuracy: 0.9810 - 7s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 7s - loss: 0.0732 - accuracy: 0.9801 - val_loss: 0.0699 - val_accuracy: 0.9812 - 7s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 7s - loss: 0.0728 - accuracy: 0.9802 - val_loss: 0.0696 - val_accuracy: 0.9810 - 7s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 7s - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0681 - val_accuracy: 0.9813 - 7s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 7s - loss: 0.0714 - accuracy: 0.9806 - val_loss: 0.0674 - val_accuracy: 0.9815 - 7s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 7s - loss: 0.0710 - accuracy: 0.9806 - val_loss: 0.0678 - val_accuracy: 0.9817 - 7s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 7s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0671 - val_accuracy: 0.9816 - 7s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 7s - loss: 0.0704 - accuracy: 0.9807 - val_loss: 0.0671 - val_accuracy: 0.9817 - 7s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 7s - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.0676 - val_accuracy: 0.9818 - 7s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 7s - loss: 0.0696 - accuracy: 0.9811 - val_loss: 0.0669 - val_accuracy: 0.9820 - 7s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 7s - loss: 0.0693 - accuracy: 0.9810 - val_loss: 0.0664 - val_accuracy: 0.9821 - 7s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 7s - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.0661 - val_accuracy: 0.9821 - 7s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 7s - loss: 0.0688 - accuracy: 0.9814 - val_loss: 0.0659 - val_accuracy: 0.9821 - 7s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 7s - loss: 0.0684 - accuracy: 0.9812 - val_loss: 0.0676 - val_accuracy: 0.9818 - 7s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 7s - loss: 0.0682 - accuracy: 0.9814 - val_loss: 0.0654 - val_accuracy: 0.9823 - 7s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 7s - loss: 0.0677 - accuracy: 0.9815 - val_loss: 0.0658 - val_accuracy: 0.9819 - 7s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 7s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0660 - val_accuracy: 0.9821 - 7s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 7s - loss: 0.0678 - accuracy: 0.9815 - val_loss: 0.0683 - val_accuracy: 0.9818 - 7s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 7s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0651 - val_accuracy: 0.9823 - 7s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 7s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0651 - val_accuracy: 0.9824 - 7s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 7s - loss: 0.0670 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9823 - 7s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 7s - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0651 - val_accuracy: 0.9827 - 7s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 7s - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.0674 - val_accuracy: 0.9817 - 7s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 7s - loss: 0.0665 - accuracy: 0.9817 - val_loss: 0.0653 - val_accuracy: 0.9822 - 7s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 7s - loss: 0.0662 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9822 - 7s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 7s - loss: 0.0663 - accuracy: 0.9819 - val_loss: 0.0656 - val_accuracy: 0.9822 - 7s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 7s - loss: 0.0659 - accuracy: 0.9820 - val_loss: 0.0640 - val_accuracy: 0.9826 - 7s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 7s - loss: 0.0663 - accuracy: 0.9821 - val_loss: 0.0656 - val_accuracy: 0.9822 - 7s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 7s - loss: 0.0661 - accuracy: 0.9820 - val_loss: 0.0642 - val_accuracy: 0.9826 - 7s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 7s - loss: 0.0656 - accuracy: 0.9823 - val_loss: 0.0658 - val_accuracy: 0.9818 - 7s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 7s - loss: 0.0658 - accuracy: 0.9820 - val_loss: 0.0634 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 7s - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0632 - val_accuracy: 0.9827 - 7s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 7s - loss: 0.0654 - accuracy: 0.9822 - val_loss: 0.0639 - val_accuracy: 0.9828 - 7s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 7s - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.0641 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 7s - loss: 0.0655 - accuracy: 0.9823 - val_loss: 0.0627 - val_accuracy: 0.9832 - 7s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 7s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0636 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 7s - loss: 0.0652 - accuracy: 0.9824 - val_loss: 0.0643 - val_accuracy: 0.9826 - 7s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 7s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0635 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 7s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0639 - val_accuracy: 0.9830 - 7s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 7s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0635 - val_accuracy: 0.9828 - 7s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 7s - loss: 0.0645 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 7s - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.0626 - val_accuracy: 0.9831 - 7s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 7s - loss: 0.0645 - accuracy: 0.9826 - val_loss: 0.0631 - val_accuracy: 0.9831 - 7s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 7s - loss: 0.0642 - accuracy: 0.9826 - val_loss: 0.0649 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 7s - loss: 0.0643 - accuracy: 0.9825 - val_loss: 0.0637 - val_accuracy: 0.9831 - 7s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 7s - loss: 0.0641 - accuracy: 0.9825 - val_loss: 0.0635 - val_accuracy: 0.9830 - 7s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 7s - loss: 0.0641 - accuracy: 0.9825 - val_loss: 0.0640 - val_accuracy: 0.9831 - 7s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 7s - loss: 0.0641 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9830 - 7s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 7s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0622 - val_accuracy: 0.9832 - 7s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 7s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9830 - 7s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 7s - loss: 0.0641 - accuracy: 0.9825 - val_loss: 0.0628 - val_accuracy: 0.9833 - 7s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 7s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0651 - val_accuracy: 0.9819 - 7s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 7s - loss: 0.0638 - accuracy: 0.9826 - val_loss: 0.0626 - val_accuracy: 0.9833 - 7s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 7s - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0636 - val_accuracy: 0.9829 - 7s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 7s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0649 - val_accuracy: 0.9821 - 7s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 7s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0625 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 7s - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 7s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0635 - val_accuracy: 0.9832 - 7s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 7s - loss: 0.0634 - accuracy: 0.9828 - val_loss: 0.0626 - val_accuracy: 0.9833 - 7s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 7s - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0618 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 7s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9832 - 7s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 7s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0625 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 7s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9832 - 7s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 7s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0626 - val_accuracy: 0.9832 - 7s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 7s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0624 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 7s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 7s - loss: 0.0632 - accuracy: 0.9829 - val_loss: 0.0631 - val_accuracy: 0.9831 - 7s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 7s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0631 - val_accuracy: 0.9830 - 7s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 7s - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0621 - val_accuracy: 0.9836 - 7s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 7s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0621 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 7s - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0622 - val_accuracy: 0.9833 - 7s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 7s - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.0622 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 7s - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0623 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 7s - loss: 0.0626 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 7s - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 7s - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 7s - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0625 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 7s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0616 - val_accuracy: 0.9838 - 7s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 7s - loss: 0.0624 - accuracy: 0.9833 - val_loss: 0.0633 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 7s - loss: 0.0626 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 7s - loss: 0.0622 - accuracy: 0.9832 - val_loss: 0.0624 - val_accuracy: 0.9838 - 7s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 7s - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0619 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 7s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9836 - 7s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 7s - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.0620 - val_accuracy: 0.9835 - 7s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 7s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0622 - val_accuracy: 0.9834 - 7s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 7s - loss: 0.0622 - accuracy: 0.9832 - val_loss: 0.0622 - val_accuracy: 0.9837 - 7s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 7s - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0618 - val_accuracy: 0.9833 - 7s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_2 = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#monitor_2 = [\n",
    "#             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "#             tf.keras.callbacks.TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "#            ]\n",
    "#history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_2],verbose=2, batch_size=512, epochs=100)\n",
    "history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7345bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 rd model for stack\n",
    "model_3 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3a'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(256, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3d'),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1901e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 13s - loss: 0.1724 - accuracy: 0.9497 - val_loss: 0.0970 - val_accuracy: 0.9744 - 13s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 12s - loss: 0.1005 - accuracy: 0.9730 - val_loss: 0.0863 - val_accuracy: 0.9772 - 12s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 12s - loss: 0.0900 - accuracy: 0.9760 - val_loss: 0.0838 - val_accuracy: 0.9771 - 12s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 12s - loss: 0.0853 - accuracy: 0.9772 - val_loss: 0.0790 - val_accuracy: 0.9793 - 12s/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 12s - loss: 0.0817 - accuracy: 0.9781 - val_loss: 0.0758 - val_accuracy: 0.9798 - 12s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 12s - loss: 0.0790 - accuracy: 0.9787 - val_loss: 0.0744 - val_accuracy: 0.9800 - 12s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 12s - loss: 0.0775 - accuracy: 0.9791 - val_loss: 0.0735 - val_accuracy: 0.9805 - 12s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0759 - accuracy: 0.9795 - val_loss: 0.0715 - val_accuracy: 0.9807 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 12s - loss: 0.0748 - accuracy: 0.9797 - val_loss: 0.0716 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 12s - loss: 0.0734 - accuracy: 0.9802 - val_loss: 0.0695 - val_accuracy: 0.9813 - 12s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 12s - loss: 0.0725 - accuracy: 0.9803 - val_loss: 0.0687 - val_accuracy: 0.9813 - 12s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 12s - loss: 0.0713 - accuracy: 0.9805 - val_loss: 0.0689 - val_accuracy: 0.9814 - 12s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 12s - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.0690 - val_accuracy: 0.9812 - 12s/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 12s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0698 - val_accuracy: 0.9814 - 12s/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 12s - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0678 - val_accuracy: 0.9816 - 12s/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 12s - loss: 0.0688 - accuracy: 0.9812 - val_loss: 0.0673 - val_accuracy: 0.9818 - 12s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 12s - loss: 0.0684 - accuracy: 0.9813 - val_loss: 0.0671 - val_accuracy: 0.9818 - 12s/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 12s - loss: 0.0680 - accuracy: 0.9815 - val_loss: 0.0675 - val_accuracy: 0.9816 - 12s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 12s - loss: 0.0676 - accuracy: 0.9815 - val_loss: 0.0678 - val_accuracy: 0.9816 - 12s/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 12s - loss: 0.0669 - accuracy: 0.9817 - val_loss: 0.0674 - val_accuracy: 0.9820 - 12s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.0670 - val_accuracy: 0.9819 - 12s/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 12s - loss: 0.0661 - accuracy: 0.9820 - val_loss: 0.0659 - val_accuracy: 0.9822 - 12s/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 12s - loss: 0.0658 - accuracy: 0.9821 - val_loss: 0.0666 - val_accuracy: 0.9823 - 12s/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 12s - loss: 0.0656 - accuracy: 0.9821 - val_loss: 0.0666 - val_accuracy: 0.9821 - 12s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 12s - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.0649 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 12s - loss: 0.0651 - accuracy: 0.9822 - val_loss: 0.0648 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 12s - loss: 0.0646 - accuracy: 0.9823 - val_loss: 0.0652 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0662 - val_accuracy: 0.9819 - 12s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 12s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0655 - val_accuracy: 0.9823 - 12s/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 12s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0650 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 12s - loss: 0.0636 - accuracy: 0.9827 - val_loss: 0.0642 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 12s - loss: 0.0632 - accuracy: 0.9827 - val_loss: 0.0649 - val_accuracy: 0.9825 - 12s/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 12s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0656 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 12s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0654 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 12s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0646 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 12s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0651 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 12s - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0652 - val_accuracy: 0.9825 - 12s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 12s - loss: 0.0624 - accuracy: 0.9830 - val_loss: 0.0649 - val_accuracy: 0.9823 - 12s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "1704/1704 - 12s - loss: 0.0624 - accuracy: 0.9830 - val_loss: 0.0655 - val_accuracy: 0.9822 - 12s/epoch - 7ms/step\n",
      "Epoch 39: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_3.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_3 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=2, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "history_3  = model_3.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_3],verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e56734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4 rd model for stack\n",
    "# model_4 = tf.keras.Sequential([\n",
    "#       tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4a'),\n",
    "#       tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4b'),\n",
    "#       tf.keras.layers.Dropout(0.3),\n",
    "#       tf.keras.layers.Dense(32, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4c'),\n",
    "#       tf.keras.layers.Dropout(0.2),\n",
    "#       tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4d'),\n",
    "#       tf.keras.layers.Dense(y_train.shape[1],activation='softmax')\n",
    "#       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdeb9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# log_dir_4 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# monitor_4 = [\n",
    "#             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "#             tf.keras.callbacks.TensorBoard(log_dir=log_dir_4, histogram_freq=1)\n",
    "#         ]\n",
    "# history_4  = model_4.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_4],verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa98ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('model1_1.h5')\n",
    "model_2.save('model1_2.h5')\n",
    "model_3.save('model1_3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfab861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fdb293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (871999, 127) (871999, 21)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (1297272, 127) (1297272, 21)\n"
     ]
    }
   ],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_over,y_train_over = smote.fit_resample(x_train,y_train)\n",
    "MININUM_SAMPLES = 30000\n",
    "MAXINUM_SAMPLES = 300000\n",
    "\n",
    "sample_dict = {6: 205290,\n",
    "         2: 288786,\n",
    "         5: 249311,\n",
    "         20: 28278,\n",
    "         19: 43885,\n",
    "         11: 29889,\n",
    "         17: 13051,\n",
    "         3: 1639,\n",
    "         15: 7863,\n",
    "         4: 1436,\n",
    "         10: 1354,\n",
    "         8: 256,\n",
    "         9: 185,\n",
    "         7: 373,\n",
    "         18: 31,\n",
    "         1: 214,\n",
    "         13: 17,\n",
    "         16: 86,\n",
    "         0: 38,\n",
    "         12: 13,\n",
    "         14: 4}\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=33)\n",
    "for i in range(21):\n",
    "    if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "        sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "ros = RandomUnderSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_under, y_train_under = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "for i in range(21):\n",
    "    if sample_dict[i] <  MININUM_SAMPLES:\n",
    "        sample_dict[i] =  MININUM_SAMPLES\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train_under, y_train_under)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d140066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "#6 rd model for stack\n",
    "model_6 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6b'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6d'),\n",
    "      tf.keras.layers.Dense(y_train_over.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dbdfdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2534/2534 - 11s - loss: 0.2983 - accuracy: 0.9011 - val_loss: 0.1333 - val_accuracy: 0.9634 - 11s/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "2534/2534 - 10s - loss: 0.1593 - accuracy: 0.9503 - val_loss: 0.1111 - val_accuracy: 0.9722 - 10s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "2534/2534 - 10s - loss: 0.1382 - accuracy: 0.9571 - val_loss: 0.1108 - val_accuracy: 0.9728 - 10s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "2534/2534 - 10s - loss: 0.1284 - accuracy: 0.9598 - val_loss: 0.1142 - val_accuracy: 0.9702 - 10s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "2534/2534 - 10s - loss: 0.1228 - accuracy: 0.9615 - val_loss: 0.0998 - val_accuracy: 0.9758 - 10s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "2534/2534 - 10s - loss: 0.1187 - accuracy: 0.9627 - val_loss: 0.0997 - val_accuracy: 0.9754 - 10s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "2534/2534 - 10s - loss: 0.1154 - accuracy: 0.9635 - val_loss: 0.1011 - val_accuracy: 0.9756 - 10s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "2534/2534 - 10s - loss: 0.1130 - accuracy: 0.9642 - val_loss: 0.0989 - val_accuracy: 0.9747 - 10s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "2534/2534 - 10s - loss: 0.1107 - accuracy: 0.9649 - val_loss: 0.0954 - val_accuracy: 0.9753 - 10s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "2534/2534 - 10s - loss: 0.1088 - accuracy: 0.9655 - val_loss: 0.0948 - val_accuracy: 0.9759 - 10s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "2534/2534 - 10s - loss: 0.1072 - accuracy: 0.9659 - val_loss: 0.1004 - val_accuracy: 0.9733 - 10s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "2534/2534 - 10s - loss: 0.1062 - accuracy: 0.9660 - val_loss: 0.0961 - val_accuracy: 0.9754 - 10s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "2534/2534 - 10s - loss: 0.1046 - accuracy: 0.9665 - val_loss: 0.0933 - val_accuracy: 0.9764 - 10s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "2534/2534 - 10s - loss: 0.1034 - accuracy: 0.9670 - val_loss: 0.0928 - val_accuracy: 0.9756 - 10s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "2534/2534 - 10s - loss: 0.1018 - accuracy: 0.9672 - val_loss: 0.0923 - val_accuracy: 0.9762 - 10s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "2534/2534 - 10s - loss: 0.1014 - accuracy: 0.9675 - val_loss: 0.0859 - val_accuracy: 0.9770 - 10s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "2534/2534 - 10s - loss: 0.1000 - accuracy: 0.9678 - val_loss: 0.0918 - val_accuracy: 0.9766 - 10s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "2534/2534 - 10s - loss: 0.0992 - accuracy: 0.9680 - val_loss: 0.0924 - val_accuracy: 0.9763 - 10s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "2534/2534 - 10s - loss: 0.0982 - accuracy: 0.9682 - val_loss: 0.0906 - val_accuracy: 0.9766 - 10s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "2534/2534 - 10s - loss: 0.0974 - accuracy: 0.9686 - val_loss: 0.0916 - val_accuracy: 0.9758 - 10s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "2534/2534 - 10s - loss: 0.0968 - accuracy: 0.9686 - val_loss: 0.0915 - val_accuracy: 0.9761 - 10s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "2534/2534 - 10s - loss: 0.0961 - accuracy: 0.9689 - val_loss: 0.0895 - val_accuracy: 0.9772 - 10s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "2534/2534 - 10s - loss: 0.0957 - accuracy: 0.9690 - val_loss: 0.0910 - val_accuracy: 0.9764 - 10s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "2534/2534 - 10s - loss: 0.0948 - accuracy: 0.9694 - val_loss: 0.0873 - val_accuracy: 0.9777 - 10s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "2534/2534 - 10s - loss: 0.0938 - accuracy: 0.9696 - val_loss: 0.0924 - val_accuracy: 0.9752 - 10s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "2534/2534 - 10s - loss: 0.0937 - accuracy: 0.9697 - val_loss: 0.0867 - val_accuracy: 0.9776 - 10s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "2534/2534 - 10s - loss: 0.0930 - accuracy: 0.9698 - val_loss: 0.0909 - val_accuracy: 0.9750 - 10s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "2534/2534 - 10s - loss: 0.0926 - accuracy: 0.9700 - val_loss: 0.0864 - val_accuracy: 0.9775 - 10s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "2534/2534 - 10s - loss: 0.0914 - accuracy: 0.9703 - val_loss: 0.0854 - val_accuracy: 0.9775 - 10s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "2534/2534 - 10s - loss: 0.0913 - accuracy: 0.9702 - val_loss: 0.0837 - val_accuracy: 0.9775 - 10s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "2534/2534 - 10s - loss: 0.0907 - accuracy: 0.9705 - val_loss: 0.0842 - val_accuracy: 0.9778 - 10s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "2534/2534 - 10s - loss: 0.0906 - accuracy: 0.9705 - val_loss: 0.0880 - val_accuracy: 0.9774 - 10s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "2534/2534 - 10s - loss: 0.0902 - accuracy: 0.9706 - val_loss: 0.0850 - val_accuracy: 0.9775 - 10s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "2534/2534 - 10s - loss: 0.0893 - accuracy: 0.9707 - val_loss: 0.0825 - val_accuracy: 0.9779 - 10s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "2534/2534 - 10s - loss: 0.0892 - accuracy: 0.9708 - val_loss: 0.0872 - val_accuracy: 0.9777 - 10s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "2534/2534 - 10s - loss: 0.0890 - accuracy: 0.9709 - val_loss: 0.0868 - val_accuracy: 0.9766 - 10s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "2534/2534 - 10s - loss: 0.0882 - accuracy: 0.9711 - val_loss: 0.0841 - val_accuracy: 0.9782 - 10s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "2534/2534 - 10s - loss: 0.0882 - accuracy: 0.9711 - val_loss: 0.0903 - val_accuracy: 0.9752 - 10s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "2534/2534 - 11s - loss: 0.0880 - accuracy: 0.9713 - val_loss: 0.0814 - val_accuracy: 0.9785 - 11s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "2534/2534 - 10s - loss: 0.0873 - accuracy: 0.9715 - val_loss: 0.0850 - val_accuracy: 0.9776 - 10s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "2534/2534 - 9s - loss: 0.0867 - accuracy: 0.9716 - val_loss: 0.0839 - val_accuracy: 0.9781 - 9s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "2534/2534 - 10s - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.0870 - val_accuracy: 0.9763 - 10s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "2534/2534 - 10s - loss: 0.0863 - accuracy: 0.9718 - val_loss: 0.0850 - val_accuracy: 0.9777 - 10s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "2534/2534 - 10s - loss: 0.0863 - accuracy: 0.9718 - val_loss: 0.0849 - val_accuracy: 0.9770 - 10s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "2534/2534 - 10s - loss: 0.0861 - accuracy: 0.9719 - val_loss: 0.0834 - val_accuracy: 0.9784 - 10s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "2534/2534 - 10s - loss: 0.0855 - accuracy: 0.9721 - val_loss: 0.0835 - val_accuracy: 0.9783 - 10s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "2534/2534 - 10s - loss: 0.0851 - accuracy: 0.9719 - val_loss: 0.0833 - val_accuracy: 0.9779 - 10s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "2534/2534 - 10s - loss: 0.0853 - accuracy: 0.9721 - val_loss: 0.0858 - val_accuracy: 0.9770 - 10s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "2534/2534 - 10s - loss: 0.0847 - accuracy: 0.9723 - val_loss: 0.0817 - val_accuracy: 0.9784 - 10s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "2534/2534 - 10s - loss: 0.0848 - accuracy: 0.9721 - val_loss: 0.0851 - val_accuracy: 0.9769 - 10s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "2534/2534 - 10s - loss: 0.0839 - accuracy: 0.9724 - val_loss: 0.0852 - val_accuracy: 0.9781 - 10s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "2534/2534 - 10s - loss: 0.0840 - accuracy: 0.9726 - val_loss: 0.0828 - val_accuracy: 0.9787 - 10s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "2534/2534 - 10s - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.0834 - val_accuracy: 0.9778 - 10s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "2534/2534 - 10s - loss: 0.0836 - accuracy: 0.9725 - val_loss: 0.0854 - val_accuracy: 0.9767 - 10s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "2534/2534 - 10s - loss: 0.0832 - accuracy: 0.9727 - val_loss: 0.0810 - val_accuracy: 0.9791 - 10s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "2534/2534 - 10s - loss: 0.0832 - accuracy: 0.9727 - val_loss: 0.0844 - val_accuracy: 0.9776 - 10s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "2534/2534 - 11s - loss: 0.0828 - accuracy: 0.9729 - val_loss: 0.0842 - val_accuracy: 0.9785 - 11s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "2534/2534 - 11s - loss: 0.0825 - accuracy: 0.9730 - val_loss: 0.0836 - val_accuracy: 0.9775 - 11s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "2534/2534 - 10s - loss: 0.0826 - accuracy: 0.9729 - val_loss: 0.0855 - val_accuracy: 0.9763 - 10s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "2534/2534 - 10s - loss: 0.0823 - accuracy: 0.9731 - val_loss: 0.0827 - val_accuracy: 0.9785 - 10s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "2534/2534 - 10s - loss: 0.0823 - accuracy: 0.9729 - val_loss: 0.0843 - val_accuracy: 0.9777 - 10s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "2534/2534 - 10s - loss: 0.0820 - accuracy: 0.9730 - val_loss: 0.0823 - val_accuracy: 0.9770 - 10s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "2534/2534 - 10s - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.0868 - val_accuracy: 0.9752 - 10s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "2534/2534 - 10s - loss: 0.0815 - accuracy: 0.9731 - val_loss: 0.0828 - val_accuracy: 0.9780 - 10s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "2534/2534 - 10s - loss: 0.0813 - accuracy: 0.9732 - val_loss: 0.0791 - val_accuracy: 0.9790 - 10s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "2534/2534 - 10s - loss: 0.0810 - accuracy: 0.9734 - val_loss: 0.0829 - val_accuracy: 0.9763 - 10s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "2534/2534 - 11s - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.0805 - val_accuracy: 0.9787 - 11s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "2534/2534 - 11s - loss: 0.0804 - accuracy: 0.9736 - val_loss: 0.0811 - val_accuracy: 0.9792 - 11s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "2534/2534 - 11s - loss: 0.0806 - accuracy: 0.9736 - val_loss: 0.0862 - val_accuracy: 0.9762 - 11s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "2534/2534 - 11s - loss: 0.0806 - accuracy: 0.9735 - val_loss: 0.0836 - val_accuracy: 0.9779 - 11s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "2534/2534 - 11s - loss: 0.0807 - accuracy: 0.9736 - val_loss: 0.0813 - val_accuracy: 0.9781 - 11s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "2534/2534 - 10s - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.0806 - val_accuracy: 0.9786 - 10s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "2534/2534 - 10s - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.0792 - val_accuracy: 0.9794 - 10s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "2534/2534 - 10s - loss: 0.0796 - accuracy: 0.9737 - val_loss: 0.0831 - val_accuracy: 0.9776 - 10s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "2534/2534 - 10s - loss: 0.0798 - accuracy: 0.9737 - val_loss: 0.0835 - val_accuracy: 0.9775 - 10s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "2534/2534 - 10s - loss: 0.0795 - accuracy: 0.9740 - val_loss: 0.0820 - val_accuracy: 0.9782 - 10s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "2534/2534 - 10s - loss: 0.0798 - accuracy: 0.9739 - val_loss: 0.0825 - val_accuracy: 0.9784 - 10s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "2534/2534 - 10s - loss: 0.0794 - accuracy: 0.9740 - val_loss: 0.0833 - val_accuracy: 0.9775 - 10s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "2534/2534 - 10s - loss: 0.0792 - accuracy: 0.9740 - val_loss: 0.0804 - val_accuracy: 0.9785 - 10s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "2534/2534 - 10s - loss: 0.0793 - accuracy: 0.9739 - val_loss: 0.0811 - val_accuracy: 0.9792 - 10s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "2534/2534 - 10s - loss: 0.0790 - accuracy: 0.9742 - val_loss: 0.0809 - val_accuracy: 0.9779 - 10s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "2534/2534 - 10s - loss: 0.0791 - accuracy: 0.9741 - val_loss: 0.0820 - val_accuracy: 0.9786 - 10s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "2534/2534 - 10s - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.0800 - val_accuracy: 0.9790 - 10s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "2534/2534 - 10s - loss: 0.0783 - accuracy: 0.9743 - val_loss: 0.0821 - val_accuracy: 0.9786 - 10s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "2534/2534 - 10s - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.0806 - val_accuracy: 0.9787 - 10s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "2534/2534 - 10s - loss: 0.0782 - accuracy: 0.9742 - val_loss: 0.0829 - val_accuracy: 0.9772 - 10s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "2534/2534 - 10s - loss: 0.0778 - accuracy: 0.9744 - val_loss: 0.0812 - val_accuracy: 0.9788 - 10s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "2534/2534 - 10s - loss: 0.0782 - accuracy: 0.9744 - val_loss: 0.0801 - val_accuracy: 0.9791 - 10s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "2534/2534 - 10s - loss: 0.0778 - accuracy: 0.9745 - val_loss: 0.0818 - val_accuracy: 0.9781 - 10s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "2534/2534 - 10s - loss: 0.0776 - accuracy: 0.9747 - val_loss: 0.0821 - val_accuracy: 0.9780 - 10s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "2534/2534 - 10s - loss: 0.0778 - accuracy: 0.9744 - val_loss: 0.0816 - val_accuracy: 0.9786 - 10s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "2534/2534 - 10s - loss: 0.0777 - accuracy: 0.9747 - val_loss: 0.0780 - val_accuracy: 0.9794 - 10s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "2534/2534 - 10s - loss: 0.0777 - accuracy: 0.9745 - val_loss: 0.0791 - val_accuracy: 0.9790 - 10s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "2534/2534 - 10s - loss: 0.0774 - accuracy: 0.9748 - val_loss: 0.0796 - val_accuracy: 0.9784 - 10s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "2534/2534 - 10s - loss: 0.0769 - accuracy: 0.9749 - val_loss: 0.0792 - val_accuracy: 0.9789 - 10s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "2534/2534 - 10s - loss: 0.0774 - accuracy: 0.9748 - val_loss: 0.0801 - val_accuracy: 0.9778 - 10s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "2534/2534 - 10s - loss: 0.0771 - accuracy: 0.9748 - val_loss: 0.0826 - val_accuracy: 0.9759 - 10s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "2534/2534 - 10s - loss: 0.0771 - accuracy: 0.9748 - val_loss: 0.0783 - val_accuracy: 0.9786 - 10s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "2534/2534 - 10s - loss: 0.0765 - accuracy: 0.9752 - val_loss: 0.0786 - val_accuracy: 0.9794 - 10s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "2534/2534 - 10s - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.0809 - val_accuracy: 0.9783 - 10s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_6 = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_6 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_6, histogram_freq=1)\n",
    "        ]\n",
    "#print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_test.shape, y_test.shape)\n",
    "#print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
    "history_6  = model_6.fit(X_train_over,y_train_over,validation_data=(x_test,y_test), callbacks=[monitor_6],verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f62c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.save('model1_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b67d4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "# for both logistic and nueral\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "#\t\tcolab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "\t\t#model_4.save(colab_path + 'model4.h5')\n",
    "\t\tif i != 4 and i != 3:\n",
    "\t\t\tfilename =  'model1_' + str(i + 1) + '.h5'\n",
    "\t\t\t# load model from file\n",
    "\t\t\tmodel = load_model(filename,custom_objects=None)\n",
    "\t\t\t# add to list of members\n",
    "\t\t\tall_models.append(model)\n",
    "\t\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58de75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "#neural\n",
    "\n",
    "def define_stacked_model(members):\n",
    "\tinitializer = tf.keras.initializers.GlorotUniform(seed=64)\n",
    "\tconstraints = None\n",
    "\n",
    "  # update all layers in all models to not be trainable\n",
    "\tfor i in range(len(members)):\n",
    "\t\tmodel = members[i]\n",
    "\t\tfor layer in model.layers:\n",
    "\t\t\t# make not trainable\n",
    "\t\t\tlayer.trainable = False\n",
    "\t\t\t# rename to avoid 'unique layer name' issue\n",
    "\t\t\tlayer._name = 'ensemble_' + str(i + 1) + '_' + layer.name\n",
    "\n",
    "\n",
    "\t# define multi-headed input\n",
    "\tensemble_visible = [model.input for model in members]\n",
    "\t# concatenate merge output from each model\n",
    "\tensemble_outputs = [model.output for model in members]\n",
    "\tmerge = concatenate(ensemble_outputs)\n",
    "\thidden1 = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_ea\")(merge)\n",
    "\thidden2 = Dense(64, kernel_initializer=initializer, activation='relu',name=\"dense_eb\")(hidden1)\n",
    "\toutput = Dense(Y.shape[1], kernel_initializer=initializer, activation='softmax',name=\"dense_ec\")(hidden1)\n",
    "\tmodel = Model(inputs=ensemble_visible, outputs=output)\n",
    "\t# plot graph of ensemble\n",
    "\tplot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "\t# compile\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "789219ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "#neural\n",
    "import datetime\n",
    "\n",
    "\n",
    "#colab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "log_dir =  \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_7= [\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "\n",
    "def fit_stacked_model(model, inputX, inputy):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# encode output data\n",
    "\tinputy_enc = to_categorical(inputy)\n",
    "\t# fit model\n",
    "\thistory_7=model.fit(X, inputy_enc, epochs=60, verbose=2,callbacks=[monitor_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc6cf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a stacked model\n",
    "#neural\n",
    "def predict_stacked_model(model, inputX):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# make prediction\n",
    "\treturn model.predict(X, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6d0ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded model1_1.h5\n",
      ">loaded model1_2.h5\n",
      ">loaded model1_3.h5\n",
      ">loaded model1_6.h5\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "#neural\n",
    "from keras.models import load_model\n",
    "n_members = 6\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "050121ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_2a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_3a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_6a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_1a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dense_2a  (None, 64)          8192        ['dense_2a_input[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dense_3a  (None, 512)         65536       ['dense_3a_input[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dense_6a  (None, 256)         32768       ['dense_6a_input[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dense_1a  (None, 64)          8192        ['dense_1a_input[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dense_2b  (None, 128)         8320        ['ensemble_2_ensemble_2_dense_2a[\n",
      "  (Dense)                                                        0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dropout_  (None, 512)         0           ['ensemble_3_ensemble_3_dense_3a[\n",
      " 5 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dropout_  (None, 256)         0           ['ensemble_4_ensemble_4_dense_6a[\n",
      " 8 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dense_1b  (None, 128)         8320        ['ensemble_1_ensemble_1_dense_1a[\n",
      "  (Dense)                                                        0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dropout_  (None, 128)         0           ['ensemble_2_ensemble_2_dense_2b[\n",
      " 2 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dense_3b  (None, 256)         131328      ['ensemble_3_ensemble_3_dropout_5\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dense_6b  (None, 128)         32896       ['ensemble_4_ensemble_4_dropout_8\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dropout   (None, 128)         0           ['ensemble_1_ensemble_1_dense_1b[\n",
      " (Dropout)                                                       0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dense_2c  (None, 256)         33024       ['ensemble_2_ensemble_2_dropout_2\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dropout_  (None, 256)         0           ['ensemble_3_ensemble_3_dense_3b[\n",
      " 6 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dropout_  (None, 128)         0           ['ensemble_4_ensemble_4_dense_6b[\n",
      " 9 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dense_1c  (None, 128)         16512       ['ensemble_1_ensemble_1_dropout[0\n",
      "  (Dense)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dropout_  (None, 256)         0           ['ensemble_2_ensemble_2_dense_2c[\n",
      " 3 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dense_3c  (None, 128)         32896       ['ensemble_3_ensemble_3_dropout_6\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dense_6c  (None, 128)         16512       ['ensemble_4_ensemble_4_dropout_9\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dropout_  (None, 128)         0           ['ensemble_1_ensemble_1_dense_1c[\n",
      " 1 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dense_2d  (None, 128)         32896       ['ensemble_2_ensemble_2_dropout_3\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dropout_  (None, 128)         0           ['ensemble_3_ensemble_3_dense_3c[\n",
      " 7 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dropout_  (None, 128)         0           ['ensemble_4_ensemble_4_dense_6c[\n",
      " 10 (Dropout)                                                    0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dense_1d  (None, 64)          8256        ['ensemble_1_ensemble_1_dropout_1\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dropout_  (None, 128)         0           ['ensemble_2_ensemble_2_dense_2d[\n",
      " 4 (Dropout)                                                     0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dense_3d  (None, 128)         16512       ['ensemble_3_ensemble_3_dropout_7\n",
      "  (Dense)                                                        [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dense_6d  (None, 64)          8256        ['ensemble_4_ensemble_4_dropout_1\n",
      "  (Dense)                                                        0[0][0]']                        \n",
      "                                                                                                  \n",
      " ensemble_1_ensemble_1_dense (D  (None, 21)          1365        ['ensemble_1_ensemble_1_dense_1d[\n",
      " ense)                                                           0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_2_ensemble_2_dense_1   (None, 21)          2709        ['ensemble_2_ensemble_2_dropout_4\n",
      " (Dense)                                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " ensemble_3_ensemble_3_dense_2   (None, 21)          2709        ['ensemble_3_ensemble_3_dense_3d[\n",
      " (Dense)                                                         0][0]']                          \n",
      "                                                                                                  \n",
      " ensemble_4_ensemble_4_dense_3   (None, 21)          1365        ['ensemble_4_ensemble_4_dense_6d[\n",
      " (Dense)                                                         0][0]']                          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 84)           0           ['ensemble_1_ensemble_1_dense[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'ensemble_2_ensemble_2_dense_1[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'ensemble_3_ensemble_3_dense_2[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'ensemble_4_ensemble_4_dense_3[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " dense_ea (Dense)               (None, 128)          10880       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_ec (Dense)               (None, 21)           2709        ['dense_ea[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 482,153\n",
      "Trainable params: 13,589\n",
      "Non-trainable params: 468,564\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define ensemble model\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.utils import plot_model\n",
    "#neural\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87aa5175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "27250/27250 - 38s - loss: 0.0644 - accuracy: 0.9845 - 38s/epoch - 1ms/step\n",
      "Epoch 2/60\n",
      "27250/27250 - 36s - loss: 0.0557 - accuracy: 0.9850 - 36s/epoch - 1ms/step\n",
      "Epoch 3/60\n",
      "27250/27250 - 36s - loss: 0.0547 - accuracy: 0.9852 - 36s/epoch - 1ms/step\n",
      "Epoch 4/60\n",
      "27250/27250 - 37s - loss: 0.0547 - accuracy: 0.9850 - 37s/epoch - 1ms/step\n",
      "Epoch 5/60\n",
      "27250/27250 - 37s - loss: 0.0544 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 6/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9851 - 37s/epoch - 1ms/step\n",
      "Epoch 7/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9851 - 37s/epoch - 1ms/step\n",
      "Epoch 8/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 9/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 10/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 11/60\n",
      "27250/27250 - 37s - loss: 0.0540 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 12/60\n",
      "27250/27250 - 37s - loss: 0.0543 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 13/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 14/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 15/60\n",
      "27250/27250 - 37s - loss: 0.0539 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 16/60\n",
      "27250/27250 - 36s - loss: 0.0542 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 17/60\n",
      "27250/27250 - 37s - loss: 0.0540 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 18/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 19/60\n",
      "27250/27250 - 37s - loss: 0.0543 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 20/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 21/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 22/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 23/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 24/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 25/60\n",
      "27250/27250 - 36s - loss: 0.0539 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 26/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 27/60\n",
      "27250/27250 - 38s - loss: 0.0543 - accuracy: 0.9852 - 38s/epoch - 1ms/step\n",
      "Epoch 28/60\n",
      "27250/27250 - 37s - loss: 0.0543 - accuracy: 0.9852 - 37s/epoch - 1ms/step\n",
      "Epoch 29/60\n",
      "27250/27250 - 36s - loss: 0.0539 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 30/60\n",
      "27250/27250 - 36s - loss: 0.0543 - accuracy: 0.9852 - 36s/epoch - 1ms/step\n",
      "Epoch 31/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9854 - 37s/epoch - 1ms/step\n",
      "Epoch 32/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 33/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 34/60\n",
      "27250/27250 - 36s - loss: 0.0541 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 35/60\n",
      "27250/27250 - 37s - loss: 0.0541 - accuracy: 0.9854 - 37s/epoch - 1ms/step\n",
      "Epoch 36/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 37/60\n",
      "27250/27250 - 37s - loss: 0.0545 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 38/60\n",
      "27250/27250 - 37s - loss: 0.0544 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 39/60\n",
      "27250/27250 - 37s - loss: 0.0547 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 40/60\n",
      "27250/27250 - 36s - loss: 0.0541 - accuracy: 0.9854 - 36s/epoch - 1ms/step\n",
      "Epoch 41/60\n",
      "27250/27250 - 37s - loss: 0.0545 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 42/60\n",
      "27250/27250 - 37s - loss: 0.0543 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 43/60\n",
      "27250/27250 - 37s - loss: 0.0543 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 44/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 45/60\n",
      "27250/27250 - 37s - loss: 0.0545 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 46/60\n",
      "27250/27250 - 37s - loss: 0.0544 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 47/60\n",
      "27250/27250 - 36s - loss: 0.0546 - accuracy: 0.9854 - 36s/epoch - 1ms/step\n",
      "Epoch 48/60\n",
      "27250/27250 - 37s - loss: 0.0542 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 49/60\n",
      "27250/27250 - 36s - loss: 0.0545 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 50/60\n",
      "27250/27250 - 36s - loss: 0.0545 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 51/60\n",
      "27250/27250 - 37s - loss: 0.0546 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 52/60\n",
      "27250/27250 - 35s - loss: 0.0545 - accuracy: 0.9853 - 35s/epoch - 1ms/step\n",
      "Epoch 53/60\n",
      "27250/27250 - 36s - loss: 0.0546 - accuracy: 0.9852 - 36s/epoch - 1ms/step\n",
      "Epoch 54/60\n",
      "27250/27250 - 36s - loss: 0.0544 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 55/60\n",
      "27250/27250 - 37s - loss: 0.0545 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n",
      "Epoch 56/60\n",
      "27250/27250 - 36s - loss: 0.0548 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 57/60\n",
      "27250/27250 - 36s - loss: 0.0548 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 58/60\n",
      "27250/27250 - 36s - loss: 0.0547 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 59/60\n",
      "27250/27250 - 36s - loss: 0.0545 - accuracy: 0.9853 - 36s/epoch - 1ms/step\n",
      "Epoch 60/60\n",
      "27250/27250 - 37s - loss: 0.0548 - accuracy: 0.9853 - 37s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "# fit stacked model on test dataset\n",
    "#neural\n",
    "fit_stacked_model(stacked_model, x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e827eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 6s - 6s/epoch - 907us/step\n",
      "Stacked Test Accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e23b59c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.92      0.96      0.94        51\n",
      "           2       0.99      0.99      0.99     72091\n",
      "           3       1.00      1.00      1.00       433\n",
      "           4       1.00      0.97      0.98       365\n",
      "           5       0.99      0.99      0.99     62503\n",
      "           6       0.98      0.99      0.99     51385\n",
      "           7       0.59      0.69      0.64        78\n",
      "           8       0.46      0.31      0.37        67\n",
      "           9       0.94      0.71      0.81        62\n",
      "          10       0.91      0.21      0.34       349\n",
      "          11       0.98      0.95      0.96      7418\n",
      "          12       1.00      0.20      0.33         5\n",
      "          13       1.00      0.67      0.80         9\n",
      "          15       0.89      0.74      0.81      1989\n",
      "          16       0.86      0.35      0.50        17\n",
      "          17       0.91      0.94      0.92      3272\n",
      "          18       1.00      0.73      0.85        15\n",
      "          19       0.97      0.98      0.97     10833\n",
      "          20       0.94      0.97      0.95      7055\n",
      "\n",
      "    accuracy                           0.98    218000\n",
      "   macro avg       0.87      0.72      0.76    218000\n",
      "weighted avg       0.98      0.98      0.98    218000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00         3\\n           1       0.92      0.96      0.94        51\\n           2       0.99      0.99      0.99     72091\\n           3       1.00      1.00      1.00       433\\n           4       1.00      0.97      0.98       365\\n           5       0.99      0.99      0.99     62503\\n           6       0.98      0.99      0.99     51385\\n           7       0.59      0.69      0.64        78\\n           8       0.46      0.31      0.37        67\\n           9       0.94      0.71      0.81        62\\n          10       0.91      0.21      0.34       349\\n          11       0.98      0.95      0.96      7418\\n          12       1.00      0.20      0.33         5\\n          13       1.00      0.67      0.80         9\\n          15       0.89      0.74      0.81      1989\\n          16       0.86      0.35      0.50        17\\n          17       0.91      0.94      0.92      3272\\n          18       1.00      0.73      0.85        15\\n          19       0.97      0.98      0.97     10833\\n          20       0.94      0.97      0.95      7055\\n\\n    accuracy                           0.98    218000\\n   macro avg       0.87      0.72      0.76    218000\\nweighted avg       0.98      0.98      0.98    218000\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_1, yhat_val))\n",
    "classification_report(y_test_1, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea2a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
