{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 19:21:42.543239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 기본라이브러리 import\n",
    "#from google.colab import drive\n",
    "#import os, json, pickle\n",
    "#import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# 파이토치 라이브러리 import\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "#Keras Import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import ipaddress\n",
    "\n",
    "# 구글 드라이브 mount\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# 데이터 파일 위치\n",
    "#C:\\Users\\mariu\\내 드라이브\\Colab Notebooks\\Network\n",
    "colab_path = '/home/marius1406/'\n",
    "colab_write_path = \"/home/marius1406/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_path = \"/home/marius1406/\"\n",
    "df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False, nrows=1089999)\n",
    "#df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장판에서 사용\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'DNS_QUERY_ID','Label','Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR_1','IPV4_SRC_ADDR_2','Label','Attack','Dataset', 'Label_1','Attack_1','Dataset_1', 'Label_2','Attack_2','Dataset_2'])  #명목형변수, 레이블 변수 제외\n",
    "cols = df.columns.drop(['Label','Attack'])  #명목형변수, 레이블 변수 제외#cols = df.columns.drop(['Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "X = df[cols]\n",
    "dummies = pd.get_dummies(df['Attack']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "Y = dummies.values\n",
    "\n",
    "#==================\n",
    "dummiesLabel = pd.get_dummies(df['Label']) # Classification\n",
    "y_1_label = df['Label'].values\n",
    "y_label = dummiesLabel.values\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "def extend_sparse(val):\n",
    "    if val in ['Analysis', 'Exploits', 'Fuzzers', 'Shellcode', 'Theft', 'Worms', 'mitm']: return 1\n",
    "    return 0\n",
    "\n",
    "y_1_attack = pd.DataFrame(df['Attack'])\n",
    "\n",
    "is_sparse = y_1_attack.applymap(extend_sparse)\n",
    "y_1_enforce = is_sparse.values\n",
    "y_enforce = pd.get_dummies(is_sparse['Attack']) # Classification\n",
    "\n",
    "#=======================\n",
    "\n",
    "def max_8G(val):\n",
    "    if (val > 1.0e+9): return 1.0e+9\n",
    "    return val\n",
    "\n",
    "#cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT']\n",
    "cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "'DST_TO_SRC_SECOND_BYTES_1', 'SRC_TO_DST_SECOND_BYTES_1', 'SRC_TO_DST_AVG_THROUGHPUT_1', 'DST_TO_SRC_AVG_THROUGHPUT_1',\n",
    "'DST_TO_SRC_SECOND_BYTES_2', 'SRC_TO_DST_SECOND_BYTES_2', 'SRC_TO_DST_AVG_THROUGHPUT_2', 'DST_TO_SRC_AVG_THROUGHPUT_2'] \n",
    "\n",
    "X[cols] = X[cols].applymap(max_8G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 4291722866\n",
      "L4_SRC_PORT 65535\n",
      "IPV4_DST_ADDR 4294967295\n",
      "L4_DST_PORT 65535\n",
      "PROTOCOL 254\n",
      "L7_PROTO 248.0\n",
      "IN_BYTES 34641563\n",
      "IN_PKTS 123763\n",
      "OUT_BYTES 129573662\n",
      "OUT_PKTS 87179\n",
      "TCP_FLAGS 223\n",
      "CLIENT_TCP_FLAGS 223\n",
      "SERVER_TCP_FLAGS 223\n",
      "FLOW_DURATION_MILLISECONDS 4294967\n",
      "DURATION_IN 105400\n",
      "DURATION_OUT 38547\n",
      "MIN_TTL 255\n",
      "MAX_TTL 255\n",
      "LONGEST_FLOW_PKT 7292\n",
      "SHORTEST_FLOW_PKT 1504\n",
      "MIN_IP_PKT_LEN 547\n",
      "MAX_IP_PKT_LEN 7292\n",
      "SRC_TO_DST_SECOND_BYTES 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES 6321251\n",
      "RETRANSMITTED_IN_PKTS 4774\n",
      "RETRANSMITTED_OUT_BYTES 2183347\n",
      "RETRANSMITTED_OUT_PKTS 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES 191858\n",
      "NUM_PKTS_128_TO_256_BYTES 7230\n",
      "NUM_PKTS_256_TO_512_BYTES 4921\n",
      "NUM_PKTS_512_TO_1024_BYTES 34443\n",
      "NUM_PKTS_1024_TO_1514_BYTES 86096\n",
      "TCP_WIN_MAX_IN 65535\n",
      "TCP_WIN_MAX_OUT 65535\n",
      "ICMP_TYPE 65280\n",
      "ICMP_IPV4_TYPE 255\n",
      "DNS_QUERY_ID 65535\n",
      "DNS_QUERY_TYPE 32769\n",
      "DNS_TTL_ANSWER 4294915672\n",
      "FTP_COMMAND_RET_CODE 550.0\n",
      "L4_SRC_PORT_1 65535\n",
      "IPV4_DST_ADDR_1 4294967295\n",
      "L4_DST_PORT_1 65535\n",
      "PROTOCOL_1 254\n",
      "L7_PROTO_1 248.0\n",
      "IN_BYTES_1 32341314\n",
      "IN_PKTS_1 123763\n",
      "OUT_BYTES_1 129573662\n",
      "OUT_PKTS_1 87179\n",
      "TCP_FLAGS_1 223\n",
      "CLIENT_TCP_FLAGS_1 223\n",
      "SERVER_TCP_FLAGS_1 223\n",
      "FLOW_DURATION_MILLISECONDS_1 4294967\n",
      "DURATION_IN_1 105400\n",
      "DURATION_OUT_1 38547\n",
      "MIN_TTL_1 255\n",
      "MAX_TTL_1 255\n",
      "LONGEST_FLOW_PKT_1 7292\n",
      "SHORTEST_FLOW_PKT_1 1504\n",
      "MIN_IP_PKT_LEN_1 547\n",
      "MAX_IP_PKT_LEN_1 7292\n",
      "SRC_TO_DST_SECOND_BYTES_1 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_1 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_1 6321251\n",
      "RETRANSMITTED_IN_PKTS_1 4774\n",
      "RETRANSMITTED_OUT_BYTES_1 2183347\n",
      "RETRANSMITTED_OUT_PKTS_1 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_1 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_1 3406\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 18388\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 86096\n",
      "TCP_WIN_MAX_IN_1 65535\n",
      "TCP_WIN_MAX_OUT_1 65535\n",
      "ICMP_TYPE_1 65280\n",
      "ICMP_IPV4_TYPE_1 255\n",
      "DNS_QUERY_ID_1 65535\n",
      "DNS_QUERY_TYPE_1 32769\n",
      "DNS_TTL_ANSWER_1 4294915672\n",
      "FTP_COMMAND_RET_CODE_1 550.0\n",
      "L4_SRC_PORT_2 65535\n",
      "IPV4_DST_ADDR_2 4294967295\n",
      "L4_DST_PORT_2 65535\n",
      "PROTOCOL_2 254\n",
      "L7_PROTO_2 245.178\n",
      "IN_BYTES_2 33337052\n",
      "IN_PKTS_2 123763\n",
      "OUT_BYTES_2 129573662\n",
      "OUT_PKTS_2 87179\n",
      "TCP_FLAGS_2 223\n",
      "CLIENT_TCP_FLAGS_2 223\n",
      "SERVER_TCP_FLAGS_2 223\n",
      "FLOW_DURATION_MILLISECONDS_2 4294967\n",
      "DURATION_IN_2 105400\n",
      "DURATION_OUT_2 38547\n",
      "MIN_TTL_2 255\n",
      "MAX_TTL_2 255\n",
      "LONGEST_FLOW_PKT_2 7292\n",
      "SHORTEST_FLOW_PKT_2 1504\n",
      "MIN_IP_PKT_LEN_2 422\n",
      "MAX_IP_PKT_LEN_2 7292\n",
      "SRC_TO_DST_SECOND_BYTES_2 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_2 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_2 6321251\n",
      "RETRANSMITTED_IN_PKTS_2 4774\n",
      "RETRANSMITTED_OUT_BYTES_2 1109291\n",
      "RETRANSMITTED_OUT_PKTS_2 824\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_2 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_2 3446\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 18954\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 86096\n",
      "TCP_WIN_MAX_IN_2 65535\n",
      "TCP_WIN_MAX_OUT_2 65535\n",
      "ICMP_TYPE_2 65280\n",
      "ICMP_IPV4_TYPE_2 255\n",
      "DNS_QUERY_ID_2 65535\n",
      "DNS_QUERY_TYPE_2 32769\n",
      "DNS_TTL_ANSWER_2 4294915672\n",
      "FTP_COMMAND_RET_CODE_2 550.0\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scaler_train = preprocessing.StandardScaler()\n",
    "scaler_train = scaler_train.fit(X)\n",
    "X = pd.DataFrame(scaler_train.transform(X),index=np.arange(0,X.shape[0],1), columns = X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 0\n",
      "L4_SRC_PORT 0\n",
      "IPV4_DST_ADDR 0\n",
      "L4_DST_PORT 0\n",
      "PROTOCOL 0\n",
      "L7_PROTO 0\n",
      "IN_BYTES 0\n",
      "IN_PKTS 0\n",
      "OUT_BYTES 0\n",
      "OUT_PKTS 0\n",
      "TCP_FLAGS 0\n",
      "CLIENT_TCP_FLAGS 0\n",
      "SERVER_TCP_FLAGS 0\n",
      "FLOW_DURATION_MILLISECONDS 0\n",
      "DURATION_IN 0\n",
      "DURATION_OUT 0\n",
      "MIN_TTL 0\n",
      "MAX_TTL 0\n",
      "LONGEST_FLOW_PKT 0\n",
      "SHORTEST_FLOW_PKT 0\n",
      "MIN_IP_PKT_LEN 0\n",
      "MAX_IP_PKT_LEN 0\n",
      "SRC_TO_DST_SECOND_BYTES 0\n",
      "DST_TO_SRC_SECOND_BYTES 0\n",
      "RETRANSMITTED_IN_BYTES 0\n",
      "RETRANSMITTED_IN_PKTS 0\n",
      "RETRANSMITTED_OUT_BYTES 0\n",
      "RETRANSMITTED_OUT_PKTS 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 0\n",
      "NUM_PKTS_UP_TO_128_BYTES 0\n",
      "NUM_PKTS_128_TO_256_BYTES 0\n",
      "NUM_PKTS_256_TO_512_BYTES 0\n",
      "NUM_PKTS_512_TO_1024_BYTES 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES 0\n",
      "TCP_WIN_MAX_IN 0\n",
      "TCP_WIN_MAX_OUT 0\n",
      "ICMP_TYPE 0\n",
      "ICMP_IPV4_TYPE 0\n",
      "DNS_QUERY_ID 0\n",
      "DNS_QUERY_TYPE 0\n",
      "DNS_TTL_ANSWER 0\n",
      "FTP_COMMAND_RET_CODE 0\n",
      "L4_SRC_PORT_1 0\n",
      "IPV4_DST_ADDR_1 0\n",
      "L4_DST_PORT_1 0\n",
      "PROTOCOL_1 0\n",
      "L7_PROTO_1 0\n",
      "IN_BYTES_1 0\n",
      "IN_PKTS_1 0\n",
      "OUT_BYTES_1 0\n",
      "OUT_PKTS_1 0\n",
      "TCP_FLAGS_1 0\n",
      "CLIENT_TCP_FLAGS_1 0\n",
      "SERVER_TCP_FLAGS_1 0\n",
      "FLOW_DURATION_MILLISECONDS_1 0\n",
      "DURATION_IN_1 0\n",
      "DURATION_OUT_1 0\n",
      "MIN_TTL_1 0\n",
      "MAX_TTL_1 0\n",
      "LONGEST_FLOW_PKT_1 0\n",
      "SHORTEST_FLOW_PKT_1 0\n",
      "MIN_IP_PKT_LEN_1 0\n",
      "MAX_IP_PKT_LEN_1 0\n",
      "SRC_TO_DST_SECOND_BYTES_1 0\n",
      "DST_TO_SRC_SECOND_BYTES_1 0\n",
      "RETRANSMITTED_IN_BYTES_1 0\n",
      "RETRANSMITTED_IN_PKTS_1 0\n",
      "RETRANSMITTED_OUT_BYTES_1 0\n",
      "RETRANSMITTED_OUT_PKTS_1 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 0\n",
      "NUM_PKTS_128_TO_256_BYTES_1 0\n",
      "NUM_PKTS_256_TO_512_BYTES_1 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 0\n",
      "TCP_WIN_MAX_IN_1 0\n",
      "TCP_WIN_MAX_OUT_1 0\n",
      "ICMP_TYPE_1 0\n",
      "ICMP_IPV4_TYPE_1 0\n",
      "DNS_QUERY_ID_1 0\n",
      "DNS_QUERY_TYPE_1 0\n",
      "DNS_TTL_ANSWER_1 0\n",
      "FTP_COMMAND_RET_CODE_1 0\n",
      "L4_SRC_PORT_2 0\n",
      "IPV4_DST_ADDR_2 0\n",
      "L4_DST_PORT_2 0\n",
      "PROTOCOL_2 0\n",
      "L7_PROTO_2 0\n",
      "IN_BYTES_2 0\n",
      "IN_PKTS_2 0\n",
      "OUT_BYTES_2 0\n",
      "OUT_PKTS_2 0\n",
      "TCP_FLAGS_2 0\n",
      "CLIENT_TCP_FLAGS_2 0\n",
      "SERVER_TCP_FLAGS_2 0\n",
      "FLOW_DURATION_MILLISECONDS_2 0\n",
      "DURATION_IN_2 0\n",
      "DURATION_OUT_2 0\n",
      "MIN_TTL_2 0\n",
      "MAX_TTL_2 0\n",
      "LONGEST_FLOW_PKT_2 0\n",
      "SHORTEST_FLOW_PKT_2 0\n",
      "MIN_IP_PKT_LEN_2 0\n",
      "MAX_IP_PKT_LEN_2 0\n",
      "SRC_TO_DST_SECOND_BYTES_2 0\n",
      "DST_TO_SRC_SECOND_BYTES_2 0\n",
      "RETRANSMITTED_IN_BYTES_2 0\n",
      "RETRANSMITTED_IN_PKTS_2 0\n",
      "RETRANSMITTED_OUT_BYTES_2 0\n",
      "RETRANSMITTED_OUT_PKTS_2 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 0\n",
      "NUM_PKTS_128_TO_256_BYTES_2 0\n",
      "NUM_PKTS_256_TO_512_BYTES_2 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 0\n",
      "TCP_WIN_MAX_IN_2 0\n",
      "TCP_WIN_MAX_OUT_2 0\n",
      "ICMP_TYPE_2 0\n",
      "ICMP_IPV4_TYPE_2 0\n",
      "DNS_QUERY_ID_2 0\n",
      "DNS_QUERY_TYPE_2 0\n",
      "DNS_TTL_ANSWER_2 0\n",
      "FTP_COMMAND_RET_CODE_2 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].isna().sum())\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_3sigma(val):\n",
    "    if (val < -3): return -3\n",
    "    if (val > 3): return 3\n",
    "    return val\n",
    "\n",
    "X = X.applymap(max_3sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 19:22:37.928685: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.argmax(dummies, axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_label, y_train_label, y_test_label = train_test_split(X, y_label, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_enforce, y_train_enforce, y_test_enforce = train_test_split(X, y_enforce, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_1, y_train_1, y_test_1 = train_test_split(X, y1.numpy(), test_size=0.20, shuffle = True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_write_path = \"/home/marius1406/\"\n",
    "colab_model_write_path = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M\" + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_1 = tf.keras.Sequential([\\n  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation=\\'relu\\'),\\n  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation=\\'softmax\\')\\n  ])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1\n",
    "#initializer = \"glorot_uniform\"\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu',name='dense_1a'),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1b'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1c'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1d'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "  ])\n",
    "'''\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation='softmax')\n",
    "  ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marius1406/20231010221352\n",
      "Epoch 1/100\n",
      "852/852 - 10s - loss: 0.2878 - accuracy: 0.9140 - val_loss: 0.1270 - val_accuracy: 0.9654 - 10s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "852/852 - 20s - loss: 0.1290 - accuracy: 0.9653 - val_loss: 0.1031 - val_accuracy: 0.9727 - 20s/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "852/852 - 11s - loss: 0.1105 - accuracy: 0.9708 - val_loss: 0.0938 - val_accuracy: 0.9753 - 11s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "852/852 - 14s - loss: 0.1012 - accuracy: 0.9734 - val_loss: 0.0869 - val_accuracy: 0.9771 - 14s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "852/852 - 15s - loss: 0.0947 - accuracy: 0.9749 - val_loss: 0.0852 - val_accuracy: 0.9774 - 15s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "852/852 - 14s - loss: 0.0906 - accuracy: 0.9761 - val_loss: 0.0807 - val_accuracy: 0.9787 - 14s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "852/852 - 17s - loss: 0.0876 - accuracy: 0.9767 - val_loss: 0.0793 - val_accuracy: 0.9792 - 17s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "852/852 - 23s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0764 - val_accuracy: 0.9796 - 23s/epoch - 27ms/step\n",
      "Epoch 9/100\n",
      "852/852 - 23s - loss: 0.0828 - accuracy: 0.9779 - val_loss: 0.0754 - val_accuracy: 0.9801 - 23s/epoch - 27ms/step\n",
      "Epoch 10/100\n",
      "852/852 - 19s - loss: 0.0818 - accuracy: 0.9782 - val_loss: 0.0751 - val_accuracy: 0.9793 - 19s/epoch - 22ms/step\n",
      "Epoch 11/100\n",
      "852/852 - 12s - loss: 0.0798 - accuracy: 0.9785 - val_loss: 0.0744 - val_accuracy: 0.9800 - 12s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "852/852 - 16s - loss: 0.0789 - accuracy: 0.9788 - val_loss: 0.0742 - val_accuracy: 0.9802 - 16s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "852/852 - 14s - loss: 0.0779 - accuracy: 0.9791 - val_loss: 0.0747 - val_accuracy: 0.9801 - 14s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "852/852 - 19s - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.0730 - val_accuracy: 0.9804 - 19s/epoch - 22ms/step\n",
      "Epoch 15/100\n",
      "852/852 - 18s - loss: 0.0761 - accuracy: 0.9794 - val_loss: 0.0741 - val_accuracy: 0.9808 - 18s/epoch - 22ms/step\n",
      "Epoch 16/100\n",
      "852/852 - 15s - loss: 0.0753 - accuracy: 0.9797 - val_loss: 0.0711 - val_accuracy: 0.9812 - 15s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "852/852 - 10s - loss: 0.0748 - accuracy: 0.9799 - val_loss: 0.0711 - val_accuracy: 0.9808 - 10s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "852/852 - 11s - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.0693 - val_accuracy: 0.9815 - 11s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "852/852 - 13s - loss: 0.0732 - accuracy: 0.9802 - val_loss: 0.0701 - val_accuracy: 0.9810 - 13s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "852/852 - 12s - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.0693 - val_accuracy: 0.9813 - 12s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "852/852 - 16s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0699 - val_accuracy: 0.9814 - 16s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "852/852 - 32s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0687 - val_accuracy: 0.9816 - 32s/epoch - 37ms/step\n",
      "Epoch 23/100\n",
      "852/852 - 26s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0685 - val_accuracy: 0.9818 - 26s/epoch - 30ms/step\n",
      "Epoch 24/100\n",
      "852/852 - 18s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0686 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "852/852 - 17s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9818 - 17s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "852/852 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "852/852 - 10s - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0671 - val_accuracy: 0.9820 - 10s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "852/852 - 11s - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0683 - val_accuracy: 0.9818 - 11s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "852/852 - 10s - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0684 - val_accuracy: 0.9813 - 10s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "852/852 - 15s - loss: 0.0694 - accuracy: 0.9812 - val_loss: 0.0669 - val_accuracy: 0.9821 - 15s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "852/852 - 13s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0676 - val_accuracy: 0.9819 - 13s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "852/852 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0659 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "852/852 - 14s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0664 - val_accuracy: 0.9824 - 14s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "852/852 - 20s - loss: 0.0681 - accuracy: 0.9815 - val_loss: 0.0653 - val_accuracy: 0.9826 - 20s/epoch - 23ms/step\n",
      "Epoch 35/100\n",
      "852/852 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0675 - val_accuracy: 0.9821 - 12s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "852/852 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0655 - val_accuracy: 0.9823 - 12s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "852/852 - 10s - loss: 0.0677 - accuracy: 0.9817 - val_loss: 0.0656 - val_accuracy: 0.9826 - 10s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "852/852 - 10s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0652 - val_accuracy: 0.9823 - 10s/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "852/852 - 18s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0683 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "852/852 - 20s - loss: 0.0673 - accuracy: 0.9818 - val_loss: 0.0674 - val_accuracy: 0.9816 - 20s/epoch - 23ms/step\n",
      "Epoch 41/100\n",
      "852/852 - 26s - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.0653 - val_accuracy: 0.9828 - 26s/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "852/852 - 34s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0659 - val_accuracy: 0.9825 - 34s/epoch - 40ms/step\n",
      "Epoch 43/100\n",
      "852/852 - 30s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 30s/epoch - 35ms/step\n",
      "Epoch 44/100\n",
      "852/852 - 19s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 19s/epoch - 22ms/step\n",
      "Epoch 45/100\n",
      "852/852 - 21s - loss: 0.0665 - accuracy: 0.9819 - val_loss: 0.0654 - val_accuracy: 0.9825 - 21s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "852/852 - 13s - loss: 0.0664 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9827 - 13s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "852/852 - 10s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0659 - val_accuracy: 0.9825 - 10s/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "852/852 - 13s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0655 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "852/852 - 11s - loss: 0.0659 - accuracy: 0.9821 - val_loss: 0.0654 - val_accuracy: 0.9826 - 11s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "852/852 - 18s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0656 - val_accuracy: 0.9823 - 18s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "852/852 - 16s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0641 - val_accuracy: 0.9827 - 16s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "852/852 - 18s - loss: 0.0655 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9827 - 18s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "852/852 - 15s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0644 - val_accuracy: 0.9827 - 15s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "852/852 - 13s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9827 - 13s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "852/852 - 24s - loss: 0.0653 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9827 - 24s/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "852/852 - 14s - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9831 - 14s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "852/852 - 26s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.9825 - 26s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "852/852 - 26s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0642 - val_accuracy: 0.9826 - 26s/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "852/852 - 20s - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.0645 - val_accuracy: 0.9828 - 20s/epoch - 23ms/step\n",
      "Epoch 60/100\n",
      "852/852 - 17s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9829 - 17s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "852/852 - 10s - loss: 0.0645 - accuracy: 0.9826 - val_loss: 0.0644 - val_accuracy: 0.9828 - 10s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "852/852 - 12s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0646 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "852/852 - 13s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0642 - val_accuracy: 0.9829 - 13s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "852/852 - 13s - loss: 0.0644 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "852/852 - 18s - loss: 0.0640 - accuracy: 0.9826 - val_loss: 0.0636 - val_accuracy: 0.9829 - 18s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "852/852 - 12s - loss: 0.0644 - accuracy: 0.9824 - val_loss: 0.0647 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "852/852 - 18s - loss: 0.0642 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9830 - 18s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "852/852 - 11s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0635 - val_accuracy: 0.9829 - 11s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "852/852 - 10s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9828 - 10s/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "852/852 - 13s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0627 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "852/852 - 16s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9830 - 16s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "852/852 - 15s - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0640 - val_accuracy: 0.9831 - 15s/epoch - 18ms/step\n",
      "Epoch 73/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0639 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0632 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "852/852 - 10s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "852/852 - 10s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9831 - 10s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "852/852 - 12s - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0628 - val_accuracy: 0.9832 - 12s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "852/852 - 16s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0620 - val_accuracy: 0.9834 - 16s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "852/852 - 26s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0635 - val_accuracy: 0.9831 - 26s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "852/852 - 17s - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9827 - 17s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "852/852 - 17s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9832 - 17s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "852/852 - 7s - loss: 0.0631 - accuracy: 0.9830 - val_loss: 0.0621 - val_accuracy: 0.9834 - 7s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "852/852 - 10s - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.0628 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "852/852 - 15s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0624 - val_accuracy: 0.9832 - 15s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "852/852 - 23s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9833 - 23s/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "852/852 - 13s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "852/852 - 24s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0629 - val_accuracy: 0.9831 - 24s/epoch - 28ms/step\n",
      "Epoch 88/100\n",
      "852/852 - 31s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9832 - 31s/epoch - 36ms/step\n",
      "Epoch 89/100\n",
      "852/852 - 7s - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9833 - 7s/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "852/852 - 11s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9834 - 11s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "852/852 - 13s - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.0630 - val_accuracy: 0.9833 - 13s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "852/852 - 27s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9834 - 27s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "852/852 - 28s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0618 - val_accuracy: 0.9834 - 28s/epoch - 33ms/step\n",
      "Epoch 94/100\n",
      "852/852 - 25s - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0623 - val_accuracy: 0.9833 - 25s/epoch - 30ms/step\n",
      "Epoch 95/100\n",
      "852/852 - 10s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9823 - 10s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "852/852 - 12s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9836 - 12s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "852/852 - 27s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9836 - 27s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "852/852 - 8s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9835 - 8s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "852/852 - 9s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9834 - 9s/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "852/852 - 18s - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9835 - 18s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model_1.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_1 = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(log_dir_1)\n",
    "monitor_1 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "            ]\n",
    "history_1  = model_1.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=1024, epochs=100)\n",
    "model_1.save(colab_model_write_path + 'model1.h5')\n",
    "#history_1  = model_1.fit(x_train,y_train,validation_split=0.2, callbacks=[monitor_1],verbose=2, batch_size=1024, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  model 2  with different structure\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_2a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, activation='relu',name='dense_2b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(256, input_dim=128, kernel_initializer=initializer, activation='relu',name='dense_2c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=256, kernel_initializer=initializer, activation='relu',name='dense_2d'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 14s - loss: 0.2063 - accuracy: 0.9384 - val_loss: 0.1091 - val_accuracy: 0.9693 - 14s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 15s - loss: 0.1104 - accuracy: 0.9704 - val_loss: 0.0928 - val_accuracy: 0.9750 - 15s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 12s - loss: 0.0971 - accuracy: 0.9739 - val_loss: 0.0835 - val_accuracy: 0.9780 - 12s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 16s - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.0814 - val_accuracy: 0.9785 - 16s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 12s - loss: 0.0865 - accuracy: 0.9769 - val_loss: 0.0774 - val_accuracy: 0.9796 - 12s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 13s - loss: 0.0833 - accuracy: 0.9778 - val_loss: 0.0785 - val_accuracy: 0.9796 - 13s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 13s - loss: 0.0815 - accuracy: 0.9782 - val_loss: 0.0755 - val_accuracy: 0.9798 - 13s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0793 - accuracy: 0.9787 - val_loss: 0.0725 - val_accuracy: 0.9802 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 12s - loss: 0.0780 - accuracy: 0.9791 - val_loss: 0.0717 - val_accuracy: 0.9808 - 12s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 13s - loss: 0.0767 - accuracy: 0.9793 - val_loss: 0.0705 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 12s - loss: 0.0757 - accuracy: 0.9796 - val_loss: 0.0700 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 12s - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.0705 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 12s - loss: 0.0741 - accuracy: 0.9799 - val_loss: 0.0699 - val_accuracy: 0.9812 - 12s/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 15s - loss: 0.0736 - accuracy: 0.9801 - val_loss: 0.0692 - val_accuracy: 0.9813 - 15s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 14s - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0691 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 13s - loss: 0.0721 - accuracy: 0.9805 - val_loss: 0.0671 - val_accuracy: 0.9821 - 13s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 14s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9819 - 14s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.0695 - val_accuracy: 0.9813 - 13s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 12s - loss: 0.0704 - accuracy: 0.9809 - val_loss: 0.0670 - val_accuracy: 0.9817 - 12s/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 12s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0668 - val_accuracy: 0.9818 - 12s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0665 - val_accuracy: 0.9819 - 13s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 15s - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.0651 - val_accuracy: 0.9822 - 15s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 17s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0693 - val_accuracy: 0.9816 - 17s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 14s - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.0648 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 14s - loss: 0.0688 - accuracy: 0.9813 - val_loss: 0.0657 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0653 - val_accuracy: 0.9823 - 13s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0642 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 11s - loss: 0.0679 - accuracy: 0.9816 - val_loss: 0.0644 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 12s - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0651 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 12s - loss: 0.0674 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 11s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0646 - val_accuracy: 0.9824 - 11s/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9817 - val_loss: 0.0647 - val_accuracy: 0.9825 - 12s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0643 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 12s - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.0635 - val_accuracy: 0.9828 - 12s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 12s - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0650 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 12s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 11s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0642 - val_accuracy: 0.9827 - 11s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 12s - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.0641 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 12s - loss: 0.0658 - accuracy: 0.9823 - val_loss: 0.0635 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 11s - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0630 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0639 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 12s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0631 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 13s - loss: 0.0653 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9830 - 13s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9823 - val_loss: 0.0634 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0626 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 11s - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.0628 - val_accuracy: 0.9834 - 11s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 12s - loss: 0.0646 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 11s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0626 - val_accuracy: 0.9833 - 11s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0643 - val_accuracy: 0.9831 - 11s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0630 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 12s - loss: 0.0645 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 12s - loss: 0.0641 - accuracy: 0.9827 - val_loss: 0.0625 - val_accuracy: 0.9833 - 12s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0631 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_2 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_2 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "            ]\n",
    "history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_2],verbose=2, batch_size=512, epochs=100)\n",
    "model_2.save(colab_model_write_path + 'model2.h5')\n",
    "\n",
    "#history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3a'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(256, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3d'),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 22s - loss: 0.1728 - accuracy: 0.9499 - val_loss: 0.0947 - val_accuracy: 0.9748 - 22s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 21s - loss: 0.1002 - accuracy: 0.9733 - val_loss: 0.0837 - val_accuracy: 0.9779 - 21s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 22s - loss: 0.0899 - accuracy: 0.9761 - val_loss: 0.0802 - val_accuracy: 0.9786 - 22s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 21s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0785 - val_accuracy: 0.9797 - 21s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 22s - loss: 0.0819 - accuracy: 0.9781 - val_loss: 0.0752 - val_accuracy: 0.9803 - 22s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 20s - loss: 0.0795 - accuracy: 0.9788 - val_loss: 0.0746 - val_accuracy: 0.9801 - 20s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 20s - loss: 0.0770 - accuracy: 0.9792 - val_loss: 0.0728 - val_accuracy: 0.9806 - 20s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 20s - loss: 0.0756 - accuracy: 0.9796 - val_loss: 0.0732 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 20s - loss: 0.0746 - accuracy: 0.9797 - val_loss: 0.0702 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 23s - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.0695 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 23s - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.0690 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 22s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0688 - val_accuracy: 0.9817 - 22s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 20s - loss: 0.0706 - accuracy: 0.9807 - val_loss: 0.0695 - val_accuracy: 0.9815 - 20s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 21s - loss: 0.0700 - accuracy: 0.9809 - val_loss: 0.0691 - val_accuracy: 0.9814 - 21s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 21s - loss: 0.0693 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9815 - 21s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 21s - loss: 0.0691 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9816 - 21s/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 21s - loss: 0.0681 - accuracy: 0.9814 - val_loss: 0.0658 - val_accuracy: 0.9823 - 21s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 20s - loss: 0.0678 - accuracy: 0.9816 - val_loss: 0.0662 - val_accuracy: 0.9822 - 20s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 20s - loss: 0.0671 - accuracy: 0.9814 - val_loss: 0.0654 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 22s - loss: 0.0666 - accuracy: 0.9817 - val_loss: 0.0672 - val_accuracy: 0.9822 - 22s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 23s - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.0656 - val_accuracy: 0.9825 - 23s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 24s - loss: 0.0656 - accuracy: 0.9820 - val_loss: 0.0659 - val_accuracy: 0.9821 - 24s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 20s - loss: 0.0657 - accuracy: 0.9820 - val_loss: 0.0681 - val_accuracy: 0.9816 - 20s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 20s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0655 - val_accuracy: 0.9824 - 20s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 20s - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.0658 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 23s - loss: 0.0649 - accuracy: 0.9823 - val_loss: 0.0668 - val_accuracy: 0.9824 - 23s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "1704/1704 - 24s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9824 - 24s/epoch - 14ms/step\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_3.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_3 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=2, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "history_3  = model_3.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_3],verbose=2, batch_size=512, epochs=100)\n",
    "model_3.save(colab_model_write_path + 'model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4b'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4d'),\n",
    "      tf.keras.layers.Dense(y_train.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 9s - loss: 0.2432 - accuracy: 0.9265 - val_loss: 0.1163 - val_accuracy: 0.9687 - 9s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 9s - loss: 0.1272 - accuracy: 0.9651 - val_loss: 0.0988 - val_accuracy: 0.9741 - 9s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 8s - loss: 0.1102 - accuracy: 0.9701 - val_loss: 0.0887 - val_accuracy: 0.9766 - 8s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.1018 - accuracy: 0.9725 - val_loss: 0.0856 - val_accuracy: 0.9776 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 8s - loss: 0.0972 - accuracy: 0.9740 - val_loss: 0.0831 - val_accuracy: 0.9785 - 8s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 8s - loss: 0.0933 - accuracy: 0.9749 - val_loss: 0.0786 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 9s - loss: 0.0907 - accuracy: 0.9756 - val_loss: 0.0774 - val_accuracy: 0.9796 - 9s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0891 - accuracy: 0.9760 - val_loss: 0.0768 - val_accuracy: 0.9797 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 9s - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.0757 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 9s - loss: 0.0864 - accuracy: 0.9767 - val_loss: 0.0760 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 9s - loss: 0.0852 - accuracy: 0.9770 - val_loss: 0.0734 - val_accuracy: 0.9800 - 9s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 9s - loss: 0.0844 - accuracy: 0.9772 - val_loss: 0.0743 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0835 - accuracy: 0.9775 - val_loss: 0.0741 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 8s - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.0733 - val_accuracy: 0.9804 - 8s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 0.0823 - accuracy: 0.9777 - val_loss: 0.0718 - val_accuracy: 0.9806 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 8s - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.0718 - val_accuracy: 0.9809 - 8s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.0713 - val_accuracy: 0.9807 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.0714 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 0.0801 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9809 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 8s - loss: 0.0798 - accuracy: 0.9783 - val_loss: 0.0704 - val_accuracy: 0.9812 - 8s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 10s - loss: 0.0792 - accuracy: 0.9785 - val_loss: 0.0699 - val_accuracy: 0.9811 - 10s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 9s - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.0700 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 0.0787 - accuracy: 0.9786 - val_loss: 0.0703 - val_accuracy: 0.9810 - 9s/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 9s - loss: 0.0783 - accuracy: 0.9787 - val_loss: 0.0690 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 0.0780 - accuracy: 0.9788 - val_loss: 0.0692 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 8s - loss: 0.0775 - accuracy: 0.9789 - val_loss: 0.0683 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 8s - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9817 - 8s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.0688 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 14s - loss: 0.0768 - accuracy: 0.9791 - val_loss: 0.0693 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 8s - loss: 0.0768 - accuracy: 0.9790 - val_loss: 0.0677 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 0.0766 - accuracy: 0.9792 - val_loss: 0.0681 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 8s - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.0674 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 0.0757 - accuracy: 0.9794 - val_loss: 0.0677 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 0.0759 - accuracy: 0.9793 - val_loss: 0.0673 - val_accuracy: 0.9816 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 8s - loss: 0.0758 - accuracy: 0.9793 - val_loss: 0.0682 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 11s - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.0680 - val_accuracy: 0.9814 - 11s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 0.0753 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 0.0751 - accuracy: 0.9795 - val_loss: 0.0670 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0678 - val_accuracy: 0.9816 - 11s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0750 - accuracy: 0.9794 - val_loss: 0.0675 - val_accuracy: 0.9821 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0672 - val_accuracy: 0.9818 - 11s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0672 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 0.0741 - accuracy: 0.9798 - val_loss: 0.0660 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 8s - loss: 0.0742 - accuracy: 0.9798 - val_loss: 0.0667 - val_accuracy: 0.9822 - 8s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 13s - loss: 0.0741 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9824 - 13s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0658 - val_accuracy: 0.9824 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 9s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0659 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 8s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0661 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 8s - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.0661 - val_accuracy: 0.9820 - 8s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 0.0736 - accuracy: 0.9798 - val_loss: 0.0655 - val_accuracy: 0.9822 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 9s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0653 - val_accuracy: 0.9823 - 9s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 0.0730 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0667 - val_accuracy: 0.9821 - 8s/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0650 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 11s - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.0650 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0655 - val_accuracy: 0.9825 - 8s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 8s - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.0653 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 9s - loss: 0.0726 - accuracy: 0.9802 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 11s - loss: 0.0725 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 9s - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 8s - loss: 0.0728 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 8s - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0645 - val_accuracy: 0.9826 - 8s/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 9s - loss: 0.0721 - accuracy: 0.9804 - val_loss: 0.0643 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 0.0720 - accuracy: 0.9805 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 9s - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.0649 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0653 - val_accuracy: 0.9823 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 11s - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9829 - 11s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 8s - loss: 0.0715 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 0.0715 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9828 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0643 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 8s - loss: 0.0714 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 9s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0651 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 13s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0648 - val_accuracy: 0.9826 - 13s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 11s - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0643 - val_accuracy: 0.9827 - 11s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9808 - val_loss: 0.0643 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 8s - loss: 0.0710 - accuracy: 0.9806 - val_loss: 0.0645 - val_accuracy: 0.9828 - 8s/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.0639 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9806 - val_loss: 0.0642 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0637 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9807 - val_loss: 0.0638 - val_accuracy: 0.9830 - 8s/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9809 - val_loss: 0.0641 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 11s - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9831 - 11s/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.0640 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0633 - val_accuracy: 0.9831 - 10s/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0627 - val_accuracy: 0.9832 - 8s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9810 - val_loss: 0.0639 - val_accuracy: 0.9826 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0632 - val_accuracy: 0.9831 - 13s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9809 - val_loss: 0.0629 - val_accuracy: 0.9832 - 10s/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 8s - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.0634 - val_accuracy: 0.9831 - 8s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 9s - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.0634 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_4 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_4 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_4, histogram_freq=1)\n",
    "        ]\n",
    "history_4  = model_4.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_4],verbose=2, batch_size=512, epochs=100)\n",
    "model_4.save(colab_model_write_path + 'model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_5 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5c'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5d'),\n",
    "      tf.keras.layers.Dense(y_train_enforce.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 11s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9993 - 11s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 10s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 9s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 10s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 9s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 10s - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 9.8441e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 10s - loss: 9.3665e-04 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 9.2064e-04 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 9s - loss: 9.3356e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 8.7414e-04 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 10s - loss: 8.5468e-04 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 9s - loss: 8.3748e-04 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 10s - loss: 8.6668e-04 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 7.5136e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 10s - loss: 8.0980e-04 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 7.3481e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 9s - loss: 6.9155e-04 - accuracy: 0.9998 - val_loss: 0.0045 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 9s - loss: 7.2576e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 6.4573e-04 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 10s - loss: 7.3001e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 10s - loss: 6.0983e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 6.4264e-04 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 9s - loss: 6.1619e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 6.2433e-04 - accuracy: 0.9998 - val_loss: 0.0053 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 6.3250e-04 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 10s - loss: 5.6048e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 9s - loss: 5.4817e-04 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 5.1804e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 5.7661e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 9s - loss: 5.4797e-04 - accuracy: 0.9999 - val_loss: 0.0085 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 9s - loss: 4.9753e-04 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 9s - loss: 5.4127e-04 - accuracy: 0.9999 - val_loss: 0.0097 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 10s - loss: 5.1966e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 4.7119e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 5.0597e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 10s - loss: 5.3273e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 10s - loss: 5.2568e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 4.7804e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 10s - loss: 4.1050e-04 - accuracy: 0.9999 - val_loss: 0.0120 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 9s - loss: 4.3036e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 9s - loss: 4.2457e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 5.9950e-04 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 10s - loss: 4.3468e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 3.7293e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 10s - loss: 4.0470e-04 - accuracy: 0.9999 - val_loss: 0.0087 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 9s - loss: 4.1268e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 9s - loss: 4.2829e-04 - accuracy: 0.9999 - val_loss: 0.0092 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 10s - loss: 3.5180e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 10s - loss: 3.9473e-04 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 10s - loss: 4.5839e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 10s - loss: 3.0135e-04 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 10s - loss: 4.2675e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 9s - loss: 3.2920e-04 - accuracy: 0.9999 - val_loss: 0.0233 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 10s - loss: 5.3860e-04 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 10s - loss: 3.5807e-04 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 3.6816e-04 - accuracy: 0.9999 - val_loss: 0.0187 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 10s - loss: 4.3158e-04 - accuracy: 0.9999 - val_loss: 0.0179 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 3.8634e-04 - accuracy: 0.9999 - val_loss: 0.0275 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 10s - loss: 4.6297e-04 - accuracy: 0.9999 - val_loss: 0.0335 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 10s - loss: 3.7752e-04 - accuracy: 0.9999 - val_loss: 0.0201 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 4.2812e-04 - accuracy: 0.9999 - val_loss: 0.0134 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 3.7992e-04 - accuracy: 0.9999 - val_loss: 0.0262 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 9s - loss: 3.3662e-04 - accuracy: 0.9999 - val_loss: 0.0195 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 10s - loss: 3.5111e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 3.5474e-04 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 10s - loss: 3.6096e-04 - accuracy: 0.9999 - val_loss: 0.0129 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 10s - loss: 5.7303e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 3.3251e-04 - accuracy: 0.9999 - val_loss: 0.0193 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 9s - loss: 3.9361e-04 - accuracy: 0.9999 - val_loss: 0.0203 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 3.1856e-04 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 10s - loss: 3.0138e-04 - accuracy: 0.9999 - val_loss: 0.0224 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 4.1926e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 14s - loss: 4.1826e-04 - accuracy: 0.9999 - val_loss: 0.0204 - val_accuracy: 0.9994 - 14s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 2.9279e-04 - accuracy: 0.9999 - val_loss: 0.0170 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 9s - loss: 3.0474e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 3.6375e-04 - accuracy: 0.9999 - val_loss: 0.0261 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 10s - loss: 3.9308e-04 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9992 - 10s/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 3.3599e-04 - accuracy: 0.9999 - val_loss: 0.0535 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 10s - loss: 4.3944e-04 - accuracy: 0.9999 - val_loss: 0.0341 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 9s - loss: 3.3641e-04 - accuracy: 0.9999 - val_loss: 0.0285 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 3.7667e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 9s - loss: 3.3478e-04 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 11s - loss: 3.2279e-04 - accuracy: 0.9999 - val_loss: 0.0254 - val_accuracy: 0.9994 - 11s/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 3.8158e-04 - accuracy: 0.9999 - val_loss: 0.0329 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 2.9903e-04 - accuracy: 0.9999 - val_loss: 0.0514 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 3.4784e-04 - accuracy: 0.9999 - val_loss: 0.0336 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 10s - loss: 3.5308e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 3.3192e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 9s - loss: 4.5388e-04 - accuracy: 0.9999 - val_loss: 0.0309 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 9s - loss: 6.0361e-04 - accuracy: 0.9999 - val_loss: 0.0196 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 10s - loss: 3.1968e-04 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_5 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_5 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_5, histogram_freq=1)\n",
    "        ]\n",
    "history_5  = model_5.fit(x_train,y_train_enforce,validation_data=(x_test,y_test_enforce), callbacks=[monitor_5],verbose=2, batch_size=512, epochs=100)\n",
    "model_5.save(colab_model_write_path + 'model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(colab_model_write_path + 'model1_1.h5')\n",
    "model_2.save(colab_model_write_path + 'model1_2.h5')\n",
    "model_3.save(colab_model_write_path + 'model1_3.h5')\n",
    "model_4.save(colab_model_write_path + 'model1_4.h5')\n",
    "model_5.save(colab_model_write_path + 'model1_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model 6 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# #type(y_train)\n",
    "# ydp= pd.DataFrame(y_train)\n",
    "# ydp = tf.argmax(ydp, axis=1)\n",
    "# #ydp = pd.DataFrame(ydp)\n",
    "# #ydp.value_counts\n",
    "# dicts = Counter(ydp.numpy())\n",
    "# dicts\n",
    "\n",
    "# MININUM_SAMPLES = 30000\n",
    "# MAXINUM_SAMPLES = 300000\n",
    "\n",
    "# sample_dict = {2: 793860,\n",
    "#          19: 119826,\n",
    "#          6: 564661,\n",
    "#          15: 21588,\n",
    "#          20: 77352,\n",
    "#          5: 687703,\n",
    "#          4: 3987,\n",
    "#          11: 82959,\n",
    "#          17: 36318,\n",
    "#          10: 3759,\n",
    "#          7: 999,\n",
    "#          9: 562,\n",
    "#          3: 4605,\n",
    "#          16: 233,\n",
    "#          1: 592,\n",
    "#          8: 710,\n",
    "#          13: 71,\n",
    "#          18: 92,\n",
    "#          0: 74,\n",
    "#          12: 45,\n",
    "#          14: 4}\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# #ros = RandomOverSampler(random_state=33)\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "#     sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  MININUM_SAMPLES:\n",
    "#     sample_dict[i] =  MININUM_SAMPLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 30000,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 30000,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 30000,\n",
       " 7: 30000,\n",
       " 9: 30000,\n",
       " 3: 30000,\n",
       " 16: 30000,\n",
       " 1: 30000,\n",
       " 8: 30000,\n",
       " 13: 30000,\n",
       " 18: 30000,\n",
       " 0: 30000,\n",
       " 12: 30000,\n",
       " 14: 30000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "# sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 21588,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 3987,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 3759,\n",
       " 7: 999,\n",
       " 9: 562,\n",
       " 3: 4605,\n",
       " 16: 233,\n",
       " 1: 592,\n",
       " 8: 710,\n",
       " 13: 71,\n",
       " 18: 92,\n",
       " 0: 74,\n",
       " 12: 45,\n",
       " 14: 4}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (871999, 127) (871999, 21)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (555103, 127) (555103, 21)\n"
     ]
    }
   ],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_over,y_train_over = smote.fit_resample(x_train,y_train)\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "MININUM_SAMPLES = 10000\n",
    "MAXINUM_SAMPLES = 100000\n",
    "\n",
    "# sample_dict = {5: 687357,\n",
    "#          2: 794288,\n",
    "#          19: 119905,\n",
    "#          15: 21686,\n",
    "#          6: 564557,\n",
    "#          4: 4025,\n",
    "#          11: 82731,\n",
    "#          20: 77617,\n",
    "#          17: 36205,\n",
    "#          3: 4569,\n",
    "#          10: 3752,\n",
    "#          9: 542,\n",
    "#          7: 968,\n",
    "#          8: 694,\n",
    "#          1: 575,\n",
    "#          16: 239,\n",
    "#          0: 81,\n",
    "#          18: 94,\n",
    "#          13: 69,\n",
    "#          12: 42,\n",
    "#          14: 4}\n",
    "\n",
    "sample_dict = {6: 205290,\n",
    "         2: 288786,\n",
    "         5: 249311,\n",
    "         20: 28278,\n",
    "         19: 43885,\n",
    "         11: 29889,\n",
    "         17: 13051,\n",
    "         3: 1639,\n",
    "         15: 7863,\n",
    "         4: 1436,\n",
    "         10: 1354,\n",
    "         8: 256,\n",
    "         9: 185,\n",
    "         7: 373,\n",
    "         18: 31,\n",
    "         1: 214,\n",
    "         13: 17,\n",
    "         16: 86,\n",
    "         0: 38,\n",
    "         12: 13,\n",
    "         14: 4}\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=33)\n",
    "for i in range(21):\n",
    "  if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "    sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "ros = RandomUnderSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_under, y_train_under = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  16:\n",
    "#     sample_dict[i] =  16\n",
    "\n",
    "# ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "for i in range(21):\n",
    "  if sample_dict[i] <  MININUM_SAMPLES:\n",
    "    sample_dict[i] =  MININUM_SAMPLES\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train_under, y_train_under)\n",
    "\n",
    "# sm = SMOTE(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = sm.fit_resample(X_train_over, y_train_over)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "#6 rd model for stack\n",
    "model_6 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6b'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6d'),\n",
    "      tf.keras.layers.Dense(y_train_over.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1085/1085 - 10s - loss: 0.4190 - accuracy: 0.8622 - val_loss: 0.1915 - val_accuracy: 0.9446 - 10s/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "1085/1085 - 8s - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1437 - val_accuracy: 0.9617 - 8s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "1085/1085 - 8s - loss: 0.1844 - accuracy: 0.9437 - val_loss: 0.1276 - val_accuracy: 0.9676 - 8s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1085/1085 - 9s - loss: 0.1657 - accuracy: 0.9494 - val_loss: 0.1276 - val_accuracy: 0.9701 - 9s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "1085/1085 - 9s - loss: 0.1553 - accuracy: 0.9531 - val_loss: 0.1107 - val_accuracy: 0.9716 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1085/1085 - 8s - loss: 0.1465 - accuracy: 0.9555 - val_loss: 0.1217 - val_accuracy: 0.9720 - 8s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1085/1085 - 9s - loss: 0.1415 - accuracy: 0.9571 - val_loss: 0.1092 - val_accuracy: 0.9733 - 9s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "1085/1085 - 8s - loss: 0.1382 - accuracy: 0.9581 - val_loss: 0.1119 - val_accuracy: 0.9725 - 8s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1085/1085 - 8s - loss: 0.1342 - accuracy: 0.9590 - val_loss: 0.1153 - val_accuracy: 0.9727 - 8s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1085/1085 - 8s - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1051 - val_accuracy: 0.9747 - 8s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1085/1085 - 8s - loss: 0.1297 - accuracy: 0.9604 - val_loss: 0.1044 - val_accuracy: 0.9743 - 8s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1085/1085 - 9s - loss: 0.1272 - accuracy: 0.9611 - val_loss: 0.1036 - val_accuracy: 0.9743 - 9s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1085/1085 - 10s - loss: 0.1258 - accuracy: 0.9614 - val_loss: 0.1045 - val_accuracy: 0.9742 - 10s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1085/1085 - 9s - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1062 - val_accuracy: 0.9747 - 9s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "1085/1085 - 9s - loss: 0.1230 - accuracy: 0.9623 - val_loss: 0.1045 - val_accuracy: 0.9750 - 9s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1085/1085 - 8s - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.1155 - val_accuracy: 0.9726 - 8s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "1085/1085 - 9s - loss: 0.1202 - accuracy: 0.9631 - val_loss: 0.1079 - val_accuracy: 0.9754 - 9s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1085/1085 - 8s - loss: 0.1196 - accuracy: 0.9632 - val_loss: 0.1032 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1085/1085 - 11s - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1034 - val_accuracy: 0.9751 - 11s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "1085/1085 - 8s - loss: 0.1176 - accuracy: 0.9637 - val_loss: 0.0993 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1085/1085 - 8s - loss: 0.1171 - accuracy: 0.9639 - val_loss: 0.0999 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "1085/1085 - 8s - loss: 0.1156 - accuracy: 0.9641 - val_loss: 0.1006 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "1085/1085 - 8s - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.0978 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "1085/1085 - 8s - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.0991 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "1085/1085 - 8s - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.1017 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "1085/1085 - 7s - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.0966 - val_accuracy: 0.9766 - 7s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1085/1085 - 8s - loss: 0.1114 - accuracy: 0.9652 - val_loss: 0.1054 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1085/1085 - 8s - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1019 - val_accuracy: 0.9755 - 8s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1085/1085 - 9s - loss: 0.1110 - accuracy: 0.9654 - val_loss: 0.0986 - val_accuracy: 0.9765 - 9s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1085/1085 - 9s - loss: 0.1107 - accuracy: 0.9656 - val_loss: 0.0987 - val_accuracy: 0.9749 - 9s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "1085/1085 - 8s - loss: 0.1094 - accuracy: 0.9659 - val_loss: 0.1004 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9659 - val_loss: 0.0910 - val_accuracy: 0.9766 - 8s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1085/1085 - 9s - loss: 0.1089 - accuracy: 0.9661 - val_loss: 0.0982 - val_accuracy: 0.9767 - 9s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.1018 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1085/1085 - 8s - loss: 0.1082 - accuracy: 0.9659 - val_loss: 0.0920 - val_accuracy: 0.9768 - 8s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1085/1085 - 8s - loss: 0.1074 - accuracy: 0.9662 - val_loss: 0.0954 - val_accuracy: 0.9770 - 8s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1085/1085 - 7s - loss: 0.1064 - accuracy: 0.9668 - val_loss: 0.0957 - val_accuracy: 0.9769 - 7s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1085/1085 - 7s - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.0974 - val_accuracy: 0.9765 - 7s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1085/1085 - 8s - loss: 0.1063 - accuracy: 0.9666 - val_loss: 0.0905 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1085/1085 - 8s - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.0969 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1085/1085 - 8s - loss: 0.1051 - accuracy: 0.9670 - val_loss: 0.0943 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1085/1085 - 9s - loss: 0.1052 - accuracy: 0.9668 - val_loss: 0.0956 - val_accuracy: 0.9770 - 9s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1085/1085 - 8s - loss: 0.1046 - accuracy: 0.9673 - val_loss: 0.1010 - val_accuracy: 0.9747 - 8s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1085/1085 - 9s - loss: 0.1045 - accuracy: 0.9672 - val_loss: 0.0937 - val_accuracy: 0.9766 - 9s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "1085/1085 - 8s - loss: 0.1038 - accuracy: 0.9674 - val_loss: 0.0895 - val_accuracy: 0.9771 - 8s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1085/1085 - 8s - loss: 0.1039 - accuracy: 0.9675 - val_loss: 0.0934 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9674 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.0939 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1085/1085 - 8s - loss: 0.1027 - accuracy: 0.9676 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1085/1085 - 8s - loss: 0.1024 - accuracy: 0.9679 - val_loss: 0.0930 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1085/1085 - 9s - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.0929 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "1085/1085 - 8s - loss: 0.1022 - accuracy: 0.9678 - val_loss: 0.0942 - val_accuracy: 0.9761 - 8s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1085/1085 - 9s - loss: 0.1019 - accuracy: 0.9679 - val_loss: 0.0939 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1085/1085 - 8s - loss: 0.1014 - accuracy: 0.9681 - val_loss: 0.0909 - val_accuracy: 0.9762 - 8s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "1085/1085 - 7s - loss: 0.1016 - accuracy: 0.9679 - val_loss: 0.0947 - val_accuracy: 0.9756 - 7s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9682 - val_loss: 0.0896 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1085/1085 - 8s - loss: 0.1000 - accuracy: 0.9683 - val_loss: 0.0886 - val_accuracy: 0.9772 - 8s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9683 - val_loss: 0.0883 - val_accuracy: 0.9768 - 8s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1085/1085 - 8s - loss: 0.0998 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "1085/1085 - 8s - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.0933 - val_accuracy: 0.9764 - 8s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1085/1085 - 8s - loss: 0.0997 - accuracy: 0.9685 - val_loss: 0.0921 - val_accuracy: 0.9758 - 8s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1085/1085 - 8s - loss: 0.0987 - accuracy: 0.9687 - val_loss: 0.0840 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "1085/1085 - 8s - loss: 0.0992 - accuracy: 0.9687 - val_loss: 0.0926 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "1085/1085 - 8s - loss: 0.0984 - accuracy: 0.9689 - val_loss: 0.0934 - val_accuracy: 0.9742 - 8s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9779 - 8s/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0879 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0921 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "1085/1085 - 8s - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.0925 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0913 - val_accuracy: 0.9773 - 8s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1085/1085 - 8s - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.0864 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "1085/1085 - 8s - loss: 0.0974 - accuracy: 0.9690 - val_loss: 0.0918 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9692 - val_loss: 0.0850 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9694 - val_loss: 0.0883 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1085/1085 - 8s - loss: 0.0961 - accuracy: 0.9694 - val_loss: 0.0846 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "1085/1085 - 8s - loss: 0.0964 - accuracy: 0.9695 - val_loss: 0.0855 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "1085/1085 - 8s - loss: 0.0962 - accuracy: 0.9696 - val_loss: 0.0915 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "1085/1085 - 8s - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.0859 - val_accuracy: 0.9782 - 8s/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "1085/1085 - 10s - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.0877 - val_accuracy: 0.9776 - 10s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "1085/1085 - 8s - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.0887 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "1085/1085 - 8s - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.0872 - val_accuracy: 0.9769 - 8s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9701 - val_loss: 0.0898 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "1085/1085 - 8s - loss: 0.0950 - accuracy: 0.9696 - val_loss: 0.0867 - val_accuracy: 0.9775 - 8s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.0891 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9699 - val_loss: 0.0894 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.0859 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9700 - val_loss: 0.0843 - val_accuracy: 0.9785 - 8s/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "1085/1085 - 8s - loss: 0.0945 - accuracy: 0.9701 - val_loss: 0.0845 - val_accuracy: 0.9786 - 8s/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "1085/1085 - 8s - loss: 0.0942 - accuracy: 0.9700 - val_loss: 0.0869 - val_accuracy: 0.9780 - 8s/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "1085/1085 - 9s - loss: 0.0937 - accuracy: 0.9703 - val_loss: 0.0865 - val_accuracy: 0.9768 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1085/1085 - 8s - loss: 0.0938 - accuracy: 0.9703 - val_loss: 0.0863 - val_accuracy: 0.9777 - 8s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0886 - val_accuracy: 0.9773 - 8s/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0921 - val_accuracy: 0.9744 - 8s/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "1085/1085 - 8s - loss: 0.0932 - accuracy: 0.9704 - val_loss: 0.0864 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "1085/1085 - 8s - loss: 0.0937 - accuracy: 0.9704 - val_loss: 0.0868 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "1085/1085 - 7s - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9784 - 7s/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0870 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "1085/1085 - 7s - loss: 0.0926 - accuracy: 0.9706 - val_loss: 0.0887 - val_accuracy: 0.9749 - 7s/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "1085/1085 - 8s - loss: 0.0925 - accuracy: 0.9706 - val_loss: 0.0820 - val_accuracy: 0.9792 - 8s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_6 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_6 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_6, histogram_freq=1)\n",
    "        ]\n",
    "history_6  = model_6.fit(X_train_over,y_train_over,validation_data=(x_test,y_test), callbacks=[monitor_6],verbose=2, batch_size=512, epochs=100)\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_model_write_path\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "https://abstractask.tistory.com/105\n",
    "\n",
    "Model #1, Model #2, Model #3, + OverSampling/UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "# for both logistic and nueral\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "#\t\tcolab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "\t\t#model_4.save(colab_path + 'model4.h5')\n",
    "\t\tif i != 4 and i != 5: #Model4와 Binary 배제\n",
    "\t\t\tfilename = colab_model_write_path + 'model1_' + str(i + 1) + '.h5'\n",
    "\t\t\t# load model from file\n",
    "\t\t\tmodel = load_model(filename,custom_objects=None)\n",
    "\t\t\t# add to list of members\n",
    "\t\t\tall_models.append(model)\n",
    "\t\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "#neural\n",
    "\n",
    "def define_stacked_model(members):\n",
    "\tinitializer = tf.keras.initializers.GlorotUniform(seed=64)\n",
    "\tconstraints = None\n",
    "\n",
    "  # update all layers in all models to not be trainable\n",
    "\tfor i in range(len(members)):\n",
    "\t\tmodel = members[i]\n",
    "\t\tfor layer in model.layers:\n",
    "\t\t\t# make not trainable\n",
    "\t\t\tlayer.trainable = False\n",
    "\t\t\t# rename to avoid 'unique layer name' issue\n",
    "\t\t\tlayer._name = 'ensemble_' + str(i + 1) + '_' + layer.name\n",
    "\n",
    "\n",
    "\t# define multi-headed input\n",
    "\tensemble_visible = [model.input for model in members]\n",
    "\t# concatenate merge output from each model\n",
    "\tensemble_outputs = [model.output for model in members]\n",
    "\tmerge = concatenate(ensemble_outputs)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_ea\")(merge)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_eb\")(merge)\n",
    "\toutput = Dense(Y.shape[1], kernel_initializer=initializer, activation='softmax',name=\"dense_ec\")(merge)\n",
    "\tmodel = Model(inputs=ensemble_visible, outputs=output)\n",
    "\t# plot graph of ensemble\n",
    "\tplot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "\t# compile\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "#neural\n",
    "import datetime\n",
    "\n",
    "\n",
    "#colab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_7= [\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "\n",
    "def fit_stacked_model(model, inputX, inputy_enc):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# encode output data\n",
    "#\tinputy_enc = to_categorical(inputy)\n",
    "\t# fit model\n",
    "\thistory_7=model.fit(X, inputy_enc, epochs=60, verbose=2,callbacks=[monitor_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a stacked model\n",
    "#neural\n",
    "def predict_stacked_model(model, inputX):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# make prediction\n",
    "\treturn model.predict(X, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded /home/marius1406/20231010221344/model1_1.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_2.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_3.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_4.h5\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "#neural\n",
    "\n",
    "colab_model_write_path = colab_write_path + \"20231010221344/\"\n",
    "\n",
    "from keras.models import load_model\n",
    "n_members = 6\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_2a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_3a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_4a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_1a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2a (Dense)    (None, 64)           8192        ['dense_2a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3a (Dense)    (None, 512)          65536       ['dense_3a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_4_dense_4a (Dense)    (None, 128)          16384       ['dense_4a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1a (Dense)    (None, 64)           8192        ['dense_1a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2b (Dense)    (None, 128)          8320        ['ensemble_2_dense_2a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_11 (Dropout  (None, 512)         0           ['ensemble_3_dense_3a[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_14 (Dropout  (None, 128)         0           ['ensemble_4_dense_4a[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1b (Dense)    (None, 128)          8320        ['ensemble_1_dense_1a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_8 (Dropout)  (None, 128)         0           ['ensemble_2_dense_2b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3b (Dense)    (None, 256)          131328      ['ensemble_3_dropout_11[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_4b (Dense)    (None, 64)           8256        ['ensemble_4_dropout_14[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_6 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2c (Dense)    (None, 256)          33024       ['ensemble_2_dropout_8[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_12 (Dropout  (None, 256)         0           ['ensemble_3_dense_3b[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_15 (Dropout  (None, 64)          0           ['ensemble_4_dense_4b[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1c (Dense)    (None, 128)          16512       ['ensemble_1_dropout_6[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_9 (Dropout)  (None, 256)         0           ['ensemble_2_dense_2c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3c (Dense)    (None, 128)          32896       ['ensemble_3_dropout_12[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_4c (Dense)    (None, 64)           4160        ['ensemble_4_dropout_15[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_7 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2d (Dense)    (None, 128)          32896       ['ensemble_2_dropout_9[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_13 (Dropout  (None, 128)         0           ['ensemble_3_dense_3c[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_16 (Dropout  (None, 64)          0           ['ensemble_4_dense_4c[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1d (Dense)    (None, 64)           8256        ['ensemble_1_dropout_7[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_10 (Dropout  (None, 128)         0           ['ensemble_2_dense_2d[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3d (Dense)    (None, 128)          16512       ['ensemble_3_dropout_13[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_4d (Dense)    (None, 128)          8320        ['ensemble_4_dropout_16[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_1_dense_2 (Dense)     (None, 21)           1365        ['ensemble_1_dense_1d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_3 (Dense)     (None, 21)           2709        ['ensemble_2_dropout_10[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_3_dense_4 (Dense)     (None, 21)           2709        ['ensemble_3_dense_3d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_4_dense_5 (Dense)     (None, 21)           2709        ['ensemble_4_dense_4d[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 84)           0           ['ensemble_1_dense_2[0][0]',     \n",
      "                                                                  'ensemble_2_dense_3[0][0]',     \n",
      "                                                                  'ensemble_3_dense_4[0][0]',     \n",
      "                                                                  'ensemble_4_dense_5[0][0]']     \n",
      "                                                                                                  \n",
      " dense_ea (Dense)               (None, 128)          10880       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_eb (Dense)               (None, 128)          16512       ['dense_ea[0][0]']               \n",
      "                                                                                                  \n",
      " dense_ec (Dense)               (None, 21)           2709        ['dense_eb[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 446,697\n",
      "Trainable params: 30,101\n",
      "Non-trainable params: 416,596\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define ensemble model\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.utils import plot_model\n",
    "#neural\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "27250/27250 - 73s - loss: 0.0682 - accuracy: 0.9837 - 73s/epoch - 3ms/step\n",
      "Epoch 2/60\n",
      "27250/27250 - 69s - loss: 0.0617 - accuracy: 0.9842 - 69s/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "27250/27250 - 70s - loss: 0.0613 - accuracy: 0.9842 - 70s/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "27250/27250 - 71s - loss: 0.0607 - accuracy: 0.9843 - 71s/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "27250/27250 - 70s - loss: 0.0606 - accuracy: 0.9844 - 70s/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "27250/27250 - 70s - loss: 0.0602 - accuracy: 0.9844 - 70s/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "27250/27250 - 69s - loss: 0.0605 - accuracy: 0.9845 - 69s/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "27250/27250 - 70s - loss: 0.0602 - accuracy: 0.9844 - 70s/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "27250/27250 - 69s - loss: 0.0602 - accuracy: 0.9845 - 69s/epoch - 3ms/step\n",
      "Epoch 10/60\n",
      "27250/27250 - 70s - loss: 0.0604 - accuracy: 0.9844 - 70s/epoch - 3ms/step\n",
      "Epoch 11/60\n",
      "27250/27250 - 69s - loss: 0.0603 - accuracy: 0.9844 - 69s/epoch - 3ms/step\n",
      "Epoch 12/60\n",
      "27250/27250 - 69s - loss: 0.0604 - accuracy: 0.9844 - 69s/epoch - 3ms/step\n",
      "Epoch 13/60\n",
      "27250/27250 - 69s - loss: 0.0604 - accuracy: 0.9845 - 69s/epoch - 3ms/step\n",
      "Epoch 14/60\n",
      "27250/27250 - 70s - loss: 0.0608 - accuracy: 0.9844 - 70s/epoch - 3ms/step\n",
      "Epoch 15/60\n",
      "27250/27250 - 70s - loss: 0.0605 - accuracy: 0.9844 - 70s/epoch - 3ms/step\n",
      "Epoch 16/60\n",
      "27250/27250 - 69s - loss: 0.0606 - accuracy: 0.9843 - 69s/epoch - 3ms/step\n",
      "Epoch 17/60\n",
      "27250/27250 - 68s - loss: 0.0616 - accuracy: 0.9844 - 68s/epoch - 3ms/step\n",
      "Epoch 18/60\n",
      "27250/27250 - 70s - loss: 0.0603 - accuracy: 0.9845 - 70s/epoch - 3ms/step\n",
      "Epoch 19/60\n",
      "27250/27250 - 69s - loss: 0.0607 - accuracy: 0.9844 - 69s/epoch - 3ms/step\n",
      "Epoch 20/60\n",
      "27250/27250 - 72s - loss: 0.0609 - accuracy: 0.9845 - 72s/epoch - 3ms/step\n",
      "Epoch 21/60\n",
      "27250/27250 - 73s - loss: 0.0616 - accuracy: 0.9843 - 73s/epoch - 3ms/step\n",
      "Epoch 22/60\n",
      "27250/27250 - 75s - loss: 0.0609 - accuracy: 0.9843 - 75s/epoch - 3ms/step\n",
      "Epoch 23/60\n",
      "27250/27250 - 70s - loss: 0.0611 - accuracy: 0.9843 - 70s/epoch - 3ms/step\n",
      "Epoch 24/60\n",
      "27250/27250 - 73s - loss: 0.0615 - accuracy: 0.9843 - 73s/epoch - 3ms/step\n",
      "Epoch 25/60\n",
      "27250/27250 - 76s - loss: 0.0610 - accuracy: 0.9843 - 76s/epoch - 3ms/step\n",
      "Epoch 26/60\n",
      "27250/27250 - 77s - loss: 0.0607 - accuracy: 0.9844 - 77s/epoch - 3ms/step\n",
      "Epoch 27/60\n",
      "27250/27250 - 77s - loss: 0.0615 - accuracy: 0.9843 - 77s/epoch - 3ms/step\n",
      "Epoch 28/60\n",
      "27250/27250 - 77s - loss: 0.0619 - accuracy: 0.9844 - 77s/epoch - 3ms/step\n",
      "Epoch 29/60\n",
      "27250/27250 - 79s - loss: 0.0618 - accuracy: 0.9844 - 79s/epoch - 3ms/step\n",
      "Epoch 30/60\n",
      "27250/27250 - 75s - loss: 0.0621 - accuracy: 0.9843 - 75s/epoch - 3ms/step\n",
      "Epoch 31/60\n",
      "27250/27250 - 73s - loss: 0.0612 - accuracy: 0.9842 - 73s/epoch - 3ms/step\n",
      "Epoch 32/60\n",
      "27250/27250 - 75s - loss: 0.0630 - accuracy: 0.9843 - 75s/epoch - 3ms/step\n",
      "Epoch 33/60\n",
      "27250/27250 - 74s - loss: 0.0615 - accuracy: 0.9842 - 74s/epoch - 3ms/step\n",
      "Epoch 34/60\n",
      "27250/27250 - 76s - loss: 0.0635 - accuracy: 0.9842 - 76s/epoch - 3ms/step\n",
      "Epoch 35/60\n",
      "27250/27250 - 74s - loss: 0.0611 - accuracy: 0.9843 - 74s/epoch - 3ms/step\n",
      "Epoch 36/60\n",
      "27250/27250 - 74s - loss: 0.0622 - accuracy: 0.9843 - 74s/epoch - 3ms/step\n",
      "Epoch 37/60\n",
      "27250/27250 - 75s - loss: 0.0621 - accuracy: 0.9842 - 75s/epoch - 3ms/step\n",
      "Epoch 38/60\n",
      "27250/27250 - 77s - loss: 0.0626 - accuracy: 0.9842 - 77s/epoch - 3ms/step\n",
      "Epoch 39/60\n",
      "27250/27250 - 74s - loss: 0.0621 - accuracy: 0.9842 - 74s/epoch - 3ms/step\n",
      "Epoch 40/60\n",
      "27250/27250 - 69s - loss: 0.0624 - accuracy: 0.9842 - 69s/epoch - 3ms/step\n",
      "Epoch 41/60\n",
      "27250/27250 - 71s - loss: 0.0637 - accuracy: 0.9842 - 71s/epoch - 3ms/step\n",
      "Epoch 42/60\n",
      "27250/27250 - 71s - loss: 0.0631 - accuracy: 0.9843 - 71s/epoch - 3ms/step\n",
      "Epoch 43/60\n",
      "27250/27250 - 69s - loss: 0.0624 - accuracy: 0.9842 - 69s/epoch - 3ms/step\n",
      "Epoch 44/60\n",
      "27250/27250 - 71s - loss: 0.0622 - accuracy: 0.9842 - 71s/epoch - 3ms/step\n",
      "Epoch 45/60\n",
      "27250/27250 - 69s - loss: 0.0620 - accuracy: 0.9842 - 69s/epoch - 3ms/step\n",
      "Epoch 46/60\n",
      "27250/27250 - 69s - loss: 0.0626 - accuracy: 0.9841 - 69s/epoch - 3ms/step\n",
      "Epoch 47/60\n",
      "27250/27250 - 73s - loss: 0.0640 - accuracy: 0.9841 - 73s/epoch - 3ms/step\n",
      "Epoch 48/60\n",
      "27250/27250 - 75s - loss: 0.0625 - accuracy: 0.9841 - 75s/epoch - 3ms/step\n",
      "Epoch 49/60\n",
      "27250/27250 - 76s - loss: 0.0640 - accuracy: 0.9841 - 76s/epoch - 3ms/step\n",
      "Epoch 50/60\n",
      "27250/27250 - 74s - loss: 0.0630 - accuracy: 0.9841 - 74s/epoch - 3ms/step\n",
      "Epoch 51/60\n",
      "27250/27250 - 76s - loss: 0.0634 - accuracy: 0.9842 - 76s/epoch - 3ms/step\n",
      "Epoch 52/60\n",
      "27250/27250 - 70s - loss: 0.0635 - accuracy: 0.9841 - 70s/epoch - 3ms/step\n",
      "Epoch 53/60\n",
      "27250/27250 - 76s - loss: 0.0639 - accuracy: 0.9841 - 76s/epoch - 3ms/step\n",
      "Epoch 54/60\n",
      "27250/27250 - 78s - loss: 0.0639 - accuracy: 0.9840 - 78s/epoch - 3ms/step\n",
      "Epoch 55/60\n",
      "27250/27250 - 75s - loss: 0.0640 - accuracy: 0.9841 - 75s/epoch - 3ms/step\n",
      "Epoch 56/60\n",
      "27250/27250 - 79s - loss: 0.0632 - accuracy: 0.9840 - 79s/epoch - 3ms/step\n",
      "Epoch 57/60\n",
      "27250/27250 - 76s - loss: 0.0633 - accuracy: 0.9840 - 76s/epoch - 3ms/step\n",
      "Epoch 58/60\n",
      "27250/27250 - 74s - loss: 0.0662 - accuracy: 0.9841 - 74s/epoch - 3ms/step\n",
      "Epoch 59/60\n",
      "27250/27250 - 73s - loss: 0.0636 - accuracy: 0.9840 - 73s/epoch - 3ms/step\n",
      "Epoch 60/60\n",
      "27250/27250 - 73s - loss: 0.0654 - accuracy: 0.9840 - 73s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "fit_stacked_model(stacked_model, x_train,y_train)\n",
    "stacked_model.save(colab_model_write_path + 'stacked_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 13s - 13s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       1.00      0.92      0.96        51\n",
      "           2       0.99      0.99      0.99     72091\n",
      "           3       1.00      1.00      1.00       433\n",
      "           4       1.00      0.97      0.98       365\n",
      "           5       0.99      0.99      0.99     62503\n",
      "           6       0.98      0.99      0.99     51385\n",
      "           7       0.41      0.63      0.50        78\n",
      "           8       0.40      0.52      0.45        67\n",
      "           9       1.00      0.69      0.82        62\n",
      "          10       0.97      0.19      0.31       349\n",
      "          11       0.98      0.94      0.96      7418\n",
      "          12       1.00      0.40      0.57         5\n",
      "          13       0.86      0.67      0.75         9\n",
      "          15       0.90      0.71      0.80      1989\n",
      "          16       0.86      0.35      0.50        17\n",
      "          17       0.92      0.92      0.92      3272\n",
      "          18       1.00      0.60      0.75        15\n",
      "          19       0.97      0.97      0.97     10833\n",
      "          20       0.92      0.98      0.95      7055\n",
      "\n",
      "    accuracy                           0.98    218000\n",
      "   macro avg       0.86      0.72      0.76    218000\n",
      "weighted avg       0.98      0.98      0.98    218000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00         3\\n           1       1.00      0.92      0.96        51\\n           2       0.99      0.99      0.99     72091\\n           3       1.00      1.00      1.00       433\\n           4       1.00      0.97      0.98       365\\n           5       0.99      0.99      0.99     62503\\n           6       0.98      0.99      0.99     51385\\n           7       0.41      0.63      0.50        78\\n           8       0.40      0.52      0.45        67\\n           9       1.00      0.69      0.82        62\\n          10       0.97      0.19      0.31       349\\n          11       0.98      0.94      0.96      7418\\n          12       1.00      0.40      0.57         5\\n          13       0.86      0.67      0.75         9\\n          15       0.90      0.71      0.80      1989\\n          16       0.86      0.35      0.50        17\\n          17       0.92      0.92      0.92      3272\\n          18       1.00      0.60      0.75        15\\n          19       0.97      0.97      0.97     10833\\n          20       0.92      0.98      0.95      7055\\n\\n    accuracy                           0.98    218000\\n   macro avg       0.86      0.72      0.76    218000\\nweighted avg       0.98      0.98      0.98    218000\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_1, yhat_val))\n",
    "classification_report(y_test_1, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 11s - 11s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5099c649d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 predict 수행\n",
    "# 모델 성능 - confusion matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test_1, y_pred=yhat_val)\n",
    "conf_mat\n",
    "\n",
    "disp = ConfusionMatrixDisplay(conf_mat)\n",
    "#disp = ConfusionMatrixDisplay(conf_mat)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
