{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 17:50:56.013826: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 기본라이브러리 import\n",
    "#from google.colab import drive\n",
    "#import os, json, pickle\n",
    "#import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# 파이토치 라이브러리 import\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "#Keras Import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import ipaddress\n",
    "\n",
    "# 구글 드라이브 mount\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# 데이터 파일 위치\n",
    "#C:\\Users\\mariu\\내 드라이브\\Colab Notebooks\\Network\n",
    "colab_path = '/home/marius1406/'\n",
    "colab_write_path = \"/home/marius1406/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_path = \"/home/marius1406/\"\n",
    "df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False, nrows=1089999)\n",
    "#df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장판에서 사용\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'DNS_QUERY_ID','Label','Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR_1','IPV4_SRC_ADDR_2','Label','Attack','Dataset', 'Label_1','Attack_1','Dataset_1', 'Label_2','Attack_2','Dataset_2'])  #명목형변수, 레이블 변수 제외\n",
    "cols = df.columns.drop(['Label','Attack'])  #명목형변수, 레이블 변수 제외#cols = df.columns.drop(['Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "X = df[cols]\n",
    "dummies = pd.get_dummies(df['Attack']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "Y = dummies.values\n",
    "\n",
    "#==================\n",
    "dummiesLabel = pd.get_dummies(df['Label']) # Classification\n",
    "y_1_label = df['Label'].values\n",
    "y_label = dummiesLabel.values\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "def extend_sparse(val):\n",
    "    if val in ['Analysis', 'Exploits', 'Fuzzers', 'Shellcode', 'Theft', 'Worms', 'mitm']: return 1\n",
    "    return 0\n",
    "\n",
    "y_1_attack = pd.DataFrame(df['Attack'])\n",
    "\n",
    "is_sparse = y_1_attack.applymap(extend_sparse)\n",
    "y_1_enforce = is_sparse.values\n",
    "y_enforce = pd.get_dummies(is_sparse['Attack']) # Classification\n",
    "\n",
    "#=======================\n",
    "\n",
    "def max_8G(val):\n",
    "    if (val > 1.0e+9): return 1.0e+9\n",
    "    return val\n",
    "\n",
    "#cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT']\n",
    "cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "'DST_TO_SRC_SECOND_BYTES_1', 'SRC_TO_DST_SECOND_BYTES_1', 'SRC_TO_DST_AVG_THROUGHPUT_1', 'DST_TO_SRC_AVG_THROUGHPUT_1',\n",
    "'DST_TO_SRC_SECOND_BYTES_2', 'SRC_TO_DST_SECOND_BYTES_2', 'SRC_TO_DST_AVG_THROUGHPUT_2', 'DST_TO_SRC_AVG_THROUGHPUT_2'] \n",
    "\n",
    "X[cols] = X[cols].applymap(max_8G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 4291722866\n",
      "L4_SRC_PORT 65535\n",
      "IPV4_DST_ADDR 4294967295\n",
      "L4_DST_PORT 65535\n",
      "PROTOCOL 254\n",
      "L7_PROTO 248.0\n",
      "IN_BYTES 34641563\n",
      "IN_PKTS 123763\n",
      "OUT_BYTES 129573662\n",
      "OUT_PKTS 87179\n",
      "TCP_FLAGS 223\n",
      "CLIENT_TCP_FLAGS 223\n",
      "SERVER_TCP_FLAGS 223\n",
      "FLOW_DURATION_MILLISECONDS 4294967\n",
      "DURATION_IN 105400\n",
      "DURATION_OUT 38547\n",
      "MIN_TTL 255\n",
      "MAX_TTL 255\n",
      "LONGEST_FLOW_PKT 7292\n",
      "SHORTEST_FLOW_PKT 1504\n",
      "MIN_IP_PKT_LEN 547\n",
      "MAX_IP_PKT_LEN 7292\n",
      "SRC_TO_DST_SECOND_BYTES 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES 6321251\n",
      "RETRANSMITTED_IN_PKTS 4774\n",
      "RETRANSMITTED_OUT_BYTES 2183347\n",
      "RETRANSMITTED_OUT_PKTS 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES 191858\n",
      "NUM_PKTS_128_TO_256_BYTES 7230\n",
      "NUM_PKTS_256_TO_512_BYTES 4921\n",
      "NUM_PKTS_512_TO_1024_BYTES 34443\n",
      "NUM_PKTS_1024_TO_1514_BYTES 86096\n",
      "TCP_WIN_MAX_IN 65535\n",
      "TCP_WIN_MAX_OUT 65535\n",
      "ICMP_TYPE 65280\n",
      "ICMP_IPV4_TYPE 255\n",
      "DNS_QUERY_ID 65535\n",
      "DNS_QUERY_TYPE 32769\n",
      "DNS_TTL_ANSWER 4294915672\n",
      "FTP_COMMAND_RET_CODE 550.0\n",
      "L4_SRC_PORT_1 65535\n",
      "IPV4_DST_ADDR_1 4294967295\n",
      "L4_DST_PORT_1 65535\n",
      "PROTOCOL_1 254\n",
      "L7_PROTO_1 248.0\n",
      "IN_BYTES_1 32341314\n",
      "IN_PKTS_1 123763\n",
      "OUT_BYTES_1 129573662\n",
      "OUT_PKTS_1 87179\n",
      "TCP_FLAGS_1 223\n",
      "CLIENT_TCP_FLAGS_1 223\n",
      "SERVER_TCP_FLAGS_1 223\n",
      "FLOW_DURATION_MILLISECONDS_1 4294967\n",
      "DURATION_IN_1 105400\n",
      "DURATION_OUT_1 38547\n",
      "MIN_TTL_1 255\n",
      "MAX_TTL_1 255\n",
      "LONGEST_FLOW_PKT_1 7292\n",
      "SHORTEST_FLOW_PKT_1 1504\n",
      "MIN_IP_PKT_LEN_1 547\n",
      "MAX_IP_PKT_LEN_1 7292\n",
      "SRC_TO_DST_SECOND_BYTES_1 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_1 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_1 6321251\n",
      "RETRANSMITTED_IN_PKTS_1 4774\n",
      "RETRANSMITTED_OUT_BYTES_1 2183347\n",
      "RETRANSMITTED_OUT_PKTS_1 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_1 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_1 3406\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 18388\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 86096\n",
      "TCP_WIN_MAX_IN_1 65535\n",
      "TCP_WIN_MAX_OUT_1 65535\n",
      "ICMP_TYPE_1 65280\n",
      "ICMP_IPV4_TYPE_1 255\n",
      "DNS_QUERY_ID_1 65535\n",
      "DNS_QUERY_TYPE_1 32769\n",
      "DNS_TTL_ANSWER_1 4294915672\n",
      "FTP_COMMAND_RET_CODE_1 550.0\n",
      "L4_SRC_PORT_2 65535\n",
      "IPV4_DST_ADDR_2 4294967295\n",
      "L4_DST_PORT_2 65535\n",
      "PROTOCOL_2 254\n",
      "L7_PROTO_2 245.178\n",
      "IN_BYTES_2 33337052\n",
      "IN_PKTS_2 123763\n",
      "OUT_BYTES_2 129573662\n",
      "OUT_PKTS_2 87179\n",
      "TCP_FLAGS_2 223\n",
      "CLIENT_TCP_FLAGS_2 223\n",
      "SERVER_TCP_FLAGS_2 223\n",
      "FLOW_DURATION_MILLISECONDS_2 4294967\n",
      "DURATION_IN_2 105400\n",
      "DURATION_OUT_2 38547\n",
      "MIN_TTL_2 255\n",
      "MAX_TTL_2 255\n",
      "LONGEST_FLOW_PKT_2 7292\n",
      "SHORTEST_FLOW_PKT_2 1504\n",
      "MIN_IP_PKT_LEN_2 422\n",
      "MAX_IP_PKT_LEN_2 7292\n",
      "SRC_TO_DST_SECOND_BYTES_2 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_2 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_2 6321251\n",
      "RETRANSMITTED_IN_PKTS_2 4774\n",
      "RETRANSMITTED_OUT_BYTES_2 1109291\n",
      "RETRANSMITTED_OUT_PKTS_2 824\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_2 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_2 3446\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 18954\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 86096\n",
      "TCP_WIN_MAX_IN_2 65535\n",
      "TCP_WIN_MAX_OUT_2 65535\n",
      "ICMP_TYPE_2 65280\n",
      "ICMP_IPV4_TYPE_2 255\n",
      "DNS_QUERY_ID_2 65535\n",
      "DNS_QUERY_TYPE_2 32769\n",
      "DNS_TTL_ANSWER_2 4294915672\n",
      "FTP_COMMAND_RET_CODE_2 550.0\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scaler_train = preprocessing.StandardScaler()\n",
    "scaler_train = scaler_train.fit(X)\n",
    "X = pd.DataFrame(scaler_train.transform(X),index=np.arange(0,X.shape[0],1), columns = X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 0\n",
      "L4_SRC_PORT 0\n",
      "IPV4_DST_ADDR 0\n",
      "L4_DST_PORT 0\n",
      "PROTOCOL 0\n",
      "L7_PROTO 0\n",
      "IN_BYTES 0\n",
      "IN_PKTS 0\n",
      "OUT_BYTES 0\n",
      "OUT_PKTS 0\n",
      "TCP_FLAGS 0\n",
      "CLIENT_TCP_FLAGS 0\n",
      "SERVER_TCP_FLAGS 0\n",
      "FLOW_DURATION_MILLISECONDS 0\n",
      "DURATION_IN 0\n",
      "DURATION_OUT 0\n",
      "MIN_TTL 0\n",
      "MAX_TTL 0\n",
      "LONGEST_FLOW_PKT 0\n",
      "SHORTEST_FLOW_PKT 0\n",
      "MIN_IP_PKT_LEN 0\n",
      "MAX_IP_PKT_LEN 0\n",
      "SRC_TO_DST_SECOND_BYTES 0\n",
      "DST_TO_SRC_SECOND_BYTES 0\n",
      "RETRANSMITTED_IN_BYTES 0\n",
      "RETRANSMITTED_IN_PKTS 0\n",
      "RETRANSMITTED_OUT_BYTES 0\n",
      "RETRANSMITTED_OUT_PKTS 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 0\n",
      "NUM_PKTS_UP_TO_128_BYTES 0\n",
      "NUM_PKTS_128_TO_256_BYTES 0\n",
      "NUM_PKTS_256_TO_512_BYTES 0\n",
      "NUM_PKTS_512_TO_1024_BYTES 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES 0\n",
      "TCP_WIN_MAX_IN 0\n",
      "TCP_WIN_MAX_OUT 0\n",
      "ICMP_TYPE 0\n",
      "ICMP_IPV4_TYPE 0\n",
      "DNS_QUERY_ID 0\n",
      "DNS_QUERY_TYPE 0\n",
      "DNS_TTL_ANSWER 0\n",
      "FTP_COMMAND_RET_CODE 0\n",
      "L4_SRC_PORT_1 0\n",
      "IPV4_DST_ADDR_1 0\n",
      "L4_DST_PORT_1 0\n",
      "PROTOCOL_1 0\n",
      "L7_PROTO_1 0\n",
      "IN_BYTES_1 0\n",
      "IN_PKTS_1 0\n",
      "OUT_BYTES_1 0\n",
      "OUT_PKTS_1 0\n",
      "TCP_FLAGS_1 0\n",
      "CLIENT_TCP_FLAGS_1 0\n",
      "SERVER_TCP_FLAGS_1 0\n",
      "FLOW_DURATION_MILLISECONDS_1 0\n",
      "DURATION_IN_1 0\n",
      "DURATION_OUT_1 0\n",
      "MIN_TTL_1 0\n",
      "MAX_TTL_1 0\n",
      "LONGEST_FLOW_PKT_1 0\n",
      "SHORTEST_FLOW_PKT_1 0\n",
      "MIN_IP_PKT_LEN_1 0\n",
      "MAX_IP_PKT_LEN_1 0\n",
      "SRC_TO_DST_SECOND_BYTES_1 0\n",
      "DST_TO_SRC_SECOND_BYTES_1 0\n",
      "RETRANSMITTED_IN_BYTES_1 0\n",
      "RETRANSMITTED_IN_PKTS_1 0\n",
      "RETRANSMITTED_OUT_BYTES_1 0\n",
      "RETRANSMITTED_OUT_PKTS_1 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 0\n",
      "NUM_PKTS_128_TO_256_BYTES_1 0\n",
      "NUM_PKTS_256_TO_512_BYTES_1 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 0\n",
      "TCP_WIN_MAX_IN_1 0\n",
      "TCP_WIN_MAX_OUT_1 0\n",
      "ICMP_TYPE_1 0\n",
      "ICMP_IPV4_TYPE_1 0\n",
      "DNS_QUERY_ID_1 0\n",
      "DNS_QUERY_TYPE_1 0\n",
      "DNS_TTL_ANSWER_1 0\n",
      "FTP_COMMAND_RET_CODE_1 0\n",
      "L4_SRC_PORT_2 0\n",
      "IPV4_DST_ADDR_2 0\n",
      "L4_DST_PORT_2 0\n",
      "PROTOCOL_2 0\n",
      "L7_PROTO_2 0\n",
      "IN_BYTES_2 0\n",
      "IN_PKTS_2 0\n",
      "OUT_BYTES_2 0\n",
      "OUT_PKTS_2 0\n",
      "TCP_FLAGS_2 0\n",
      "CLIENT_TCP_FLAGS_2 0\n",
      "SERVER_TCP_FLAGS_2 0\n",
      "FLOW_DURATION_MILLISECONDS_2 0\n",
      "DURATION_IN_2 0\n",
      "DURATION_OUT_2 0\n",
      "MIN_TTL_2 0\n",
      "MAX_TTL_2 0\n",
      "LONGEST_FLOW_PKT_2 0\n",
      "SHORTEST_FLOW_PKT_2 0\n",
      "MIN_IP_PKT_LEN_2 0\n",
      "MAX_IP_PKT_LEN_2 0\n",
      "SRC_TO_DST_SECOND_BYTES_2 0\n",
      "DST_TO_SRC_SECOND_BYTES_2 0\n",
      "RETRANSMITTED_IN_BYTES_2 0\n",
      "RETRANSMITTED_IN_PKTS_2 0\n",
      "RETRANSMITTED_OUT_BYTES_2 0\n",
      "RETRANSMITTED_OUT_PKTS_2 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 0\n",
      "NUM_PKTS_128_TO_256_BYTES_2 0\n",
      "NUM_PKTS_256_TO_512_BYTES_2 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 0\n",
      "TCP_WIN_MAX_IN_2 0\n",
      "TCP_WIN_MAX_OUT_2 0\n",
      "ICMP_TYPE_2 0\n",
      "ICMP_IPV4_TYPE_2 0\n",
      "DNS_QUERY_ID_2 0\n",
      "DNS_QUERY_TYPE_2 0\n",
      "DNS_TTL_ANSWER_2 0\n",
      "FTP_COMMAND_RET_CODE_2 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].isna().sum())\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_3sigma(val):\n",
    "    if (val < -3): return -3\n",
    "    if (val > 3): return 3\n",
    "    return val\n",
    "\n",
    "X = X.applymap(max_3sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 17:51:33.081303: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.argmax(dummies, axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_label, y_train_label, y_test_label = train_test_split(X, y_label, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_enforce, y_train_enforce, y_test_enforce = train_test_split(X, y_enforce, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_1, y_train_1, y_test_1 = train_test_split(X, y1.numpy(), test_size=0.20, shuffle = True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_write_path = \"/home/marius1406/\"\n",
    "colab_model_write_path = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M\" + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_1 = tf.keras.Sequential([\\n  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation=\\'relu\\'),\\n  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation=\\'softmax\\')\\n  ])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1\n",
    "#initializer = \"glorot_uniform\"\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu',name='dense_1a'),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1b'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1c'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1d'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "  ])\n",
    "'''\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation='softmax')\n",
    "  ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marius1406/20231010221352\n",
      "Epoch 1/100\n",
      "852/852 - 10s - loss: 0.2878 - accuracy: 0.9140 - val_loss: 0.1270 - val_accuracy: 0.9654 - 10s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "852/852 - 20s - loss: 0.1290 - accuracy: 0.9653 - val_loss: 0.1031 - val_accuracy: 0.9727 - 20s/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "852/852 - 11s - loss: 0.1105 - accuracy: 0.9708 - val_loss: 0.0938 - val_accuracy: 0.9753 - 11s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "852/852 - 14s - loss: 0.1012 - accuracy: 0.9734 - val_loss: 0.0869 - val_accuracy: 0.9771 - 14s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "852/852 - 15s - loss: 0.0947 - accuracy: 0.9749 - val_loss: 0.0852 - val_accuracy: 0.9774 - 15s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "852/852 - 14s - loss: 0.0906 - accuracy: 0.9761 - val_loss: 0.0807 - val_accuracy: 0.9787 - 14s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "852/852 - 17s - loss: 0.0876 - accuracy: 0.9767 - val_loss: 0.0793 - val_accuracy: 0.9792 - 17s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "852/852 - 23s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0764 - val_accuracy: 0.9796 - 23s/epoch - 27ms/step\n",
      "Epoch 9/100\n",
      "852/852 - 23s - loss: 0.0828 - accuracy: 0.9779 - val_loss: 0.0754 - val_accuracy: 0.9801 - 23s/epoch - 27ms/step\n",
      "Epoch 10/100\n",
      "852/852 - 19s - loss: 0.0818 - accuracy: 0.9782 - val_loss: 0.0751 - val_accuracy: 0.9793 - 19s/epoch - 22ms/step\n",
      "Epoch 11/100\n",
      "852/852 - 12s - loss: 0.0798 - accuracy: 0.9785 - val_loss: 0.0744 - val_accuracy: 0.9800 - 12s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "852/852 - 16s - loss: 0.0789 - accuracy: 0.9788 - val_loss: 0.0742 - val_accuracy: 0.9802 - 16s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "852/852 - 14s - loss: 0.0779 - accuracy: 0.9791 - val_loss: 0.0747 - val_accuracy: 0.9801 - 14s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "852/852 - 19s - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.0730 - val_accuracy: 0.9804 - 19s/epoch - 22ms/step\n",
      "Epoch 15/100\n",
      "852/852 - 18s - loss: 0.0761 - accuracy: 0.9794 - val_loss: 0.0741 - val_accuracy: 0.9808 - 18s/epoch - 22ms/step\n",
      "Epoch 16/100\n",
      "852/852 - 15s - loss: 0.0753 - accuracy: 0.9797 - val_loss: 0.0711 - val_accuracy: 0.9812 - 15s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "852/852 - 10s - loss: 0.0748 - accuracy: 0.9799 - val_loss: 0.0711 - val_accuracy: 0.9808 - 10s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "852/852 - 11s - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.0693 - val_accuracy: 0.9815 - 11s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "852/852 - 13s - loss: 0.0732 - accuracy: 0.9802 - val_loss: 0.0701 - val_accuracy: 0.9810 - 13s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "852/852 - 12s - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.0693 - val_accuracy: 0.9813 - 12s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "852/852 - 16s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0699 - val_accuracy: 0.9814 - 16s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "852/852 - 32s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0687 - val_accuracy: 0.9816 - 32s/epoch - 37ms/step\n",
      "Epoch 23/100\n",
      "852/852 - 26s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0685 - val_accuracy: 0.9818 - 26s/epoch - 30ms/step\n",
      "Epoch 24/100\n",
      "852/852 - 18s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0686 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "852/852 - 17s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9818 - 17s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "852/852 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "852/852 - 10s - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0671 - val_accuracy: 0.9820 - 10s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "852/852 - 11s - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0683 - val_accuracy: 0.9818 - 11s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "852/852 - 10s - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0684 - val_accuracy: 0.9813 - 10s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "852/852 - 15s - loss: 0.0694 - accuracy: 0.9812 - val_loss: 0.0669 - val_accuracy: 0.9821 - 15s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "852/852 - 13s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0676 - val_accuracy: 0.9819 - 13s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "852/852 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0659 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "852/852 - 14s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0664 - val_accuracy: 0.9824 - 14s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "852/852 - 20s - loss: 0.0681 - accuracy: 0.9815 - val_loss: 0.0653 - val_accuracy: 0.9826 - 20s/epoch - 23ms/step\n",
      "Epoch 35/100\n",
      "852/852 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0675 - val_accuracy: 0.9821 - 12s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "852/852 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0655 - val_accuracy: 0.9823 - 12s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "852/852 - 10s - loss: 0.0677 - accuracy: 0.9817 - val_loss: 0.0656 - val_accuracy: 0.9826 - 10s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "852/852 - 10s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0652 - val_accuracy: 0.9823 - 10s/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "852/852 - 18s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0683 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "852/852 - 20s - loss: 0.0673 - accuracy: 0.9818 - val_loss: 0.0674 - val_accuracy: 0.9816 - 20s/epoch - 23ms/step\n",
      "Epoch 41/100\n",
      "852/852 - 26s - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.0653 - val_accuracy: 0.9828 - 26s/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "852/852 - 34s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0659 - val_accuracy: 0.9825 - 34s/epoch - 40ms/step\n",
      "Epoch 43/100\n",
      "852/852 - 30s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 30s/epoch - 35ms/step\n",
      "Epoch 44/100\n",
      "852/852 - 19s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 19s/epoch - 22ms/step\n",
      "Epoch 45/100\n",
      "852/852 - 21s - loss: 0.0665 - accuracy: 0.9819 - val_loss: 0.0654 - val_accuracy: 0.9825 - 21s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "852/852 - 13s - loss: 0.0664 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9827 - 13s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "852/852 - 10s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0659 - val_accuracy: 0.9825 - 10s/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "852/852 - 13s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0655 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "852/852 - 11s - loss: 0.0659 - accuracy: 0.9821 - val_loss: 0.0654 - val_accuracy: 0.9826 - 11s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "852/852 - 18s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0656 - val_accuracy: 0.9823 - 18s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "852/852 - 16s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0641 - val_accuracy: 0.9827 - 16s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "852/852 - 18s - loss: 0.0655 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9827 - 18s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "852/852 - 15s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0644 - val_accuracy: 0.9827 - 15s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "852/852 - 13s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9827 - 13s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "852/852 - 24s - loss: 0.0653 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9827 - 24s/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "852/852 - 14s - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9831 - 14s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "852/852 - 26s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.9825 - 26s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "852/852 - 26s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0642 - val_accuracy: 0.9826 - 26s/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "852/852 - 20s - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.0645 - val_accuracy: 0.9828 - 20s/epoch - 23ms/step\n",
      "Epoch 60/100\n",
      "852/852 - 17s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9829 - 17s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "852/852 - 10s - loss: 0.0645 - accuracy: 0.9826 - val_loss: 0.0644 - val_accuracy: 0.9828 - 10s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "852/852 - 12s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0646 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "852/852 - 13s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0642 - val_accuracy: 0.9829 - 13s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "852/852 - 13s - loss: 0.0644 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "852/852 - 18s - loss: 0.0640 - accuracy: 0.9826 - val_loss: 0.0636 - val_accuracy: 0.9829 - 18s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "852/852 - 12s - loss: 0.0644 - accuracy: 0.9824 - val_loss: 0.0647 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "852/852 - 18s - loss: 0.0642 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9830 - 18s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "852/852 - 11s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0635 - val_accuracy: 0.9829 - 11s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "852/852 - 10s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9828 - 10s/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "852/852 - 13s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0627 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "852/852 - 16s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9830 - 16s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "852/852 - 15s - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0640 - val_accuracy: 0.9831 - 15s/epoch - 18ms/step\n",
      "Epoch 73/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0639 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0632 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "852/852 - 10s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "852/852 - 10s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9831 - 10s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "852/852 - 12s - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0628 - val_accuracy: 0.9832 - 12s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "852/852 - 16s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0620 - val_accuracy: 0.9834 - 16s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "852/852 - 26s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0635 - val_accuracy: 0.9831 - 26s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "852/852 - 17s - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9827 - 17s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "852/852 - 17s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9832 - 17s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "852/852 - 7s - loss: 0.0631 - accuracy: 0.9830 - val_loss: 0.0621 - val_accuracy: 0.9834 - 7s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "852/852 - 10s - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.0628 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "852/852 - 15s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0624 - val_accuracy: 0.9832 - 15s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "852/852 - 23s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9833 - 23s/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "852/852 - 13s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "852/852 - 24s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0629 - val_accuracy: 0.9831 - 24s/epoch - 28ms/step\n",
      "Epoch 88/100\n",
      "852/852 - 31s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9832 - 31s/epoch - 36ms/step\n",
      "Epoch 89/100\n",
      "852/852 - 7s - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9833 - 7s/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "852/852 - 11s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9834 - 11s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "852/852 - 13s - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.0630 - val_accuracy: 0.9833 - 13s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "852/852 - 27s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9834 - 27s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "852/852 - 28s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0618 - val_accuracy: 0.9834 - 28s/epoch - 33ms/step\n",
      "Epoch 94/100\n",
      "852/852 - 25s - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0623 - val_accuracy: 0.9833 - 25s/epoch - 30ms/step\n",
      "Epoch 95/100\n",
      "852/852 - 10s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9823 - 10s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "852/852 - 12s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9836 - 12s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "852/852 - 27s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9836 - 27s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "852/852 - 8s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9835 - 8s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "852/852 - 9s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9834 - 9s/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "852/852 - 18s - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9835 - 18s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model_1.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_1 = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(log_dir_1)\n",
    "monitor_1 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "            ]\n",
    "history_1  = model_1.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=1024, epochs=100)\n",
    "model_1.save(colab_model_write_path + 'model1.h5')\n",
    "#history_1  = model_1.fit(x_train,y_train,validation_split=0.2, callbacks=[monitor_1],verbose=2, batch_size=1024, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  model 2  with different structure\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_2a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, activation='relu',name='dense_2b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(256, input_dim=128, kernel_initializer=initializer, activation='relu',name='dense_2c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=256, kernel_initializer=initializer, activation='relu',name='dense_2d'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 14s - loss: 0.2063 - accuracy: 0.9384 - val_loss: 0.1091 - val_accuracy: 0.9693 - 14s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 15s - loss: 0.1104 - accuracy: 0.9704 - val_loss: 0.0928 - val_accuracy: 0.9750 - 15s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 12s - loss: 0.0971 - accuracy: 0.9739 - val_loss: 0.0835 - val_accuracy: 0.9780 - 12s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 16s - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.0814 - val_accuracy: 0.9785 - 16s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 12s - loss: 0.0865 - accuracy: 0.9769 - val_loss: 0.0774 - val_accuracy: 0.9796 - 12s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 13s - loss: 0.0833 - accuracy: 0.9778 - val_loss: 0.0785 - val_accuracy: 0.9796 - 13s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 13s - loss: 0.0815 - accuracy: 0.9782 - val_loss: 0.0755 - val_accuracy: 0.9798 - 13s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0793 - accuracy: 0.9787 - val_loss: 0.0725 - val_accuracy: 0.9802 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 12s - loss: 0.0780 - accuracy: 0.9791 - val_loss: 0.0717 - val_accuracy: 0.9808 - 12s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 13s - loss: 0.0767 - accuracy: 0.9793 - val_loss: 0.0705 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 12s - loss: 0.0757 - accuracy: 0.9796 - val_loss: 0.0700 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 12s - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.0705 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 12s - loss: 0.0741 - accuracy: 0.9799 - val_loss: 0.0699 - val_accuracy: 0.9812 - 12s/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 15s - loss: 0.0736 - accuracy: 0.9801 - val_loss: 0.0692 - val_accuracy: 0.9813 - 15s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 14s - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0691 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 13s - loss: 0.0721 - accuracy: 0.9805 - val_loss: 0.0671 - val_accuracy: 0.9821 - 13s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 14s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9819 - 14s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.0695 - val_accuracy: 0.9813 - 13s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 12s - loss: 0.0704 - accuracy: 0.9809 - val_loss: 0.0670 - val_accuracy: 0.9817 - 12s/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 12s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0668 - val_accuracy: 0.9818 - 12s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0665 - val_accuracy: 0.9819 - 13s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 15s - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.0651 - val_accuracy: 0.9822 - 15s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 17s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0693 - val_accuracy: 0.9816 - 17s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 14s - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.0648 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 14s - loss: 0.0688 - accuracy: 0.9813 - val_loss: 0.0657 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0653 - val_accuracy: 0.9823 - 13s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0642 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 11s - loss: 0.0679 - accuracy: 0.9816 - val_loss: 0.0644 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 12s - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0651 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 12s - loss: 0.0674 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 11s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0646 - val_accuracy: 0.9824 - 11s/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9817 - val_loss: 0.0647 - val_accuracy: 0.9825 - 12s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0643 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 12s - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.0635 - val_accuracy: 0.9828 - 12s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 12s - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0650 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 12s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 11s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0642 - val_accuracy: 0.9827 - 11s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 12s - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.0641 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 12s - loss: 0.0658 - accuracy: 0.9823 - val_loss: 0.0635 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 11s - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0630 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0639 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 12s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0631 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 13s - loss: 0.0653 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9830 - 13s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9823 - val_loss: 0.0634 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0626 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 11s - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.0628 - val_accuracy: 0.9834 - 11s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 12s - loss: 0.0646 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 11s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0626 - val_accuracy: 0.9833 - 11s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0643 - val_accuracy: 0.9831 - 11s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0630 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 12s - loss: 0.0645 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 12s - loss: 0.0641 - accuracy: 0.9827 - val_loss: 0.0625 - val_accuracy: 0.9833 - 12s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0631 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_2 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_2 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "            ]\n",
    "history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_2],verbose=2, batch_size=512, epochs=100)\n",
    "model_2.save(colab_model_write_path + 'model2.h5')\n",
    "\n",
    "#history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3a'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(256, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3d'),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 22s - loss: 0.1728 - accuracy: 0.9499 - val_loss: 0.0947 - val_accuracy: 0.9748 - 22s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 21s - loss: 0.1002 - accuracy: 0.9733 - val_loss: 0.0837 - val_accuracy: 0.9779 - 21s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 22s - loss: 0.0899 - accuracy: 0.9761 - val_loss: 0.0802 - val_accuracy: 0.9786 - 22s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 21s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0785 - val_accuracy: 0.9797 - 21s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 22s - loss: 0.0819 - accuracy: 0.9781 - val_loss: 0.0752 - val_accuracy: 0.9803 - 22s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 20s - loss: 0.0795 - accuracy: 0.9788 - val_loss: 0.0746 - val_accuracy: 0.9801 - 20s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 20s - loss: 0.0770 - accuracy: 0.9792 - val_loss: 0.0728 - val_accuracy: 0.9806 - 20s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 20s - loss: 0.0756 - accuracy: 0.9796 - val_loss: 0.0732 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 20s - loss: 0.0746 - accuracy: 0.9797 - val_loss: 0.0702 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 23s - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.0695 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 23s - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.0690 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 22s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0688 - val_accuracy: 0.9817 - 22s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 20s - loss: 0.0706 - accuracy: 0.9807 - val_loss: 0.0695 - val_accuracy: 0.9815 - 20s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 21s - loss: 0.0700 - accuracy: 0.9809 - val_loss: 0.0691 - val_accuracy: 0.9814 - 21s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 21s - loss: 0.0693 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9815 - 21s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 21s - loss: 0.0691 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9816 - 21s/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 21s - loss: 0.0681 - accuracy: 0.9814 - val_loss: 0.0658 - val_accuracy: 0.9823 - 21s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 20s - loss: 0.0678 - accuracy: 0.9816 - val_loss: 0.0662 - val_accuracy: 0.9822 - 20s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 20s - loss: 0.0671 - accuracy: 0.9814 - val_loss: 0.0654 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 22s - loss: 0.0666 - accuracy: 0.9817 - val_loss: 0.0672 - val_accuracy: 0.9822 - 22s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 23s - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.0656 - val_accuracy: 0.9825 - 23s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 24s - loss: 0.0656 - accuracy: 0.9820 - val_loss: 0.0659 - val_accuracy: 0.9821 - 24s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 20s - loss: 0.0657 - accuracy: 0.9820 - val_loss: 0.0681 - val_accuracy: 0.9816 - 20s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 20s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0655 - val_accuracy: 0.9824 - 20s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 20s - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.0658 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 23s - loss: 0.0649 - accuracy: 0.9823 - val_loss: 0.0668 - val_accuracy: 0.9824 - 23s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "1704/1704 - 24s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9824 - 24s/epoch - 14ms/step\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_3.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_3 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=2, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "history_3  = model_3.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_3],verbose=2, batch_size=512, epochs=100)\n",
    "model_3.save(colab_model_write_path + 'model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4b'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4d'),\n",
    "      tf.keras.layers.Dense(y_train.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 9s - loss: 0.2432 - accuracy: 0.9265 - val_loss: 0.1163 - val_accuracy: 0.9687 - 9s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 9s - loss: 0.1272 - accuracy: 0.9651 - val_loss: 0.0988 - val_accuracy: 0.9741 - 9s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 8s - loss: 0.1102 - accuracy: 0.9701 - val_loss: 0.0887 - val_accuracy: 0.9766 - 8s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.1018 - accuracy: 0.9725 - val_loss: 0.0856 - val_accuracy: 0.9776 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 8s - loss: 0.0972 - accuracy: 0.9740 - val_loss: 0.0831 - val_accuracy: 0.9785 - 8s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 8s - loss: 0.0933 - accuracy: 0.9749 - val_loss: 0.0786 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 9s - loss: 0.0907 - accuracy: 0.9756 - val_loss: 0.0774 - val_accuracy: 0.9796 - 9s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0891 - accuracy: 0.9760 - val_loss: 0.0768 - val_accuracy: 0.9797 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 9s - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.0757 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 9s - loss: 0.0864 - accuracy: 0.9767 - val_loss: 0.0760 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 9s - loss: 0.0852 - accuracy: 0.9770 - val_loss: 0.0734 - val_accuracy: 0.9800 - 9s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 9s - loss: 0.0844 - accuracy: 0.9772 - val_loss: 0.0743 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0835 - accuracy: 0.9775 - val_loss: 0.0741 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 8s - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.0733 - val_accuracy: 0.9804 - 8s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 0.0823 - accuracy: 0.9777 - val_loss: 0.0718 - val_accuracy: 0.9806 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 8s - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.0718 - val_accuracy: 0.9809 - 8s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.0713 - val_accuracy: 0.9807 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.0714 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 0.0801 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9809 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 8s - loss: 0.0798 - accuracy: 0.9783 - val_loss: 0.0704 - val_accuracy: 0.9812 - 8s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 10s - loss: 0.0792 - accuracy: 0.9785 - val_loss: 0.0699 - val_accuracy: 0.9811 - 10s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 9s - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.0700 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 0.0787 - accuracy: 0.9786 - val_loss: 0.0703 - val_accuracy: 0.9810 - 9s/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 9s - loss: 0.0783 - accuracy: 0.9787 - val_loss: 0.0690 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 0.0780 - accuracy: 0.9788 - val_loss: 0.0692 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 8s - loss: 0.0775 - accuracy: 0.9789 - val_loss: 0.0683 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 8s - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9817 - 8s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.0688 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 14s - loss: 0.0768 - accuracy: 0.9791 - val_loss: 0.0693 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 8s - loss: 0.0768 - accuracy: 0.9790 - val_loss: 0.0677 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 0.0766 - accuracy: 0.9792 - val_loss: 0.0681 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 8s - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.0674 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 0.0757 - accuracy: 0.9794 - val_loss: 0.0677 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 0.0759 - accuracy: 0.9793 - val_loss: 0.0673 - val_accuracy: 0.9816 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 8s - loss: 0.0758 - accuracy: 0.9793 - val_loss: 0.0682 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 11s - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.0680 - val_accuracy: 0.9814 - 11s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 0.0753 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 0.0751 - accuracy: 0.9795 - val_loss: 0.0670 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0678 - val_accuracy: 0.9816 - 11s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0750 - accuracy: 0.9794 - val_loss: 0.0675 - val_accuracy: 0.9821 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0672 - val_accuracy: 0.9818 - 11s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0672 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 0.0741 - accuracy: 0.9798 - val_loss: 0.0660 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 8s - loss: 0.0742 - accuracy: 0.9798 - val_loss: 0.0667 - val_accuracy: 0.9822 - 8s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 13s - loss: 0.0741 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9824 - 13s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0658 - val_accuracy: 0.9824 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 9s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0659 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 8s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0661 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 8s - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.0661 - val_accuracy: 0.9820 - 8s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 0.0736 - accuracy: 0.9798 - val_loss: 0.0655 - val_accuracy: 0.9822 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 9s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0653 - val_accuracy: 0.9823 - 9s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 0.0730 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0667 - val_accuracy: 0.9821 - 8s/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0650 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 11s - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.0650 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0655 - val_accuracy: 0.9825 - 8s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 8s - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.0653 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 9s - loss: 0.0726 - accuracy: 0.9802 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 11s - loss: 0.0725 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 9s - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 8s - loss: 0.0728 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 8s - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0645 - val_accuracy: 0.9826 - 8s/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 9s - loss: 0.0721 - accuracy: 0.9804 - val_loss: 0.0643 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 0.0720 - accuracy: 0.9805 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 9s - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.0649 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0653 - val_accuracy: 0.9823 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 11s - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9829 - 11s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 8s - loss: 0.0715 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 0.0715 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9828 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0643 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 8s - loss: 0.0714 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 9s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0651 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 13s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0648 - val_accuracy: 0.9826 - 13s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 11s - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0643 - val_accuracy: 0.9827 - 11s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9808 - val_loss: 0.0643 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 8s - loss: 0.0710 - accuracy: 0.9806 - val_loss: 0.0645 - val_accuracy: 0.9828 - 8s/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.0639 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9806 - val_loss: 0.0642 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0637 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9807 - val_loss: 0.0638 - val_accuracy: 0.9830 - 8s/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9809 - val_loss: 0.0641 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 11s - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9831 - 11s/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.0640 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0633 - val_accuracy: 0.9831 - 10s/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0627 - val_accuracy: 0.9832 - 8s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9810 - val_loss: 0.0639 - val_accuracy: 0.9826 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0632 - val_accuracy: 0.9831 - 13s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9809 - val_loss: 0.0629 - val_accuracy: 0.9832 - 10s/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 8s - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.0634 - val_accuracy: 0.9831 - 8s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 9s - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.0634 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_4 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_4 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_4, histogram_freq=1)\n",
    "        ]\n",
    "history_4  = model_4.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_4],verbose=2, batch_size=512, epochs=100)\n",
    "model_4.save(colab_model_write_path + 'model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_5 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5c'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5d'),\n",
    "      tf.keras.layers.Dense(y_train_enforce.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 11s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9993 - 11s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 10s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 9s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 10s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 9s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 10s - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 9.8441e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 10s - loss: 9.3665e-04 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 9.2064e-04 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 9s - loss: 9.3356e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 8.7414e-04 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 10s - loss: 8.5468e-04 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 9s - loss: 8.3748e-04 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 10s - loss: 8.6668e-04 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 7.5136e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 10s - loss: 8.0980e-04 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 7.3481e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 9s - loss: 6.9155e-04 - accuracy: 0.9998 - val_loss: 0.0045 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 9s - loss: 7.2576e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 6.4573e-04 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 10s - loss: 7.3001e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 10s - loss: 6.0983e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 6.4264e-04 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 9s - loss: 6.1619e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 6.2433e-04 - accuracy: 0.9998 - val_loss: 0.0053 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 6.3250e-04 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 10s - loss: 5.6048e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 9s - loss: 5.4817e-04 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 5.1804e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 5.7661e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 9s - loss: 5.4797e-04 - accuracy: 0.9999 - val_loss: 0.0085 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 9s - loss: 4.9753e-04 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 9s - loss: 5.4127e-04 - accuracy: 0.9999 - val_loss: 0.0097 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 10s - loss: 5.1966e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 4.7119e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 5.0597e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 10s - loss: 5.3273e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 10s - loss: 5.2568e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 4.7804e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 10s - loss: 4.1050e-04 - accuracy: 0.9999 - val_loss: 0.0120 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 9s - loss: 4.3036e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 9s - loss: 4.2457e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 5.9950e-04 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 10s - loss: 4.3468e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 3.7293e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 10s - loss: 4.0470e-04 - accuracy: 0.9999 - val_loss: 0.0087 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 9s - loss: 4.1268e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 9s - loss: 4.2829e-04 - accuracy: 0.9999 - val_loss: 0.0092 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 10s - loss: 3.5180e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 10s - loss: 3.9473e-04 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 10s - loss: 4.5839e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 10s - loss: 3.0135e-04 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 10s - loss: 4.2675e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 9s - loss: 3.2920e-04 - accuracy: 0.9999 - val_loss: 0.0233 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 10s - loss: 5.3860e-04 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 10s - loss: 3.5807e-04 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 3.6816e-04 - accuracy: 0.9999 - val_loss: 0.0187 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 10s - loss: 4.3158e-04 - accuracy: 0.9999 - val_loss: 0.0179 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 3.8634e-04 - accuracy: 0.9999 - val_loss: 0.0275 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 10s - loss: 4.6297e-04 - accuracy: 0.9999 - val_loss: 0.0335 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 10s - loss: 3.7752e-04 - accuracy: 0.9999 - val_loss: 0.0201 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 4.2812e-04 - accuracy: 0.9999 - val_loss: 0.0134 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 3.7992e-04 - accuracy: 0.9999 - val_loss: 0.0262 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 9s - loss: 3.3662e-04 - accuracy: 0.9999 - val_loss: 0.0195 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 10s - loss: 3.5111e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 3.5474e-04 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 10s - loss: 3.6096e-04 - accuracy: 0.9999 - val_loss: 0.0129 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 10s - loss: 5.7303e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 3.3251e-04 - accuracy: 0.9999 - val_loss: 0.0193 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 9s - loss: 3.9361e-04 - accuracy: 0.9999 - val_loss: 0.0203 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 3.1856e-04 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 10s - loss: 3.0138e-04 - accuracy: 0.9999 - val_loss: 0.0224 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 4.1926e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 14s - loss: 4.1826e-04 - accuracy: 0.9999 - val_loss: 0.0204 - val_accuracy: 0.9994 - 14s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 2.9279e-04 - accuracy: 0.9999 - val_loss: 0.0170 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 9s - loss: 3.0474e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 3.6375e-04 - accuracy: 0.9999 - val_loss: 0.0261 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 10s - loss: 3.9308e-04 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9992 - 10s/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 3.3599e-04 - accuracy: 0.9999 - val_loss: 0.0535 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 10s - loss: 4.3944e-04 - accuracy: 0.9999 - val_loss: 0.0341 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 9s - loss: 3.3641e-04 - accuracy: 0.9999 - val_loss: 0.0285 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 3.7667e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 9s - loss: 3.3478e-04 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 11s - loss: 3.2279e-04 - accuracy: 0.9999 - val_loss: 0.0254 - val_accuracy: 0.9994 - 11s/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 3.8158e-04 - accuracy: 0.9999 - val_loss: 0.0329 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 2.9903e-04 - accuracy: 0.9999 - val_loss: 0.0514 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 3.4784e-04 - accuracy: 0.9999 - val_loss: 0.0336 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 10s - loss: 3.5308e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 3.3192e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 9s - loss: 4.5388e-04 - accuracy: 0.9999 - val_loss: 0.0309 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 9s - loss: 6.0361e-04 - accuracy: 0.9999 - val_loss: 0.0196 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 10s - loss: 3.1968e-04 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_5 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_5 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_5, histogram_freq=1)\n",
    "        ]\n",
    "history_5  = model_5.fit(x_train,y_train_enforce,validation_data=(x_test,y_test_enforce), callbacks=[monitor_5],verbose=2, batch_size=512, epochs=100)\n",
    "model_5.save(colab_model_write_path + 'model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(colab_model_write_path + 'model1_1.h5')\n",
    "model_2.save(colab_model_write_path + 'model1_2.h5')\n",
    "model_3.save(colab_model_write_path + 'model1_3.h5')\n",
    "model_4.save(colab_model_write_path + 'model1_4.h5')\n",
    "model_5.save(colab_model_write_path + 'model1_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model 6 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# #type(y_train)\n",
    "# ydp= pd.DataFrame(y_train)\n",
    "# ydp = tf.argmax(ydp, axis=1)\n",
    "# #ydp = pd.DataFrame(ydp)\n",
    "# #ydp.value_counts\n",
    "# dicts = Counter(ydp.numpy())\n",
    "# dicts\n",
    "\n",
    "# MININUM_SAMPLES = 30000\n",
    "# MAXINUM_SAMPLES = 300000\n",
    "\n",
    "# sample_dict = {2: 793860,\n",
    "#          19: 119826,\n",
    "#          6: 564661,\n",
    "#          15: 21588,\n",
    "#          20: 77352,\n",
    "#          5: 687703,\n",
    "#          4: 3987,\n",
    "#          11: 82959,\n",
    "#          17: 36318,\n",
    "#          10: 3759,\n",
    "#          7: 999,\n",
    "#          9: 562,\n",
    "#          3: 4605,\n",
    "#          16: 233,\n",
    "#          1: 592,\n",
    "#          8: 710,\n",
    "#          13: 71,\n",
    "#          18: 92,\n",
    "#          0: 74,\n",
    "#          12: 45,\n",
    "#          14: 4}\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# #ros = RandomOverSampler(random_state=33)\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "#     sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  MININUM_SAMPLES:\n",
    "#     sample_dict[i] =  MININUM_SAMPLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 30000,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 30000,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 30000,\n",
       " 7: 30000,\n",
       " 9: 30000,\n",
       " 3: 30000,\n",
       " 16: 30000,\n",
       " 1: 30000,\n",
       " 8: 30000,\n",
       " 13: 30000,\n",
       " 18: 30000,\n",
       " 0: 30000,\n",
       " 12: 30000,\n",
       " 14: 30000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "# sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 21588,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 3987,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 3759,\n",
       " 7: 999,\n",
       " 9: 562,\n",
       " 3: 4605,\n",
       " 16: 233,\n",
       " 1: 592,\n",
       " 8: 710,\n",
       " 13: 71,\n",
       " 18: 92,\n",
       " 0: 74,\n",
       " 12: 45,\n",
       " 14: 4}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (871999, 127) (871999, 21)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (555103, 127) (555103, 21)\n"
     ]
    }
   ],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_over,y_train_over = smote.fit_resample(x_train,y_train)\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "MININUM_SAMPLES = 10000\n",
    "MAXINUM_SAMPLES = 100000\n",
    "\n",
    "# sample_dict = {5: 687357,\n",
    "#          2: 794288,\n",
    "#          19: 119905,\n",
    "#          15: 21686,\n",
    "#          6: 564557,\n",
    "#          4: 4025,\n",
    "#          11: 82731,\n",
    "#          20: 77617,\n",
    "#          17: 36205,\n",
    "#          3: 4569,\n",
    "#          10: 3752,\n",
    "#          9: 542,\n",
    "#          7: 968,\n",
    "#          8: 694,\n",
    "#          1: 575,\n",
    "#          16: 239,\n",
    "#          0: 81,\n",
    "#          18: 94,\n",
    "#          13: 69,\n",
    "#          12: 42,\n",
    "#          14: 4}\n",
    "\n",
    "sample_dict = {6: 205290,\n",
    "         2: 288786,\n",
    "         5: 249311,\n",
    "         20: 28278,\n",
    "         19: 43885,\n",
    "         11: 29889,\n",
    "         17: 13051,\n",
    "         3: 1639,\n",
    "         15: 7863,\n",
    "         4: 1436,\n",
    "         10: 1354,\n",
    "         8: 256,\n",
    "         9: 185,\n",
    "         7: 373,\n",
    "         18: 31,\n",
    "         1: 214,\n",
    "         13: 17,\n",
    "         16: 86,\n",
    "         0: 38,\n",
    "         12: 13,\n",
    "         14: 4}\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=33)\n",
    "for i in range(21):\n",
    "  if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "    sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "ros = RandomUnderSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_under, y_train_under = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  16:\n",
    "#     sample_dict[i] =  16\n",
    "\n",
    "# ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "for i in range(21):\n",
    "  if sample_dict[i] <  MININUM_SAMPLES:\n",
    "    sample_dict[i] =  MININUM_SAMPLES\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train_under, y_train_under)\n",
    "\n",
    "# sm = SMOTE(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = sm.fit_resample(X_train_over, y_train_over)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "#6 rd model for stack\n",
    "model_6 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6b'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6d'),\n",
    "      tf.keras.layers.Dense(y_train_over.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1085/1085 - 10s - loss: 0.4190 - accuracy: 0.8622 - val_loss: 0.1915 - val_accuracy: 0.9446 - 10s/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "1085/1085 - 8s - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1437 - val_accuracy: 0.9617 - 8s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "1085/1085 - 8s - loss: 0.1844 - accuracy: 0.9437 - val_loss: 0.1276 - val_accuracy: 0.9676 - 8s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1085/1085 - 9s - loss: 0.1657 - accuracy: 0.9494 - val_loss: 0.1276 - val_accuracy: 0.9701 - 9s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "1085/1085 - 9s - loss: 0.1553 - accuracy: 0.9531 - val_loss: 0.1107 - val_accuracy: 0.9716 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1085/1085 - 8s - loss: 0.1465 - accuracy: 0.9555 - val_loss: 0.1217 - val_accuracy: 0.9720 - 8s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1085/1085 - 9s - loss: 0.1415 - accuracy: 0.9571 - val_loss: 0.1092 - val_accuracy: 0.9733 - 9s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "1085/1085 - 8s - loss: 0.1382 - accuracy: 0.9581 - val_loss: 0.1119 - val_accuracy: 0.9725 - 8s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1085/1085 - 8s - loss: 0.1342 - accuracy: 0.9590 - val_loss: 0.1153 - val_accuracy: 0.9727 - 8s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1085/1085 - 8s - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1051 - val_accuracy: 0.9747 - 8s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1085/1085 - 8s - loss: 0.1297 - accuracy: 0.9604 - val_loss: 0.1044 - val_accuracy: 0.9743 - 8s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1085/1085 - 9s - loss: 0.1272 - accuracy: 0.9611 - val_loss: 0.1036 - val_accuracy: 0.9743 - 9s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1085/1085 - 10s - loss: 0.1258 - accuracy: 0.9614 - val_loss: 0.1045 - val_accuracy: 0.9742 - 10s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1085/1085 - 9s - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1062 - val_accuracy: 0.9747 - 9s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "1085/1085 - 9s - loss: 0.1230 - accuracy: 0.9623 - val_loss: 0.1045 - val_accuracy: 0.9750 - 9s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1085/1085 - 8s - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.1155 - val_accuracy: 0.9726 - 8s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "1085/1085 - 9s - loss: 0.1202 - accuracy: 0.9631 - val_loss: 0.1079 - val_accuracy: 0.9754 - 9s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1085/1085 - 8s - loss: 0.1196 - accuracy: 0.9632 - val_loss: 0.1032 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1085/1085 - 11s - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1034 - val_accuracy: 0.9751 - 11s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "1085/1085 - 8s - loss: 0.1176 - accuracy: 0.9637 - val_loss: 0.0993 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1085/1085 - 8s - loss: 0.1171 - accuracy: 0.9639 - val_loss: 0.0999 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "1085/1085 - 8s - loss: 0.1156 - accuracy: 0.9641 - val_loss: 0.1006 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "1085/1085 - 8s - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.0978 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "1085/1085 - 8s - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.0991 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "1085/1085 - 8s - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.1017 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "1085/1085 - 7s - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.0966 - val_accuracy: 0.9766 - 7s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1085/1085 - 8s - loss: 0.1114 - accuracy: 0.9652 - val_loss: 0.1054 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1085/1085 - 8s - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1019 - val_accuracy: 0.9755 - 8s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1085/1085 - 9s - loss: 0.1110 - accuracy: 0.9654 - val_loss: 0.0986 - val_accuracy: 0.9765 - 9s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1085/1085 - 9s - loss: 0.1107 - accuracy: 0.9656 - val_loss: 0.0987 - val_accuracy: 0.9749 - 9s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "1085/1085 - 8s - loss: 0.1094 - accuracy: 0.9659 - val_loss: 0.1004 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9659 - val_loss: 0.0910 - val_accuracy: 0.9766 - 8s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1085/1085 - 9s - loss: 0.1089 - accuracy: 0.9661 - val_loss: 0.0982 - val_accuracy: 0.9767 - 9s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.1018 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1085/1085 - 8s - loss: 0.1082 - accuracy: 0.9659 - val_loss: 0.0920 - val_accuracy: 0.9768 - 8s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1085/1085 - 8s - loss: 0.1074 - accuracy: 0.9662 - val_loss: 0.0954 - val_accuracy: 0.9770 - 8s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1085/1085 - 7s - loss: 0.1064 - accuracy: 0.9668 - val_loss: 0.0957 - val_accuracy: 0.9769 - 7s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1085/1085 - 7s - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.0974 - val_accuracy: 0.9765 - 7s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1085/1085 - 8s - loss: 0.1063 - accuracy: 0.9666 - val_loss: 0.0905 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1085/1085 - 8s - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.0969 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1085/1085 - 8s - loss: 0.1051 - accuracy: 0.9670 - val_loss: 0.0943 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1085/1085 - 9s - loss: 0.1052 - accuracy: 0.9668 - val_loss: 0.0956 - val_accuracy: 0.9770 - 9s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1085/1085 - 8s - loss: 0.1046 - accuracy: 0.9673 - val_loss: 0.1010 - val_accuracy: 0.9747 - 8s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1085/1085 - 9s - loss: 0.1045 - accuracy: 0.9672 - val_loss: 0.0937 - val_accuracy: 0.9766 - 9s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "1085/1085 - 8s - loss: 0.1038 - accuracy: 0.9674 - val_loss: 0.0895 - val_accuracy: 0.9771 - 8s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1085/1085 - 8s - loss: 0.1039 - accuracy: 0.9675 - val_loss: 0.0934 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9674 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.0939 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1085/1085 - 8s - loss: 0.1027 - accuracy: 0.9676 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1085/1085 - 8s - loss: 0.1024 - accuracy: 0.9679 - val_loss: 0.0930 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1085/1085 - 9s - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.0929 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "1085/1085 - 8s - loss: 0.1022 - accuracy: 0.9678 - val_loss: 0.0942 - val_accuracy: 0.9761 - 8s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1085/1085 - 9s - loss: 0.1019 - accuracy: 0.9679 - val_loss: 0.0939 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1085/1085 - 8s - loss: 0.1014 - accuracy: 0.9681 - val_loss: 0.0909 - val_accuracy: 0.9762 - 8s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "1085/1085 - 7s - loss: 0.1016 - accuracy: 0.9679 - val_loss: 0.0947 - val_accuracy: 0.9756 - 7s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9682 - val_loss: 0.0896 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1085/1085 - 8s - loss: 0.1000 - accuracy: 0.9683 - val_loss: 0.0886 - val_accuracy: 0.9772 - 8s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9683 - val_loss: 0.0883 - val_accuracy: 0.9768 - 8s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1085/1085 - 8s - loss: 0.0998 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "1085/1085 - 8s - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.0933 - val_accuracy: 0.9764 - 8s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1085/1085 - 8s - loss: 0.0997 - accuracy: 0.9685 - val_loss: 0.0921 - val_accuracy: 0.9758 - 8s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1085/1085 - 8s - loss: 0.0987 - accuracy: 0.9687 - val_loss: 0.0840 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "1085/1085 - 8s - loss: 0.0992 - accuracy: 0.9687 - val_loss: 0.0926 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "1085/1085 - 8s - loss: 0.0984 - accuracy: 0.9689 - val_loss: 0.0934 - val_accuracy: 0.9742 - 8s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9779 - 8s/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0879 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0921 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "1085/1085 - 8s - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.0925 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0913 - val_accuracy: 0.9773 - 8s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1085/1085 - 8s - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.0864 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "1085/1085 - 8s - loss: 0.0974 - accuracy: 0.9690 - val_loss: 0.0918 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9692 - val_loss: 0.0850 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9694 - val_loss: 0.0883 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1085/1085 - 8s - loss: 0.0961 - accuracy: 0.9694 - val_loss: 0.0846 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "1085/1085 - 8s - loss: 0.0964 - accuracy: 0.9695 - val_loss: 0.0855 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "1085/1085 - 8s - loss: 0.0962 - accuracy: 0.9696 - val_loss: 0.0915 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "1085/1085 - 8s - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.0859 - val_accuracy: 0.9782 - 8s/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "1085/1085 - 10s - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.0877 - val_accuracy: 0.9776 - 10s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "1085/1085 - 8s - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.0887 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "1085/1085 - 8s - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.0872 - val_accuracy: 0.9769 - 8s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9701 - val_loss: 0.0898 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "1085/1085 - 8s - loss: 0.0950 - accuracy: 0.9696 - val_loss: 0.0867 - val_accuracy: 0.9775 - 8s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.0891 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9699 - val_loss: 0.0894 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.0859 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9700 - val_loss: 0.0843 - val_accuracy: 0.9785 - 8s/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "1085/1085 - 8s - loss: 0.0945 - accuracy: 0.9701 - val_loss: 0.0845 - val_accuracy: 0.9786 - 8s/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "1085/1085 - 8s - loss: 0.0942 - accuracy: 0.9700 - val_loss: 0.0869 - val_accuracy: 0.9780 - 8s/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "1085/1085 - 9s - loss: 0.0937 - accuracy: 0.9703 - val_loss: 0.0865 - val_accuracy: 0.9768 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1085/1085 - 8s - loss: 0.0938 - accuracy: 0.9703 - val_loss: 0.0863 - val_accuracy: 0.9777 - 8s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0886 - val_accuracy: 0.9773 - 8s/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0921 - val_accuracy: 0.9744 - 8s/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "1085/1085 - 8s - loss: 0.0932 - accuracy: 0.9704 - val_loss: 0.0864 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "1085/1085 - 8s - loss: 0.0937 - accuracy: 0.9704 - val_loss: 0.0868 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "1085/1085 - 7s - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9784 - 7s/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0870 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "1085/1085 - 7s - loss: 0.0926 - accuracy: 0.9706 - val_loss: 0.0887 - val_accuracy: 0.9749 - 7s/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "1085/1085 - 8s - loss: 0.0925 - accuracy: 0.9706 - val_loss: 0.0820 - val_accuracy: 0.9792 - 8s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_6 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_6 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_6, histogram_freq=1)\n",
    "        ]\n",
    "history_6  = model_6.fit(X_train_over,y_train_over,validation_data=(x_test,y_test), callbacks=[monitor_6],verbose=2, batch_size=512, epochs=100)\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_model_write_path\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "https://abstractask.tistory.com/105\n",
    "\n",
    "Model #1, Model #2, Model #3, + OverSampling/UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "# for both logistic and nueral\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "#\t\tcolab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "\t\t#model_4.save(colab_path + 'model4.h5')\n",
    "\t\tif i != 4 and i != 3: #Model4와 Binary 배제\n",
    "\t\t\tfilename = colab_model_write_path + 'model1_' + str(i + 1) + '.h5'\n",
    "\t\t\t# load model from file\n",
    "\t\t\tmodel = load_model(filename,custom_objects=None)\n",
    "\t\t\t# add to list of members\n",
    "\t\t\tall_models.append(model)\n",
    "\t\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "#neural\n",
    "\n",
    "def define_stacked_model(members):\n",
    "\tinitializer = tf.keras.initializers.GlorotUniform(seed=64)\n",
    "\tconstraints = None\n",
    "\n",
    "  # update all layers in all models to not be trainable\n",
    "\tfor i in range(len(members)):\n",
    "\t\tmodel = members[i]\n",
    "\t\tfor layer in model.layers:\n",
    "\t\t\t# make not trainable\n",
    "\t\t\tlayer.trainable = False\n",
    "\t\t\t# rename to avoid 'unique layer name' issue\n",
    "\t\t\tlayer._name = 'ensemble_' + str(i + 1) + '_' + layer.name\n",
    "\n",
    "\n",
    "\t# define multi-headed input\n",
    "\tensemble_visible = [model.input for model in members]\n",
    "\t# concatenate merge output from each model\n",
    "\tensemble_outputs = [model.output for model in members]\n",
    "\tmerge = concatenate(ensemble_outputs)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_ea\")(merge)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_eb\")(merge)\n",
    "\toutput = Dense(Y.shape[1], kernel_initializer=initializer, activation='softmax',name=\"dense_ec\")(merge)\n",
    "\tmodel = Model(inputs=ensemble_visible, outputs=output)\n",
    "\t# plot graph of ensemble\n",
    "\tplot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "\t# compile\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "#neural\n",
    "import datetime\n",
    "\n",
    "\n",
    "#colab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_7= [\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "\n",
    "def fit_stacked_model(model, inputX, inputy_enc):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# encode output data\n",
    "#\tinputy_enc = to_categorical(inputy)\n",
    "\t# fit model\n",
    "\thistory_7=model.fit(X, inputy_enc, epochs=7, verbose=2,callbacks=[monitor_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a stacked model\n",
    "#neural\n",
    "def predict_stacked_model(model, inputX):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# make prediction\n",
    "\treturn model.predict(X, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded /home/marius1406/20231010221344/model1_1.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_2.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_3.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_6.h5\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "#neural\n",
    "\n",
    "colab_write_path = \"/home/marius1406/\"\n",
    "colab_model_write_path = colab_write_path +\"20231010221344/\"\n",
    "\n",
    "from keras.models import load_model\n",
    "n_members = 6\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_2a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_3a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_6a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_1a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2a (Dense)    (None, 64)           8192        ['dense_2a_input[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ensemble_3_dense_3a (Dense)    (None, 512)          65536       ['dense_3a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6a (Dense)    (None, 256)          32768       ['dense_6a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1a (Dense)    (None, 64)           8192        ['dense_1a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2b (Dense)    (None, 128)          8320        ['ensemble_2_dense_2a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_11 (Dropout  (None, 512)         0           ['ensemble_3_dense_3a[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_3 (Dropout)  (None, 256)         0           ['ensemble_4_dense_6a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1b (Dense)    (None, 128)          8320        ['ensemble_1_dense_1a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_8 (Dropout)  (None, 128)         0           ['ensemble_2_dense_2b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3b (Dense)    (None, 256)          131328      ['ensemble_3_dropout_11[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6b (Dense)    (None, 128)          32896       ['ensemble_4_dropout_3[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_6 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2c (Dense)    (None, 256)          33024       ['ensemble_2_dropout_8[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_12 (Dropout  (None, 256)         0           ['ensemble_3_dense_3b[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_4 (Dropout)  (None, 128)         0           ['ensemble_4_dense_6b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1c (Dense)    (None, 128)          16512       ['ensemble_1_dropout_6[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_9 (Dropout)  (None, 256)         0           ['ensemble_2_dense_2c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3c (Dense)    (None, 128)          32896       ['ensemble_3_dropout_12[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6c (Dense)    (None, 128)          16512       ['ensemble_4_dropout_4[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_7 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2d (Dense)    (None, 128)          32896       ['ensemble_2_dropout_9[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_13 (Dropout  (None, 128)         0           ['ensemble_3_dense_3c[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_5 (Dropout)  (None, 128)         0           ['ensemble_4_dense_6c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1d (Dense)    (None, 64)           8256        ['ensemble_1_dropout_7[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_10 (Dropout  (None, 128)         0           ['ensemble_2_dense_2d[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3d (Dense)    (None, 128)          16512       ['ensemble_3_dropout_13[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6d (Dense)    (None, 64)           8256        ['ensemble_4_dropout_5[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1_dense_2 (Dense)     (None, 21)           1365        ['ensemble_1_dense_1d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_3 (Dense)     (None, 21)           2709        ['ensemble_2_dropout_10[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_3_dense_4 (Dense)     (None, 21)           2709        ['ensemble_3_dense_3d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_4_dense_1 (Dense)     (None, 21)           1365        ['ensemble_4_dense_6d[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 84)           0           ['ensemble_1_dense_2[0][0]',     \n",
      "                                                                  'ensemble_2_dense_3[0][0]',     \n",
      "                                                                  'ensemble_3_dense_4[0][0]',     \n",
      "                                                                  'ensemble_4_dense_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_ea (Dense)               (None, 128)          10880       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_eb (Dense)               (None, 128)          16512       ['dense_ea[0][0]']               \n",
      "                                                                                                  \n",
      " dense_ec (Dense)               (None, 21)           2709        ['dense_eb[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 498,665\n",
      "Trainable params: 30,101\n",
      "Non-trainable params: 468,564\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define ensemble model\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.utils import plot_model\n",
    "#neural\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "27250/27250 - 84s - loss: 0.0657 - accuracy: 0.9838 - 84s/epoch - 3ms/step\n",
      "Epoch 2/7\n",
      "27250/27250 - 83s - loss: 0.0590 - accuracy: 0.9846 - 83s/epoch - 3ms/step\n",
      "Epoch 3/7\n",
      "27250/27250 - 86s - loss: 0.0584 - accuracy: 0.9847 - 86s/epoch - 3ms/step\n",
      "Epoch 4/7\n",
      "27250/27250 - 81s - loss: 0.0583 - accuracy: 0.9847 - 81s/epoch - 3ms/step\n",
      "Epoch 5/7\n",
      "27250/27250 - 82s - loss: 0.0580 - accuracy: 0.9846 - 82s/epoch - 3ms/step\n",
      "Epoch 6/7\n",
      "27250/27250 - 83s - loss: 0.0578 - accuracy: 0.9847 - 83s/epoch - 3ms/step\n",
      "Epoch 7/7\n",
      "27250/27250 - 83s - loss: 0.0576 - accuracy: 0.9848 - 83s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "fit_stacked_model(stacked_model, x_train,y_train)\n",
    "stacked_model.save(colab_model_write_path + 'stacked_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 12s - 12s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.89      0.94      0.91        51\n",
      "           2       0.99      0.99      0.99     72091\n",
      "           3       1.00      1.00      1.00       433\n",
      "           4       1.00      0.97      0.98       365\n",
      "           5       0.99      0.99      0.99     62503\n",
      "           6       0.98      0.99      0.99     51385\n",
      "           7       0.64      0.74      0.69        78\n",
      "           8       0.46      0.57      0.51        67\n",
      "           9       0.94      0.73      0.82        62\n",
      "          10       0.93      0.20      0.33       349\n",
      "          11       0.98      0.95      0.96      7418\n",
      "          12       1.00      0.60      0.75         5\n",
      "          13       0.67      0.44      0.53         9\n",
      "          15       0.86      0.77      0.81      1989\n",
      "          16       0.78      0.41      0.54        17\n",
      "          17       0.93      0.91      0.92      3272\n",
      "          18       1.00      0.80      0.89        15\n",
      "          19       0.97      0.98      0.97     10833\n",
      "          20       0.93      0.98      0.95      7055\n",
      "\n",
      "    accuracy                           0.98    218000\n",
      "   macro avg       0.85      0.75      0.78    218000\n",
      "weighted avg       0.98      0.98      0.98    218000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00         3\\n           1       0.89      0.94      0.91        51\\n           2       0.99      0.99      0.99     72091\\n           3       1.00      1.00      1.00       433\\n           4       1.00      0.97      0.98       365\\n           5       0.99      0.99      0.99     62503\\n           6       0.98      0.99      0.99     51385\\n           7       0.64      0.74      0.69        78\\n           8       0.46      0.57      0.51        67\\n           9       0.94      0.73      0.82        62\\n          10       0.93      0.20      0.33       349\\n          11       0.98      0.95      0.96      7418\\n          12       1.00      0.60      0.75         5\\n          13       0.67      0.44      0.53         9\\n          15       0.86      0.77      0.81      1989\\n          16       0.78      0.41      0.54        17\\n          17       0.93      0.91      0.92      3272\\n          18       1.00      0.80      0.89        15\\n          19       0.97      0.98      0.97     10833\\n          20       0.93      0.98      0.95      7055\\n\\n    accuracy                           0.98    218000\\n   macro avg       0.85      0.75      0.78    218000\\nweighted avg       0.98      0.98      0.98    218000\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_1, yhat_val))\n",
    "classification_report(y_test_1, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 12s - 12s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fbbebd137d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 predict 수행\n",
    "# 모델 성능 - confusion matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test_1, y_pred=yhat_val)\n",
    "conf_mat\n",
    "\n",
    "disp = ConfusionMatrixDisplay(conf_mat)\n",
    "#disp = ConfusionMatrixDisplay(conf_mat)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
