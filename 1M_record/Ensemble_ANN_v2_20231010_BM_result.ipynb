{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 15:50:55.210980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 기본라이브러리 import\n",
    "#from google.colab import drive\n",
    "#import os, json, pickle\n",
    "#import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# 파이토치 라이브러리 import\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "#Keras Import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import ipaddress\n",
    "\n",
    "# 구글 드라이브 mount\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# 데이터 파일 위치\n",
    "#C:\\Users\\mariu\\내 드라이브\\Colab Notebooks\\Network\n",
    "colab_path = '/home/marius1406/'\n",
    "colab_write_path = \"/home/marius1406/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_path = \"/home/marius1406/\"\n",
    "df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False, nrows=1089999)\n",
    "#df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장판에서 사용\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'DNS_QUERY_ID','Label','Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR_1','IPV4_SRC_ADDR_2','Label','Attack','Dataset', 'Label_1','Attack_1','Dataset_1', 'Label_2','Attack_2','Dataset_2'])  #명목형변수, 레이블 변수 제외\n",
    "cols = df.columns.drop(['Label','Attack'])  #명목형변수, 레이블 변수 제외#cols = df.columns.drop(['Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "X = df[cols]\n",
    "dummies = pd.get_dummies(df['Attack']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "Y = dummies.values\n",
    "\n",
    "#==================\n",
    "dummiesLabel = pd.get_dummies(df['Label']) # Classification\n",
    "y_1_label = df['Label'].values\n",
    "y_label = dummiesLabel.values\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "def extend_sparse(val):\n",
    "    if val in ['Analysis', 'Exploits', 'Fuzzers', 'Shellcode', 'Theft', 'Worms', 'mitm']: return 1\n",
    "    return 0\n",
    "\n",
    "y_1_attack = pd.DataFrame(df['Attack'])\n",
    "\n",
    "is_sparse = y_1_attack.applymap(extend_sparse)\n",
    "y_1_enforce = is_sparse.values\n",
    "y_enforce = pd.get_dummies(is_sparse['Attack']) # Classification\n",
    "\n",
    "#=======================\n",
    "\n",
    "def max_8G(val):\n",
    "    if (val > 1.0e+9): return 1.0e+9\n",
    "    return val\n",
    "\n",
    "#cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT']\n",
    "cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "'DST_TO_SRC_SECOND_BYTES_1', 'SRC_TO_DST_SECOND_BYTES_1', 'SRC_TO_DST_AVG_THROUGHPUT_1', 'DST_TO_SRC_AVG_THROUGHPUT_1',\n",
    "'DST_TO_SRC_SECOND_BYTES_2', 'SRC_TO_DST_SECOND_BYTES_2', 'SRC_TO_DST_AVG_THROUGHPUT_2', 'DST_TO_SRC_AVG_THROUGHPUT_2'] \n",
    "\n",
    "X[cols] = X[cols].applymap(max_8G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 4291722866\n",
      "L4_SRC_PORT 65535\n",
      "IPV4_DST_ADDR 4294967295\n",
      "L4_DST_PORT 65535\n",
      "PROTOCOL 254\n",
      "L7_PROTO 248.0\n",
      "IN_BYTES 34641563\n",
      "IN_PKTS 123763\n",
      "OUT_BYTES 129573662\n",
      "OUT_PKTS 87179\n",
      "TCP_FLAGS 223\n",
      "CLIENT_TCP_FLAGS 223\n",
      "SERVER_TCP_FLAGS 223\n",
      "FLOW_DURATION_MILLISECONDS 4294967\n",
      "DURATION_IN 105400\n",
      "DURATION_OUT 38547\n",
      "MIN_TTL 255\n",
      "MAX_TTL 255\n",
      "LONGEST_FLOW_PKT 7292\n",
      "SHORTEST_FLOW_PKT 1504\n",
      "MIN_IP_PKT_LEN 547\n",
      "MAX_IP_PKT_LEN 7292\n",
      "SRC_TO_DST_SECOND_BYTES 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES 6321251\n",
      "RETRANSMITTED_IN_PKTS 4774\n",
      "RETRANSMITTED_OUT_BYTES 2183347\n",
      "RETRANSMITTED_OUT_PKTS 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES 191858\n",
      "NUM_PKTS_128_TO_256_BYTES 7230\n",
      "NUM_PKTS_256_TO_512_BYTES 4921\n",
      "NUM_PKTS_512_TO_1024_BYTES 34443\n",
      "NUM_PKTS_1024_TO_1514_BYTES 86096\n",
      "TCP_WIN_MAX_IN 65535\n",
      "TCP_WIN_MAX_OUT 65535\n",
      "ICMP_TYPE 65280\n",
      "ICMP_IPV4_TYPE 255\n",
      "DNS_QUERY_ID 65535\n",
      "DNS_QUERY_TYPE 32769\n",
      "DNS_TTL_ANSWER 4294915672\n",
      "FTP_COMMAND_RET_CODE 550.0\n",
      "L4_SRC_PORT_1 65535\n",
      "IPV4_DST_ADDR_1 4294967295\n",
      "L4_DST_PORT_1 65535\n",
      "PROTOCOL_1 254\n",
      "L7_PROTO_1 248.0\n",
      "IN_BYTES_1 32341314\n",
      "IN_PKTS_1 123763\n",
      "OUT_BYTES_1 129573662\n",
      "OUT_PKTS_1 87179\n",
      "TCP_FLAGS_1 223\n",
      "CLIENT_TCP_FLAGS_1 223\n",
      "SERVER_TCP_FLAGS_1 223\n",
      "FLOW_DURATION_MILLISECONDS_1 4294967\n",
      "DURATION_IN_1 105400\n",
      "DURATION_OUT_1 38547\n",
      "MIN_TTL_1 255\n",
      "MAX_TTL_1 255\n",
      "LONGEST_FLOW_PKT_1 7292\n",
      "SHORTEST_FLOW_PKT_1 1504\n",
      "MIN_IP_PKT_LEN_1 547\n",
      "MAX_IP_PKT_LEN_1 7292\n",
      "SRC_TO_DST_SECOND_BYTES_1 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_1 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_1 6321251\n",
      "RETRANSMITTED_IN_PKTS_1 4774\n",
      "RETRANSMITTED_OUT_BYTES_1 2183347\n",
      "RETRANSMITTED_OUT_PKTS_1 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_1 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_1 3406\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 18388\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 86096\n",
      "TCP_WIN_MAX_IN_1 65535\n",
      "TCP_WIN_MAX_OUT_1 65535\n",
      "ICMP_TYPE_1 65280\n",
      "ICMP_IPV4_TYPE_1 255\n",
      "DNS_QUERY_ID_1 65535\n",
      "DNS_QUERY_TYPE_1 32769\n",
      "DNS_TTL_ANSWER_1 4294915672\n",
      "FTP_COMMAND_RET_CODE_1 550.0\n",
      "L4_SRC_PORT_2 65535\n",
      "IPV4_DST_ADDR_2 4294967295\n",
      "L4_DST_PORT_2 65535\n",
      "PROTOCOL_2 254\n",
      "L7_PROTO_2 245.178\n",
      "IN_BYTES_2 33337052\n",
      "IN_PKTS_2 123763\n",
      "OUT_BYTES_2 129573662\n",
      "OUT_PKTS_2 87179\n",
      "TCP_FLAGS_2 223\n",
      "CLIENT_TCP_FLAGS_2 223\n",
      "SERVER_TCP_FLAGS_2 223\n",
      "FLOW_DURATION_MILLISECONDS_2 4294967\n",
      "DURATION_IN_2 105400\n",
      "DURATION_OUT_2 38547\n",
      "MIN_TTL_2 255\n",
      "MAX_TTL_2 255\n",
      "LONGEST_FLOW_PKT_2 7292\n",
      "SHORTEST_FLOW_PKT_2 1504\n",
      "MIN_IP_PKT_LEN_2 422\n",
      "MAX_IP_PKT_LEN_2 7292\n",
      "SRC_TO_DST_SECOND_BYTES_2 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_2 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_2 6321251\n",
      "RETRANSMITTED_IN_PKTS_2 4774\n",
      "RETRANSMITTED_OUT_BYTES_2 1109291\n",
      "RETRANSMITTED_OUT_PKTS_2 824\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_2 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_2 3446\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 18954\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 86096\n",
      "TCP_WIN_MAX_IN_2 65535\n",
      "TCP_WIN_MAX_OUT_2 65535\n",
      "ICMP_TYPE_2 65280\n",
      "ICMP_IPV4_TYPE_2 255\n",
      "DNS_QUERY_ID_2 65535\n",
      "DNS_QUERY_TYPE_2 32769\n",
      "DNS_TTL_ANSWER_2 4294915672\n",
      "FTP_COMMAND_RET_CODE_2 550.0\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scaler_train = preprocessing.StandardScaler()\n",
    "scaler_train = scaler_train.fit(X)\n",
    "X = pd.DataFrame(scaler_train.transform(X),index=np.arange(0,X.shape[0],1), columns = X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 0\n",
      "L4_SRC_PORT 0\n",
      "IPV4_DST_ADDR 0\n",
      "L4_DST_PORT 0\n",
      "PROTOCOL 0\n",
      "L7_PROTO 0\n",
      "IN_BYTES 0\n",
      "IN_PKTS 0\n",
      "OUT_BYTES 0\n",
      "OUT_PKTS 0\n",
      "TCP_FLAGS 0\n",
      "CLIENT_TCP_FLAGS 0\n",
      "SERVER_TCP_FLAGS 0\n",
      "FLOW_DURATION_MILLISECONDS 0\n",
      "DURATION_IN 0\n",
      "DURATION_OUT 0\n",
      "MIN_TTL 0\n",
      "MAX_TTL 0\n",
      "LONGEST_FLOW_PKT 0\n",
      "SHORTEST_FLOW_PKT 0\n",
      "MIN_IP_PKT_LEN 0\n",
      "MAX_IP_PKT_LEN 0\n",
      "SRC_TO_DST_SECOND_BYTES 0\n",
      "DST_TO_SRC_SECOND_BYTES 0\n",
      "RETRANSMITTED_IN_BYTES 0\n",
      "RETRANSMITTED_IN_PKTS 0\n",
      "RETRANSMITTED_OUT_BYTES 0\n",
      "RETRANSMITTED_OUT_PKTS 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 0\n",
      "NUM_PKTS_UP_TO_128_BYTES 0\n",
      "NUM_PKTS_128_TO_256_BYTES 0\n",
      "NUM_PKTS_256_TO_512_BYTES 0\n",
      "NUM_PKTS_512_TO_1024_BYTES 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES 0\n",
      "TCP_WIN_MAX_IN 0\n",
      "TCP_WIN_MAX_OUT 0\n",
      "ICMP_TYPE 0\n",
      "ICMP_IPV4_TYPE 0\n",
      "DNS_QUERY_ID 0\n",
      "DNS_QUERY_TYPE 0\n",
      "DNS_TTL_ANSWER 0\n",
      "FTP_COMMAND_RET_CODE 0\n",
      "L4_SRC_PORT_1 0\n",
      "IPV4_DST_ADDR_1 0\n",
      "L4_DST_PORT_1 0\n",
      "PROTOCOL_1 0\n",
      "L7_PROTO_1 0\n",
      "IN_BYTES_1 0\n",
      "IN_PKTS_1 0\n",
      "OUT_BYTES_1 0\n",
      "OUT_PKTS_1 0\n",
      "TCP_FLAGS_1 0\n",
      "CLIENT_TCP_FLAGS_1 0\n",
      "SERVER_TCP_FLAGS_1 0\n",
      "FLOW_DURATION_MILLISECONDS_1 0\n",
      "DURATION_IN_1 0\n",
      "DURATION_OUT_1 0\n",
      "MIN_TTL_1 0\n",
      "MAX_TTL_1 0\n",
      "LONGEST_FLOW_PKT_1 0\n",
      "SHORTEST_FLOW_PKT_1 0\n",
      "MIN_IP_PKT_LEN_1 0\n",
      "MAX_IP_PKT_LEN_1 0\n",
      "SRC_TO_DST_SECOND_BYTES_1 0\n",
      "DST_TO_SRC_SECOND_BYTES_1 0\n",
      "RETRANSMITTED_IN_BYTES_1 0\n",
      "RETRANSMITTED_IN_PKTS_1 0\n",
      "RETRANSMITTED_OUT_BYTES_1 0\n",
      "RETRANSMITTED_OUT_PKTS_1 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 0\n",
      "NUM_PKTS_128_TO_256_BYTES_1 0\n",
      "NUM_PKTS_256_TO_512_BYTES_1 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 0\n",
      "TCP_WIN_MAX_IN_1 0\n",
      "TCP_WIN_MAX_OUT_1 0\n",
      "ICMP_TYPE_1 0\n",
      "ICMP_IPV4_TYPE_1 0\n",
      "DNS_QUERY_ID_1 0\n",
      "DNS_QUERY_TYPE_1 0\n",
      "DNS_TTL_ANSWER_1 0\n",
      "FTP_COMMAND_RET_CODE_1 0\n",
      "L4_SRC_PORT_2 0\n",
      "IPV4_DST_ADDR_2 0\n",
      "L4_DST_PORT_2 0\n",
      "PROTOCOL_2 0\n",
      "L7_PROTO_2 0\n",
      "IN_BYTES_2 0\n",
      "IN_PKTS_2 0\n",
      "OUT_BYTES_2 0\n",
      "OUT_PKTS_2 0\n",
      "TCP_FLAGS_2 0\n",
      "CLIENT_TCP_FLAGS_2 0\n",
      "SERVER_TCP_FLAGS_2 0\n",
      "FLOW_DURATION_MILLISECONDS_2 0\n",
      "DURATION_IN_2 0\n",
      "DURATION_OUT_2 0\n",
      "MIN_TTL_2 0\n",
      "MAX_TTL_2 0\n",
      "LONGEST_FLOW_PKT_2 0\n",
      "SHORTEST_FLOW_PKT_2 0\n",
      "MIN_IP_PKT_LEN_2 0\n",
      "MAX_IP_PKT_LEN_2 0\n",
      "SRC_TO_DST_SECOND_BYTES_2 0\n",
      "DST_TO_SRC_SECOND_BYTES_2 0\n",
      "RETRANSMITTED_IN_BYTES_2 0\n",
      "RETRANSMITTED_IN_PKTS_2 0\n",
      "RETRANSMITTED_OUT_BYTES_2 0\n",
      "RETRANSMITTED_OUT_PKTS_2 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 0\n",
      "NUM_PKTS_128_TO_256_BYTES_2 0\n",
      "NUM_PKTS_256_TO_512_BYTES_2 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 0\n",
      "TCP_WIN_MAX_IN_2 0\n",
      "TCP_WIN_MAX_OUT_2 0\n",
      "ICMP_TYPE_2 0\n",
      "ICMP_IPV4_TYPE_2 0\n",
      "DNS_QUERY_ID_2 0\n",
      "DNS_QUERY_TYPE_2 0\n",
      "DNS_TTL_ANSWER_2 0\n",
      "FTP_COMMAND_RET_CODE_2 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].isna().sum())\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_3sigma(val):\n",
    "    if (val < -3): return -3\n",
    "    if (val > 3): return 3\n",
    "    return val\n",
    "\n",
    "X = X.applymap(max_3sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 15:51:57.118423: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.argmax(dummies, axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_label, y_train_label, y_test_label = train_test_split(X, y_label, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_enforce, y_train_enforce, y_test_enforce = train_test_split(X, y_enforce, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_1, y_train_1, y_test_1 = train_test_split(X, y1.numpy(), test_size=0.20, shuffle = True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_write_path = \"/home/marius1406/\"\n",
    "colab_model_write_path = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M\" + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_1 = tf.keras.Sequential([\\n  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation=\\'relu\\'),\\n  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation=\\'softmax\\')\\n  ])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1\n",
    "#initializer = \"glorot_uniform\"\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu',name='dense_1a'),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1b'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1c'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1d'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "  ])\n",
    "'''\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation='softmax')\n",
    "  ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marius1406/20231010221352\n",
      "Epoch 1/100\n",
      "852/852 - 10s - loss: 0.2878 - accuracy: 0.9140 - val_loss: 0.1270 - val_accuracy: 0.9654 - 10s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "852/852 - 20s - loss: 0.1290 - accuracy: 0.9653 - val_loss: 0.1031 - val_accuracy: 0.9727 - 20s/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "852/852 - 11s - loss: 0.1105 - accuracy: 0.9708 - val_loss: 0.0938 - val_accuracy: 0.9753 - 11s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "852/852 - 14s - loss: 0.1012 - accuracy: 0.9734 - val_loss: 0.0869 - val_accuracy: 0.9771 - 14s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "852/852 - 15s - loss: 0.0947 - accuracy: 0.9749 - val_loss: 0.0852 - val_accuracy: 0.9774 - 15s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "852/852 - 14s - loss: 0.0906 - accuracy: 0.9761 - val_loss: 0.0807 - val_accuracy: 0.9787 - 14s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "852/852 - 17s - loss: 0.0876 - accuracy: 0.9767 - val_loss: 0.0793 - val_accuracy: 0.9792 - 17s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "852/852 - 23s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0764 - val_accuracy: 0.9796 - 23s/epoch - 27ms/step\n",
      "Epoch 9/100\n",
      "852/852 - 23s - loss: 0.0828 - accuracy: 0.9779 - val_loss: 0.0754 - val_accuracy: 0.9801 - 23s/epoch - 27ms/step\n",
      "Epoch 10/100\n",
      "852/852 - 19s - loss: 0.0818 - accuracy: 0.9782 - val_loss: 0.0751 - val_accuracy: 0.9793 - 19s/epoch - 22ms/step\n",
      "Epoch 11/100\n",
      "852/852 - 12s - loss: 0.0798 - accuracy: 0.9785 - val_loss: 0.0744 - val_accuracy: 0.9800 - 12s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "852/852 - 16s - loss: 0.0789 - accuracy: 0.9788 - val_loss: 0.0742 - val_accuracy: 0.9802 - 16s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "852/852 - 14s - loss: 0.0779 - accuracy: 0.9791 - val_loss: 0.0747 - val_accuracy: 0.9801 - 14s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "852/852 - 19s - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.0730 - val_accuracy: 0.9804 - 19s/epoch - 22ms/step\n",
      "Epoch 15/100\n",
      "852/852 - 18s - loss: 0.0761 - accuracy: 0.9794 - val_loss: 0.0741 - val_accuracy: 0.9808 - 18s/epoch - 22ms/step\n",
      "Epoch 16/100\n",
      "852/852 - 15s - loss: 0.0753 - accuracy: 0.9797 - val_loss: 0.0711 - val_accuracy: 0.9812 - 15s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "852/852 - 10s - loss: 0.0748 - accuracy: 0.9799 - val_loss: 0.0711 - val_accuracy: 0.9808 - 10s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "852/852 - 11s - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.0693 - val_accuracy: 0.9815 - 11s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "852/852 - 13s - loss: 0.0732 - accuracy: 0.9802 - val_loss: 0.0701 - val_accuracy: 0.9810 - 13s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "852/852 - 12s - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.0693 - val_accuracy: 0.9813 - 12s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "852/852 - 16s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0699 - val_accuracy: 0.9814 - 16s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "852/852 - 32s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0687 - val_accuracy: 0.9816 - 32s/epoch - 37ms/step\n",
      "Epoch 23/100\n",
      "852/852 - 26s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0685 - val_accuracy: 0.9818 - 26s/epoch - 30ms/step\n",
      "Epoch 24/100\n",
      "852/852 - 18s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0686 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "852/852 - 17s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9818 - 17s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "852/852 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "852/852 - 10s - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0671 - val_accuracy: 0.9820 - 10s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "852/852 - 11s - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0683 - val_accuracy: 0.9818 - 11s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "852/852 - 10s - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0684 - val_accuracy: 0.9813 - 10s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "852/852 - 15s - loss: 0.0694 - accuracy: 0.9812 - val_loss: 0.0669 - val_accuracy: 0.9821 - 15s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "852/852 - 13s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0676 - val_accuracy: 0.9819 - 13s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "852/852 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0659 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "852/852 - 14s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0664 - val_accuracy: 0.9824 - 14s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "852/852 - 20s - loss: 0.0681 - accuracy: 0.9815 - val_loss: 0.0653 - val_accuracy: 0.9826 - 20s/epoch - 23ms/step\n",
      "Epoch 35/100\n",
      "852/852 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0675 - val_accuracy: 0.9821 - 12s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "852/852 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0655 - val_accuracy: 0.9823 - 12s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "852/852 - 10s - loss: 0.0677 - accuracy: 0.9817 - val_loss: 0.0656 - val_accuracy: 0.9826 - 10s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "852/852 - 10s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0652 - val_accuracy: 0.9823 - 10s/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "852/852 - 18s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0683 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "852/852 - 20s - loss: 0.0673 - accuracy: 0.9818 - val_loss: 0.0674 - val_accuracy: 0.9816 - 20s/epoch - 23ms/step\n",
      "Epoch 41/100\n",
      "852/852 - 26s - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.0653 - val_accuracy: 0.9828 - 26s/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "852/852 - 34s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0659 - val_accuracy: 0.9825 - 34s/epoch - 40ms/step\n",
      "Epoch 43/100\n",
      "852/852 - 30s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 30s/epoch - 35ms/step\n",
      "Epoch 44/100\n",
      "852/852 - 19s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 19s/epoch - 22ms/step\n",
      "Epoch 45/100\n",
      "852/852 - 21s - loss: 0.0665 - accuracy: 0.9819 - val_loss: 0.0654 - val_accuracy: 0.9825 - 21s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "852/852 - 13s - loss: 0.0664 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9827 - 13s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "852/852 - 10s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0659 - val_accuracy: 0.9825 - 10s/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "852/852 - 13s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0655 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "852/852 - 11s - loss: 0.0659 - accuracy: 0.9821 - val_loss: 0.0654 - val_accuracy: 0.9826 - 11s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "852/852 - 18s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0656 - val_accuracy: 0.9823 - 18s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "852/852 - 16s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0641 - val_accuracy: 0.9827 - 16s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "852/852 - 18s - loss: 0.0655 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9827 - 18s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "852/852 - 15s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0644 - val_accuracy: 0.9827 - 15s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "852/852 - 13s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9827 - 13s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "852/852 - 24s - loss: 0.0653 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9827 - 24s/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "852/852 - 14s - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9831 - 14s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "852/852 - 26s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.9825 - 26s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "852/852 - 26s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0642 - val_accuracy: 0.9826 - 26s/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "852/852 - 20s - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.0645 - val_accuracy: 0.9828 - 20s/epoch - 23ms/step\n",
      "Epoch 60/100\n",
      "852/852 - 17s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9829 - 17s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "852/852 - 10s - loss: 0.0645 - accuracy: 0.9826 - val_loss: 0.0644 - val_accuracy: 0.9828 - 10s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "852/852 - 12s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0646 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "852/852 - 13s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0642 - val_accuracy: 0.9829 - 13s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "852/852 - 13s - loss: 0.0644 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "852/852 - 18s - loss: 0.0640 - accuracy: 0.9826 - val_loss: 0.0636 - val_accuracy: 0.9829 - 18s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "852/852 - 12s - loss: 0.0644 - accuracy: 0.9824 - val_loss: 0.0647 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "852/852 - 18s - loss: 0.0642 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9830 - 18s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "852/852 - 11s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0635 - val_accuracy: 0.9829 - 11s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "852/852 - 10s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9828 - 10s/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "852/852 - 13s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0627 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "852/852 - 16s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9830 - 16s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "852/852 - 15s - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0640 - val_accuracy: 0.9831 - 15s/epoch - 18ms/step\n",
      "Epoch 73/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0639 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0632 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "852/852 - 10s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "852/852 - 10s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9831 - 10s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "852/852 - 12s - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0628 - val_accuracy: 0.9832 - 12s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "852/852 - 16s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0620 - val_accuracy: 0.9834 - 16s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "852/852 - 26s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0635 - val_accuracy: 0.9831 - 26s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "852/852 - 17s - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9827 - 17s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "852/852 - 17s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9832 - 17s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "852/852 - 7s - loss: 0.0631 - accuracy: 0.9830 - val_loss: 0.0621 - val_accuracy: 0.9834 - 7s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "852/852 - 10s - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.0628 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "852/852 - 15s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0624 - val_accuracy: 0.9832 - 15s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "852/852 - 23s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9833 - 23s/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "852/852 - 13s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "852/852 - 24s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0629 - val_accuracy: 0.9831 - 24s/epoch - 28ms/step\n",
      "Epoch 88/100\n",
      "852/852 - 31s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9832 - 31s/epoch - 36ms/step\n",
      "Epoch 89/100\n",
      "852/852 - 7s - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9833 - 7s/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "852/852 - 11s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9834 - 11s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "852/852 - 13s - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.0630 - val_accuracy: 0.9833 - 13s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "852/852 - 27s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9834 - 27s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "852/852 - 28s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0618 - val_accuracy: 0.9834 - 28s/epoch - 33ms/step\n",
      "Epoch 94/100\n",
      "852/852 - 25s - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0623 - val_accuracy: 0.9833 - 25s/epoch - 30ms/step\n",
      "Epoch 95/100\n",
      "852/852 - 10s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9823 - 10s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "852/852 - 12s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9836 - 12s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "852/852 - 27s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9836 - 27s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "852/852 - 8s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9835 - 8s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "852/852 - 9s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9834 - 9s/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "852/852 - 18s - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9835 - 18s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model_1.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_1 = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(log_dir_1)\n",
    "monitor_1 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "            ]\n",
    "history_1  = model_1.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=1024, epochs=100)\n",
    "model_1.save(colab_model_write_path + 'model1.h5')\n",
    "#history_1  = model_1.fit(x_train,y_train,validation_split=0.2, callbacks=[monitor_1],verbose=2, batch_size=1024, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  model 2  with different structure\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_2a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, activation='relu',name='dense_2b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(256, input_dim=128, kernel_initializer=initializer, activation='relu',name='dense_2c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=256, kernel_initializer=initializer, activation='relu',name='dense_2d'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 14s - loss: 0.2063 - accuracy: 0.9384 - val_loss: 0.1091 - val_accuracy: 0.9693 - 14s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 15s - loss: 0.1104 - accuracy: 0.9704 - val_loss: 0.0928 - val_accuracy: 0.9750 - 15s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 12s - loss: 0.0971 - accuracy: 0.9739 - val_loss: 0.0835 - val_accuracy: 0.9780 - 12s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 16s - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.0814 - val_accuracy: 0.9785 - 16s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 12s - loss: 0.0865 - accuracy: 0.9769 - val_loss: 0.0774 - val_accuracy: 0.9796 - 12s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 13s - loss: 0.0833 - accuracy: 0.9778 - val_loss: 0.0785 - val_accuracy: 0.9796 - 13s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 13s - loss: 0.0815 - accuracy: 0.9782 - val_loss: 0.0755 - val_accuracy: 0.9798 - 13s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0793 - accuracy: 0.9787 - val_loss: 0.0725 - val_accuracy: 0.9802 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 12s - loss: 0.0780 - accuracy: 0.9791 - val_loss: 0.0717 - val_accuracy: 0.9808 - 12s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 13s - loss: 0.0767 - accuracy: 0.9793 - val_loss: 0.0705 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 12s - loss: 0.0757 - accuracy: 0.9796 - val_loss: 0.0700 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 12s - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.0705 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 12s - loss: 0.0741 - accuracy: 0.9799 - val_loss: 0.0699 - val_accuracy: 0.9812 - 12s/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 15s - loss: 0.0736 - accuracy: 0.9801 - val_loss: 0.0692 - val_accuracy: 0.9813 - 15s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 14s - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0691 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 13s - loss: 0.0721 - accuracy: 0.9805 - val_loss: 0.0671 - val_accuracy: 0.9821 - 13s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 14s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9819 - 14s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.0695 - val_accuracy: 0.9813 - 13s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 12s - loss: 0.0704 - accuracy: 0.9809 - val_loss: 0.0670 - val_accuracy: 0.9817 - 12s/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 12s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0668 - val_accuracy: 0.9818 - 12s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0665 - val_accuracy: 0.9819 - 13s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 15s - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.0651 - val_accuracy: 0.9822 - 15s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 17s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0693 - val_accuracy: 0.9816 - 17s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 14s - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.0648 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 14s - loss: 0.0688 - accuracy: 0.9813 - val_loss: 0.0657 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0653 - val_accuracy: 0.9823 - 13s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0642 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 11s - loss: 0.0679 - accuracy: 0.9816 - val_loss: 0.0644 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 12s - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0651 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 12s - loss: 0.0674 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 11s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0646 - val_accuracy: 0.9824 - 11s/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9817 - val_loss: 0.0647 - val_accuracy: 0.9825 - 12s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0643 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 12s - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.0635 - val_accuracy: 0.9828 - 12s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 12s - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0650 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 12s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 11s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0642 - val_accuracy: 0.9827 - 11s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 12s - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.0641 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 12s - loss: 0.0658 - accuracy: 0.9823 - val_loss: 0.0635 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 11s - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0630 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0639 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 12s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0631 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 13s - loss: 0.0653 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9830 - 13s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9823 - val_loss: 0.0634 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0626 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 11s - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.0628 - val_accuracy: 0.9834 - 11s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 12s - loss: 0.0646 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 11s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0626 - val_accuracy: 0.9833 - 11s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0643 - val_accuracy: 0.9831 - 11s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0630 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 12s - loss: 0.0645 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 12s - loss: 0.0641 - accuracy: 0.9827 - val_loss: 0.0625 - val_accuracy: 0.9833 - 12s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0631 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_2 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_2 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "            ]\n",
    "history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_2],verbose=2, batch_size=512, epochs=100)\n",
    "model_2.save(colab_model_write_path + 'model2.h5')\n",
    "\n",
    "#history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3a'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(256, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3d'),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 22s - loss: 0.1728 - accuracy: 0.9499 - val_loss: 0.0947 - val_accuracy: 0.9748 - 22s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 21s - loss: 0.1002 - accuracy: 0.9733 - val_loss: 0.0837 - val_accuracy: 0.9779 - 21s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 22s - loss: 0.0899 - accuracy: 0.9761 - val_loss: 0.0802 - val_accuracy: 0.9786 - 22s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 21s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0785 - val_accuracy: 0.9797 - 21s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 22s - loss: 0.0819 - accuracy: 0.9781 - val_loss: 0.0752 - val_accuracy: 0.9803 - 22s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 20s - loss: 0.0795 - accuracy: 0.9788 - val_loss: 0.0746 - val_accuracy: 0.9801 - 20s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 20s - loss: 0.0770 - accuracy: 0.9792 - val_loss: 0.0728 - val_accuracy: 0.9806 - 20s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 20s - loss: 0.0756 - accuracy: 0.9796 - val_loss: 0.0732 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 20s - loss: 0.0746 - accuracy: 0.9797 - val_loss: 0.0702 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 23s - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.0695 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 23s - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.0690 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 22s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0688 - val_accuracy: 0.9817 - 22s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 20s - loss: 0.0706 - accuracy: 0.9807 - val_loss: 0.0695 - val_accuracy: 0.9815 - 20s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 21s - loss: 0.0700 - accuracy: 0.9809 - val_loss: 0.0691 - val_accuracy: 0.9814 - 21s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 21s - loss: 0.0693 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9815 - 21s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 21s - loss: 0.0691 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9816 - 21s/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 21s - loss: 0.0681 - accuracy: 0.9814 - val_loss: 0.0658 - val_accuracy: 0.9823 - 21s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 20s - loss: 0.0678 - accuracy: 0.9816 - val_loss: 0.0662 - val_accuracy: 0.9822 - 20s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 20s - loss: 0.0671 - accuracy: 0.9814 - val_loss: 0.0654 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 22s - loss: 0.0666 - accuracy: 0.9817 - val_loss: 0.0672 - val_accuracy: 0.9822 - 22s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 23s - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.0656 - val_accuracy: 0.9825 - 23s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 24s - loss: 0.0656 - accuracy: 0.9820 - val_loss: 0.0659 - val_accuracy: 0.9821 - 24s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 20s - loss: 0.0657 - accuracy: 0.9820 - val_loss: 0.0681 - val_accuracy: 0.9816 - 20s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 20s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0655 - val_accuracy: 0.9824 - 20s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 20s - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.0658 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 23s - loss: 0.0649 - accuracy: 0.9823 - val_loss: 0.0668 - val_accuracy: 0.9824 - 23s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "1704/1704 - 24s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9824 - 24s/epoch - 14ms/step\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_3.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_3 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=2, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "history_3  = model_3.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_3],verbose=2, batch_size=512, epochs=100)\n",
    "model_3.save(colab_model_write_path + 'model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4b'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4d'),\n",
    "      tf.keras.layers.Dense(y_train.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 9s - loss: 0.2432 - accuracy: 0.9265 - val_loss: 0.1163 - val_accuracy: 0.9687 - 9s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 9s - loss: 0.1272 - accuracy: 0.9651 - val_loss: 0.0988 - val_accuracy: 0.9741 - 9s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 8s - loss: 0.1102 - accuracy: 0.9701 - val_loss: 0.0887 - val_accuracy: 0.9766 - 8s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.1018 - accuracy: 0.9725 - val_loss: 0.0856 - val_accuracy: 0.9776 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 8s - loss: 0.0972 - accuracy: 0.9740 - val_loss: 0.0831 - val_accuracy: 0.9785 - 8s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 8s - loss: 0.0933 - accuracy: 0.9749 - val_loss: 0.0786 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 9s - loss: 0.0907 - accuracy: 0.9756 - val_loss: 0.0774 - val_accuracy: 0.9796 - 9s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0891 - accuracy: 0.9760 - val_loss: 0.0768 - val_accuracy: 0.9797 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 9s - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.0757 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 9s - loss: 0.0864 - accuracy: 0.9767 - val_loss: 0.0760 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 9s - loss: 0.0852 - accuracy: 0.9770 - val_loss: 0.0734 - val_accuracy: 0.9800 - 9s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 9s - loss: 0.0844 - accuracy: 0.9772 - val_loss: 0.0743 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0835 - accuracy: 0.9775 - val_loss: 0.0741 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 8s - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.0733 - val_accuracy: 0.9804 - 8s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 0.0823 - accuracy: 0.9777 - val_loss: 0.0718 - val_accuracy: 0.9806 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 8s - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.0718 - val_accuracy: 0.9809 - 8s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.0713 - val_accuracy: 0.9807 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.0714 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 0.0801 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9809 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 8s - loss: 0.0798 - accuracy: 0.9783 - val_loss: 0.0704 - val_accuracy: 0.9812 - 8s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 10s - loss: 0.0792 - accuracy: 0.9785 - val_loss: 0.0699 - val_accuracy: 0.9811 - 10s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 9s - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.0700 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 0.0787 - accuracy: 0.9786 - val_loss: 0.0703 - val_accuracy: 0.9810 - 9s/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 9s - loss: 0.0783 - accuracy: 0.9787 - val_loss: 0.0690 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 0.0780 - accuracy: 0.9788 - val_loss: 0.0692 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 8s - loss: 0.0775 - accuracy: 0.9789 - val_loss: 0.0683 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 8s - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9817 - 8s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.0688 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 14s - loss: 0.0768 - accuracy: 0.9791 - val_loss: 0.0693 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 8s - loss: 0.0768 - accuracy: 0.9790 - val_loss: 0.0677 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 0.0766 - accuracy: 0.9792 - val_loss: 0.0681 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 8s - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.0674 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 0.0757 - accuracy: 0.9794 - val_loss: 0.0677 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 0.0759 - accuracy: 0.9793 - val_loss: 0.0673 - val_accuracy: 0.9816 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 8s - loss: 0.0758 - accuracy: 0.9793 - val_loss: 0.0682 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 11s - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.0680 - val_accuracy: 0.9814 - 11s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 0.0753 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 0.0751 - accuracy: 0.9795 - val_loss: 0.0670 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0678 - val_accuracy: 0.9816 - 11s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0750 - accuracy: 0.9794 - val_loss: 0.0675 - val_accuracy: 0.9821 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0672 - val_accuracy: 0.9818 - 11s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0672 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 0.0741 - accuracy: 0.9798 - val_loss: 0.0660 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 8s - loss: 0.0742 - accuracy: 0.9798 - val_loss: 0.0667 - val_accuracy: 0.9822 - 8s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 13s - loss: 0.0741 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9824 - 13s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0658 - val_accuracy: 0.9824 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 9s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0659 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 8s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0661 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 8s - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.0661 - val_accuracy: 0.9820 - 8s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 0.0736 - accuracy: 0.9798 - val_loss: 0.0655 - val_accuracy: 0.9822 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 9s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0653 - val_accuracy: 0.9823 - 9s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 0.0730 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0667 - val_accuracy: 0.9821 - 8s/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0650 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 11s - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.0650 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0655 - val_accuracy: 0.9825 - 8s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 8s - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.0653 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 9s - loss: 0.0726 - accuracy: 0.9802 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 11s - loss: 0.0725 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 9s - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 8s - loss: 0.0728 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 8s - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0645 - val_accuracy: 0.9826 - 8s/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 9s - loss: 0.0721 - accuracy: 0.9804 - val_loss: 0.0643 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 0.0720 - accuracy: 0.9805 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 9s - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.0649 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0653 - val_accuracy: 0.9823 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 11s - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9829 - 11s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 8s - loss: 0.0715 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 0.0715 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9828 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0643 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 8s - loss: 0.0714 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 9s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0651 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 13s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0648 - val_accuracy: 0.9826 - 13s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 11s - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0643 - val_accuracy: 0.9827 - 11s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9808 - val_loss: 0.0643 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 8s - loss: 0.0710 - accuracy: 0.9806 - val_loss: 0.0645 - val_accuracy: 0.9828 - 8s/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.0639 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9806 - val_loss: 0.0642 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0637 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9807 - val_loss: 0.0638 - val_accuracy: 0.9830 - 8s/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9809 - val_loss: 0.0641 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 11s - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9831 - 11s/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.0640 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0633 - val_accuracy: 0.9831 - 10s/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0627 - val_accuracy: 0.9832 - 8s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9810 - val_loss: 0.0639 - val_accuracy: 0.9826 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0632 - val_accuracy: 0.9831 - 13s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9809 - val_loss: 0.0629 - val_accuracy: 0.9832 - 10s/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 8s - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.0634 - val_accuracy: 0.9831 - 8s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 9s - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.0634 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_4 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_4 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_4, histogram_freq=1)\n",
    "        ]\n",
    "history_4  = model_4.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_4],verbose=2, batch_size=512, epochs=100)\n",
    "model_4.save(colab_model_write_path + 'model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_5 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5c'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5d'),\n",
    "      tf.keras.layers.Dense(y_train_enforce.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 11s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9993 - 11s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 10s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 9s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 10s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 9s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 10s - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 9.8441e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 10s - loss: 9.3665e-04 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 9.2064e-04 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 9s - loss: 9.3356e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 8.7414e-04 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 10s - loss: 8.5468e-04 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 9s - loss: 8.3748e-04 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 10s - loss: 8.6668e-04 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 7.5136e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 10s - loss: 8.0980e-04 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 7.3481e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 9s - loss: 6.9155e-04 - accuracy: 0.9998 - val_loss: 0.0045 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 9s - loss: 7.2576e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 6.4573e-04 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 10s - loss: 7.3001e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 10s - loss: 6.0983e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 6.4264e-04 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 9s - loss: 6.1619e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 6.2433e-04 - accuracy: 0.9998 - val_loss: 0.0053 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 6.3250e-04 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 10s - loss: 5.6048e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 9s - loss: 5.4817e-04 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 5.1804e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 5.7661e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 9s - loss: 5.4797e-04 - accuracy: 0.9999 - val_loss: 0.0085 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 9s - loss: 4.9753e-04 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 9s - loss: 5.4127e-04 - accuracy: 0.9999 - val_loss: 0.0097 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 10s - loss: 5.1966e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 4.7119e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 5.0597e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 10s - loss: 5.3273e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 10s - loss: 5.2568e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 4.7804e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 10s - loss: 4.1050e-04 - accuracy: 0.9999 - val_loss: 0.0120 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 9s - loss: 4.3036e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 9s - loss: 4.2457e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 5.9950e-04 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 10s - loss: 4.3468e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 3.7293e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 10s - loss: 4.0470e-04 - accuracy: 0.9999 - val_loss: 0.0087 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 9s - loss: 4.1268e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 9s - loss: 4.2829e-04 - accuracy: 0.9999 - val_loss: 0.0092 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 10s - loss: 3.5180e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 10s - loss: 3.9473e-04 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 10s - loss: 4.5839e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 10s - loss: 3.0135e-04 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 10s - loss: 4.2675e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 9s - loss: 3.2920e-04 - accuracy: 0.9999 - val_loss: 0.0233 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 10s - loss: 5.3860e-04 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 10s - loss: 3.5807e-04 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 3.6816e-04 - accuracy: 0.9999 - val_loss: 0.0187 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 10s - loss: 4.3158e-04 - accuracy: 0.9999 - val_loss: 0.0179 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 3.8634e-04 - accuracy: 0.9999 - val_loss: 0.0275 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 10s - loss: 4.6297e-04 - accuracy: 0.9999 - val_loss: 0.0335 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 10s - loss: 3.7752e-04 - accuracy: 0.9999 - val_loss: 0.0201 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 4.2812e-04 - accuracy: 0.9999 - val_loss: 0.0134 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 3.7992e-04 - accuracy: 0.9999 - val_loss: 0.0262 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 9s - loss: 3.3662e-04 - accuracy: 0.9999 - val_loss: 0.0195 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 10s - loss: 3.5111e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 3.5474e-04 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 10s - loss: 3.6096e-04 - accuracy: 0.9999 - val_loss: 0.0129 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 10s - loss: 5.7303e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 3.3251e-04 - accuracy: 0.9999 - val_loss: 0.0193 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 9s - loss: 3.9361e-04 - accuracy: 0.9999 - val_loss: 0.0203 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 3.1856e-04 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 10s - loss: 3.0138e-04 - accuracy: 0.9999 - val_loss: 0.0224 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 4.1926e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 14s - loss: 4.1826e-04 - accuracy: 0.9999 - val_loss: 0.0204 - val_accuracy: 0.9994 - 14s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 2.9279e-04 - accuracy: 0.9999 - val_loss: 0.0170 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 9s - loss: 3.0474e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 3.6375e-04 - accuracy: 0.9999 - val_loss: 0.0261 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 10s - loss: 3.9308e-04 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9992 - 10s/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 3.3599e-04 - accuracy: 0.9999 - val_loss: 0.0535 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 10s - loss: 4.3944e-04 - accuracy: 0.9999 - val_loss: 0.0341 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 9s - loss: 3.3641e-04 - accuracy: 0.9999 - val_loss: 0.0285 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 3.7667e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 9s - loss: 3.3478e-04 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 11s - loss: 3.2279e-04 - accuracy: 0.9999 - val_loss: 0.0254 - val_accuracy: 0.9994 - 11s/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 3.8158e-04 - accuracy: 0.9999 - val_loss: 0.0329 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 2.9903e-04 - accuracy: 0.9999 - val_loss: 0.0514 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 3.4784e-04 - accuracy: 0.9999 - val_loss: 0.0336 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 10s - loss: 3.5308e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 3.3192e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 9s - loss: 4.5388e-04 - accuracy: 0.9999 - val_loss: 0.0309 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 9s - loss: 6.0361e-04 - accuracy: 0.9999 - val_loss: 0.0196 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 10s - loss: 3.1968e-04 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_5 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_5 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_5, histogram_freq=1)\n",
    "        ]\n",
    "history_5  = model_5.fit(x_train,y_train_enforce,validation_data=(x_test,y_test_enforce), callbacks=[monitor_5],verbose=2, batch_size=512, epochs=100)\n",
    "model_5.save(colab_model_write_path + 'model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(colab_model_write_path + 'model1_1.h5')\n",
    "model_2.save(colab_model_write_path + 'model1_2.h5')\n",
    "model_3.save(colab_model_write_path + 'model1_3.h5')\n",
    "model_4.save(colab_model_write_path + 'model1_4.h5')\n",
    "model_5.save(colab_model_write_path + 'model1_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model 6 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# #type(y_train)\n",
    "# ydp= pd.DataFrame(y_train)\n",
    "# ydp = tf.argmax(ydp, axis=1)\n",
    "# #ydp = pd.DataFrame(ydp)\n",
    "# #ydp.value_counts\n",
    "# dicts = Counter(ydp.numpy())\n",
    "# dicts\n",
    "\n",
    "# MININUM_SAMPLES = 30000\n",
    "# MAXINUM_SAMPLES = 300000\n",
    "\n",
    "# sample_dict = {2: 793860,\n",
    "#          19: 119826,\n",
    "#          6: 564661,\n",
    "#          15: 21588,\n",
    "#          20: 77352,\n",
    "#          5: 687703,\n",
    "#          4: 3987,\n",
    "#          11: 82959,\n",
    "#          17: 36318,\n",
    "#          10: 3759,\n",
    "#          7: 999,\n",
    "#          9: 562,\n",
    "#          3: 4605,\n",
    "#          16: 233,\n",
    "#          1: 592,\n",
    "#          8: 710,\n",
    "#          13: 71,\n",
    "#          18: 92,\n",
    "#          0: 74,\n",
    "#          12: 45,\n",
    "#          14: 4}\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# #ros = RandomOverSampler(random_state=33)\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "#     sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  MININUM_SAMPLES:\n",
    "#     sample_dict[i] =  MININUM_SAMPLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 30000,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 30000,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 30000,\n",
       " 7: 30000,\n",
       " 9: 30000,\n",
       " 3: 30000,\n",
       " 16: 30000,\n",
       " 1: 30000,\n",
       " 8: 30000,\n",
       " 13: 30000,\n",
       " 18: 30000,\n",
       " 0: 30000,\n",
       " 12: 30000,\n",
       " 14: 30000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "# sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 21588,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 3987,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 3759,\n",
       " 7: 999,\n",
       " 9: 562,\n",
       " 3: 4605,\n",
       " 16: 233,\n",
       " 1: 592,\n",
       " 8: 710,\n",
       " 13: 71,\n",
       " 18: 92,\n",
       " 0: 74,\n",
       " 12: 45,\n",
       " 14: 4}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (871999, 127) (871999, 21)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (555103, 127) (555103, 21)\n"
     ]
    }
   ],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_over,y_train_over = smote.fit_resample(x_train,y_train)\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "MININUM_SAMPLES = 10000\n",
    "MAXINUM_SAMPLES = 100000\n",
    "\n",
    "# sample_dict = {5: 687357,\n",
    "#          2: 794288,\n",
    "#          19: 119905,\n",
    "#          15: 21686,\n",
    "#          6: 564557,\n",
    "#          4: 4025,\n",
    "#          11: 82731,\n",
    "#          20: 77617,\n",
    "#          17: 36205,\n",
    "#          3: 4569,\n",
    "#          10: 3752,\n",
    "#          9: 542,\n",
    "#          7: 968,\n",
    "#          8: 694,\n",
    "#          1: 575,\n",
    "#          16: 239,\n",
    "#          0: 81,\n",
    "#          18: 94,\n",
    "#          13: 69,\n",
    "#          12: 42,\n",
    "#          14: 4}\n",
    "\n",
    "sample_dict = {6: 205290,\n",
    "         2: 288786,\n",
    "         5: 249311,\n",
    "         20: 28278,\n",
    "         19: 43885,\n",
    "         11: 29889,\n",
    "         17: 13051,\n",
    "         3: 1639,\n",
    "         15: 7863,\n",
    "         4: 1436,\n",
    "         10: 1354,\n",
    "         8: 256,\n",
    "         9: 185,\n",
    "         7: 373,\n",
    "         18: 31,\n",
    "         1: 214,\n",
    "         13: 17,\n",
    "         16: 86,\n",
    "         0: 38,\n",
    "         12: 13,\n",
    "         14: 4}\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=33)\n",
    "for i in range(21):\n",
    "  if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "    sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "ros = RandomUnderSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_under, y_train_under = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  16:\n",
    "#     sample_dict[i] =  16\n",
    "\n",
    "# ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "for i in range(21):\n",
    "  if sample_dict[i] <  MININUM_SAMPLES:\n",
    "    sample_dict[i] =  MININUM_SAMPLES\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train_under, y_train_under)\n",
    "\n",
    "# sm = SMOTE(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = sm.fit_resample(X_train_over, y_train_over)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "#6 rd model for stack\n",
    "model_6 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6b'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6d'),\n",
    "      tf.keras.layers.Dense(y_train_over.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1085/1085 - 10s - loss: 0.4190 - accuracy: 0.8622 - val_loss: 0.1915 - val_accuracy: 0.9446 - 10s/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "1085/1085 - 8s - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1437 - val_accuracy: 0.9617 - 8s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "1085/1085 - 8s - loss: 0.1844 - accuracy: 0.9437 - val_loss: 0.1276 - val_accuracy: 0.9676 - 8s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1085/1085 - 9s - loss: 0.1657 - accuracy: 0.9494 - val_loss: 0.1276 - val_accuracy: 0.9701 - 9s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "1085/1085 - 9s - loss: 0.1553 - accuracy: 0.9531 - val_loss: 0.1107 - val_accuracy: 0.9716 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1085/1085 - 8s - loss: 0.1465 - accuracy: 0.9555 - val_loss: 0.1217 - val_accuracy: 0.9720 - 8s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1085/1085 - 9s - loss: 0.1415 - accuracy: 0.9571 - val_loss: 0.1092 - val_accuracy: 0.9733 - 9s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "1085/1085 - 8s - loss: 0.1382 - accuracy: 0.9581 - val_loss: 0.1119 - val_accuracy: 0.9725 - 8s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1085/1085 - 8s - loss: 0.1342 - accuracy: 0.9590 - val_loss: 0.1153 - val_accuracy: 0.9727 - 8s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1085/1085 - 8s - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1051 - val_accuracy: 0.9747 - 8s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1085/1085 - 8s - loss: 0.1297 - accuracy: 0.9604 - val_loss: 0.1044 - val_accuracy: 0.9743 - 8s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1085/1085 - 9s - loss: 0.1272 - accuracy: 0.9611 - val_loss: 0.1036 - val_accuracy: 0.9743 - 9s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1085/1085 - 10s - loss: 0.1258 - accuracy: 0.9614 - val_loss: 0.1045 - val_accuracy: 0.9742 - 10s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1085/1085 - 9s - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1062 - val_accuracy: 0.9747 - 9s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "1085/1085 - 9s - loss: 0.1230 - accuracy: 0.9623 - val_loss: 0.1045 - val_accuracy: 0.9750 - 9s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1085/1085 - 8s - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.1155 - val_accuracy: 0.9726 - 8s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "1085/1085 - 9s - loss: 0.1202 - accuracy: 0.9631 - val_loss: 0.1079 - val_accuracy: 0.9754 - 9s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1085/1085 - 8s - loss: 0.1196 - accuracy: 0.9632 - val_loss: 0.1032 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1085/1085 - 11s - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1034 - val_accuracy: 0.9751 - 11s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "1085/1085 - 8s - loss: 0.1176 - accuracy: 0.9637 - val_loss: 0.0993 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1085/1085 - 8s - loss: 0.1171 - accuracy: 0.9639 - val_loss: 0.0999 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "1085/1085 - 8s - loss: 0.1156 - accuracy: 0.9641 - val_loss: 0.1006 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "1085/1085 - 8s - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.0978 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "1085/1085 - 8s - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.0991 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "1085/1085 - 8s - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.1017 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "1085/1085 - 7s - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.0966 - val_accuracy: 0.9766 - 7s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1085/1085 - 8s - loss: 0.1114 - accuracy: 0.9652 - val_loss: 0.1054 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1085/1085 - 8s - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1019 - val_accuracy: 0.9755 - 8s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1085/1085 - 9s - loss: 0.1110 - accuracy: 0.9654 - val_loss: 0.0986 - val_accuracy: 0.9765 - 9s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1085/1085 - 9s - loss: 0.1107 - accuracy: 0.9656 - val_loss: 0.0987 - val_accuracy: 0.9749 - 9s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "1085/1085 - 8s - loss: 0.1094 - accuracy: 0.9659 - val_loss: 0.1004 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9659 - val_loss: 0.0910 - val_accuracy: 0.9766 - 8s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1085/1085 - 9s - loss: 0.1089 - accuracy: 0.9661 - val_loss: 0.0982 - val_accuracy: 0.9767 - 9s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.1018 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1085/1085 - 8s - loss: 0.1082 - accuracy: 0.9659 - val_loss: 0.0920 - val_accuracy: 0.9768 - 8s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1085/1085 - 8s - loss: 0.1074 - accuracy: 0.9662 - val_loss: 0.0954 - val_accuracy: 0.9770 - 8s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1085/1085 - 7s - loss: 0.1064 - accuracy: 0.9668 - val_loss: 0.0957 - val_accuracy: 0.9769 - 7s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1085/1085 - 7s - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.0974 - val_accuracy: 0.9765 - 7s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1085/1085 - 8s - loss: 0.1063 - accuracy: 0.9666 - val_loss: 0.0905 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1085/1085 - 8s - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.0969 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1085/1085 - 8s - loss: 0.1051 - accuracy: 0.9670 - val_loss: 0.0943 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1085/1085 - 9s - loss: 0.1052 - accuracy: 0.9668 - val_loss: 0.0956 - val_accuracy: 0.9770 - 9s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1085/1085 - 8s - loss: 0.1046 - accuracy: 0.9673 - val_loss: 0.1010 - val_accuracy: 0.9747 - 8s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1085/1085 - 9s - loss: 0.1045 - accuracy: 0.9672 - val_loss: 0.0937 - val_accuracy: 0.9766 - 9s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "1085/1085 - 8s - loss: 0.1038 - accuracy: 0.9674 - val_loss: 0.0895 - val_accuracy: 0.9771 - 8s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1085/1085 - 8s - loss: 0.1039 - accuracy: 0.9675 - val_loss: 0.0934 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9674 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.0939 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1085/1085 - 8s - loss: 0.1027 - accuracy: 0.9676 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1085/1085 - 8s - loss: 0.1024 - accuracy: 0.9679 - val_loss: 0.0930 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1085/1085 - 9s - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.0929 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "1085/1085 - 8s - loss: 0.1022 - accuracy: 0.9678 - val_loss: 0.0942 - val_accuracy: 0.9761 - 8s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1085/1085 - 9s - loss: 0.1019 - accuracy: 0.9679 - val_loss: 0.0939 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1085/1085 - 8s - loss: 0.1014 - accuracy: 0.9681 - val_loss: 0.0909 - val_accuracy: 0.9762 - 8s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "1085/1085 - 7s - loss: 0.1016 - accuracy: 0.9679 - val_loss: 0.0947 - val_accuracy: 0.9756 - 7s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9682 - val_loss: 0.0896 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1085/1085 - 8s - loss: 0.1000 - accuracy: 0.9683 - val_loss: 0.0886 - val_accuracy: 0.9772 - 8s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9683 - val_loss: 0.0883 - val_accuracy: 0.9768 - 8s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1085/1085 - 8s - loss: 0.0998 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "1085/1085 - 8s - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.0933 - val_accuracy: 0.9764 - 8s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1085/1085 - 8s - loss: 0.0997 - accuracy: 0.9685 - val_loss: 0.0921 - val_accuracy: 0.9758 - 8s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1085/1085 - 8s - loss: 0.0987 - accuracy: 0.9687 - val_loss: 0.0840 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "1085/1085 - 8s - loss: 0.0992 - accuracy: 0.9687 - val_loss: 0.0926 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "1085/1085 - 8s - loss: 0.0984 - accuracy: 0.9689 - val_loss: 0.0934 - val_accuracy: 0.9742 - 8s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9779 - 8s/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0879 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0921 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "1085/1085 - 8s - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.0925 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0913 - val_accuracy: 0.9773 - 8s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1085/1085 - 8s - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.0864 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "1085/1085 - 8s - loss: 0.0974 - accuracy: 0.9690 - val_loss: 0.0918 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9692 - val_loss: 0.0850 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9694 - val_loss: 0.0883 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1085/1085 - 8s - loss: 0.0961 - accuracy: 0.9694 - val_loss: 0.0846 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "1085/1085 - 8s - loss: 0.0964 - accuracy: 0.9695 - val_loss: 0.0855 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "1085/1085 - 8s - loss: 0.0962 - accuracy: 0.9696 - val_loss: 0.0915 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "1085/1085 - 8s - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.0859 - val_accuracy: 0.9782 - 8s/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "1085/1085 - 10s - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.0877 - val_accuracy: 0.9776 - 10s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "1085/1085 - 8s - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.0887 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "1085/1085 - 8s - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.0872 - val_accuracy: 0.9769 - 8s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9701 - val_loss: 0.0898 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "1085/1085 - 8s - loss: 0.0950 - accuracy: 0.9696 - val_loss: 0.0867 - val_accuracy: 0.9775 - 8s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.0891 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9699 - val_loss: 0.0894 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.0859 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9700 - val_loss: 0.0843 - val_accuracy: 0.9785 - 8s/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "1085/1085 - 8s - loss: 0.0945 - accuracy: 0.9701 - val_loss: 0.0845 - val_accuracy: 0.9786 - 8s/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "1085/1085 - 8s - loss: 0.0942 - accuracy: 0.9700 - val_loss: 0.0869 - val_accuracy: 0.9780 - 8s/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "1085/1085 - 9s - loss: 0.0937 - accuracy: 0.9703 - val_loss: 0.0865 - val_accuracy: 0.9768 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1085/1085 - 8s - loss: 0.0938 - accuracy: 0.9703 - val_loss: 0.0863 - val_accuracy: 0.9777 - 8s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0886 - val_accuracy: 0.9773 - 8s/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0921 - val_accuracy: 0.9744 - 8s/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "1085/1085 - 8s - loss: 0.0932 - accuracy: 0.9704 - val_loss: 0.0864 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "1085/1085 - 8s - loss: 0.0937 - accuracy: 0.9704 - val_loss: 0.0868 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "1085/1085 - 7s - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9784 - 7s/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0870 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "1085/1085 - 7s - loss: 0.0926 - accuracy: 0.9706 - val_loss: 0.0887 - val_accuracy: 0.9749 - 7s/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "1085/1085 - 8s - loss: 0.0925 - accuracy: 0.9706 - val_loss: 0.0820 - val_accuracy: 0.9792 - 8s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_6 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_6 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_6, histogram_freq=1)\n",
    "        ]\n",
    "history_6  = model_6.fit(X_train_over,y_train_over,validation_data=(x_test,y_test), callbacks=[monitor_6],verbose=2, batch_size=512, epochs=100)\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_model_write_path\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "https://abstractask.tistory.com/105\n",
    "\n",
    "Model #1, Model #2, Model #3, + OverSampling/UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "# for both logistic and nueral\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "#\t\tcolab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "\t\t#model_4.save(colab_path + 'model4.h5')\n",
    "\t\tif i != 5 and i != 3: #Model4와 Binary 배제\n",
    "\t\t\tfilename = colab_model_write_path + 'model1_' + str(i + 1) + '.h5'\n",
    "\t\t\t# load model from file\n",
    "\t\t\tmodel = load_model(filename,custom_objects=None)\n",
    "\t\t\t# add to list of members\n",
    "\t\t\tall_models.append(model)\n",
    "\t\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "#neural\n",
    "\n",
    "def define_stacked_model(members):\n",
    "\tinitializer = tf.keras.initializers.GlorotUniform(seed=64)\n",
    "\tconstraints = None\n",
    "\n",
    "  # update all layers in all models to not be trainable\n",
    "\tfor i in range(len(members)):\n",
    "\t\tmodel = members[i]\n",
    "\t\tfor layer in model.layers:\n",
    "\t\t\t# make not trainable\n",
    "\t\t\tlayer.trainable = False\n",
    "\t\t\t# rename to avoid 'unique layer name' issue\n",
    "\t\t\tlayer._name = 'ensemble_' + str(i + 1) + '_' + layer.name\n",
    "\n",
    "\n",
    "\t# define multi-headed input\n",
    "\tensemble_visible = [model.input for model in members]\n",
    "\t# concatenate merge output from each model\n",
    "\tensemble_outputs = [model.output for model in members]\n",
    "\tmerge = concatenate(ensemble_outputs)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_ea\")(merge)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_eb\")(merge)\n",
    "\toutput = Dense(Y.shape[1], kernel_initializer=initializer, activation='softmax',name=\"dense_ec\")(merge)\n",
    "\tmodel = Model(inputs=ensemble_visible, outputs=output)\n",
    "\t# plot graph of ensemble\n",
    "\tplot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "\t# compile\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "#neural\n",
    "import datetime\n",
    "\n",
    "\n",
    "#colab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_7= [\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "\n",
    "def fit_stacked_model(model, inputX, inputy_enc):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# encode output data\n",
    "#\tinputy_enc = to_categorical(inputy)\n",
    "\t# fit model\n",
    "\thistory_7=model.fit(X, inputy_enc, epochs=60, verbose=2,callbacks=[monitor_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a stacked model\n",
    "#neural\n",
    "def predict_stacked_model(model, inputX):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# make prediction\n",
    "\treturn model.predict(X, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (4010881687.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    colab_model_write_path = colab_write_path + \"20231010221344/\")\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "#neural\n",
    "\n",
    "colab_model_write_path = colab_write_path + \"20231010221344/\"\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "n_members = 6\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_2a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_3a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_6a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_1a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2a (Dense)    (None, 64)           8192        ['dense_2a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3a (Dense)    (None, 512)          65536       ['dense_3a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6a (Dense)    (None, 256)          32768       ['dense_6a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1a (Dense)    (None, 64)           8192        ['dense_1a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2b (Dense)    (None, 128)          8320        ['ensemble_2_dense_2a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_11 (Dropout  (None, 512)         0           ['ensemble_3_dense_3a[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_3 (Dropout)  (None, 256)         0           ['ensemble_4_dense_6a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1b (Dense)    (None, 128)          8320        ['ensemble_1_dense_1a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_8 (Dropout)  (None, 128)         0           ['ensemble_2_dense_2b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3b (Dense)    (None, 256)          131328      ['ensemble_3_dropout_11[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6b (Dense)    (None, 128)          32896       ['ensemble_4_dropout_3[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_6 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2c (Dense)    (None, 256)          33024       ['ensemble_2_dropout_8[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_12 (Dropout  (None, 256)         0           ['ensemble_3_dense_3b[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_4 (Dropout)  (None, 128)         0           ['ensemble_4_dense_6b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1c (Dense)    (None, 128)          16512       ['ensemble_1_dropout_6[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_9 (Dropout)  (None, 256)         0           ['ensemble_2_dense_2c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3c (Dense)    (None, 128)          32896       ['ensemble_3_dropout_12[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6c (Dense)    (None, 128)          16512       ['ensemble_4_dropout_4[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_7 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2d (Dense)    (None, 128)          32896       ['ensemble_2_dropout_9[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_13 (Dropout  (None, 128)         0           ['ensemble_3_dense_3c[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_5 (Dropout)  (None, 128)         0           ['ensemble_4_dense_6c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1d (Dense)    (None, 64)           8256        ['ensemble_1_dropout_7[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_10 (Dropout  (None, 128)         0           ['ensemble_2_dense_2d[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3d (Dense)    (None, 128)          16512       ['ensemble_3_dropout_13[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6d (Dense)    (None, 64)           8256        ['ensemble_4_dropout_5[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1_dense_2 (Dense)     (None, 21)           1365        ['ensemble_1_dense_1d[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " ensemble_2_dense_3 (Dense)     (None, 21)           2709        ['ensemble_2_dropout_10[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_3_dense_4 (Dense)     (None, 21)           2709        ['ensemble_3_dense_3d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_4_dense_1 (Dense)     (None, 21)           1365        ['ensemble_4_dense_6d[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 84)           0           ['ensemble_1_dense_2[0][0]',     \n",
      "                                                                  'ensemble_2_dense_3[0][0]',     \n",
      "                                                                  'ensemble_3_dense_4[0][0]',     \n",
      "                                                                  'ensemble_4_dense_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_ea (Dense)               (None, 128)          10880       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_eb (Dense)               (None, 128)          16512       ['dense_ea[0][0]']               \n",
      "                                                                                                  \n",
      " dense_ec (Dense)               (None, 21)           2709        ['dense_eb[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 498,665\n",
      "Trainable params: 30,101\n",
      "Non-trainable params: 468,564\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define ensemble model\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.utils import plot_model\n",
    "#neural\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "27250/27250 - 76s - loss: 0.0655 - accuracy: 0.9839 - 76s/epoch - 3ms/step\n",
      "Epoch 2/60\n",
      "27250/27250 - 73s - loss: 0.0589 - accuracy: 0.9845 - 73s/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "27250/27250 - 73s - loss: 0.0584 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "27250/27250 - 73s - loss: 0.0581 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "27250/27250 - 72s - loss: 0.0578 - accuracy: 0.9848 - 72s/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "27250/27250 - 73s - loss: 0.0581 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "27250/27250 - 73s - loss: 0.0577 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "27250/27250 - 73s - loss: 0.0578 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "27250/27250 - 73s - loss: 0.0579 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 10/60\n",
      "27250/27250 - 73s - loss: 0.0574 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 11/60\n",
      "27250/27250 - 73s - loss: 0.0578 - accuracy: 0.9849 - 73s/epoch - 3ms/step\n",
      "Epoch 12/60\n",
      "27250/27250 - 72s - loss: 0.0577 - accuracy: 0.9848 - 72s/epoch - 3ms/step\n",
      "Epoch 13/60\n",
      "27250/27250 - 73s - loss: 0.0581 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 14/60\n",
      "27250/27250 - 78s - loss: 0.0577 - accuracy: 0.9847 - 78s/epoch - 3ms/step\n",
      "Epoch 15/60\n",
      "27250/27250 - 75s - loss: 0.0574 - accuracy: 0.9848 - 75s/epoch - 3ms/step\n",
      "Epoch 16/60\n",
      "27250/27250 - 74s - loss: 0.0582 - accuracy: 0.9846 - 74s/epoch - 3ms/step\n",
      "Epoch 17/60\n",
      "27250/27250 - 73s - loss: 0.0578 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 18/60\n",
      "27250/27250 - 73s - loss: 0.0582 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 19/60\n",
      "27250/27250 - 73s - loss: 0.0578 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 20/60\n",
      "27250/27250 - 73s - loss: 0.0583 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 21/60\n",
      "27250/27250 - 74s - loss: 0.0588 - accuracy: 0.9847 - 74s/epoch - 3ms/step\n",
      "Epoch 22/60\n",
      "27250/27250 - 73s - loss: 0.0591 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 23/60\n",
      "27250/27250 - 72s - loss: 0.0583 - accuracy: 0.9848 - 72s/epoch - 3ms/step\n",
      "Epoch 24/60\n",
      "27250/27250 - 73s - loss: 0.0590 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 25/60\n",
      "27250/27250 - 73s - loss: 0.0594 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 26/60\n",
      "27250/27250 - 73s - loss: 0.0594 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 27/60\n",
      "27250/27250 - 73s - loss: 0.0583 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 28/60\n",
      "27250/27250 - 73s - loss: 0.0603 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 29/60\n",
      "27250/27250 - 73s - loss: 0.0593 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 30/60\n",
      "27250/27250 - 73s - loss: 0.0597 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 31/60\n",
      "27250/27250 - 72s - loss: 0.0600 - accuracy: 0.9847 - 72s/epoch - 3ms/step\n",
      "Epoch 32/60\n",
      "27250/27250 - 73s - loss: 0.0590 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 33/60\n",
      "27250/27250 - 73s - loss: 0.0596 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 34/60\n",
      "27250/27250 - 73s - loss: 0.0596 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 35/60\n",
      "27250/27250 - 73s - loss: 0.0594 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 36/60\n",
      "27250/27250 - 73s - loss: 0.0610 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 37/60\n",
      "27250/27250 - 74s - loss: 0.0601 - accuracy: 0.9846 - 74s/epoch - 3ms/step\n",
      "Epoch 38/60\n",
      "27250/27250 - 73s - loss: 0.0589 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 39/60\n",
      "27250/27250 - 73s - loss: 0.0602 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 40/60\n",
      "27250/27250 - 73s - loss: 0.0618 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 41/60\n",
      "27250/27250 - 73s - loss: 0.0591 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 42/60\n",
      "27250/27250 - 73s - loss: 0.0623 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 43/60\n",
      "27250/27250 - 73s - loss: 0.0608 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 44/60\n",
      "27250/27250 - 73s - loss: 0.0609 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 45/60\n",
      "27250/27250 - 73s - loss: 0.0591 - accuracy: 0.9848 - 73s/epoch - 3ms/step\n",
      "Epoch 46/60\n",
      "27250/27250 - 73s - loss: 0.0614 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 47/60\n",
      "27250/27250 - 73s - loss: 0.0604 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 48/60\n",
      "27250/27250 - 73s - loss: 0.0600 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 49/60\n",
      "27250/27250 - 73s - loss: 0.0606 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 50/60\n",
      "27250/27250 - 73s - loss: 0.0620 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 51/60\n",
      "27250/27250 - 73s - loss: 0.0614 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 52/60\n",
      "27250/27250 - 73s - loss: 0.0612 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 53/60\n",
      "27250/27250 - 73s - loss: 0.0620 - accuracy: 0.9845 - 73s/epoch - 3ms/step\n",
      "Epoch 54/60\n",
      "27250/27250 - 72s - loss: 0.0601 - accuracy: 0.9847 - 72s/epoch - 3ms/step\n",
      "Epoch 55/60\n",
      "27250/27250 - 73s - loss: 0.0605 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 56/60\n",
      "27250/27250 - 73s - loss: 0.0611 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 57/60\n",
      "27250/27250 - 73s - loss: 0.0623 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 58/60\n",
      "27250/27250 - 73s - loss: 0.0621 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n",
      "Epoch 59/60\n",
      "27250/27250 - 73s - loss: 0.0628 - accuracy: 0.9846 - 73s/epoch - 3ms/step\n",
      "Epoch 60/60\n",
      "27250/27250 - 73s - loss: 0.0666 - accuracy: 0.9847 - 73s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "fit_stacked_model(stacked_model, x_train,y_train)\n",
    "stacked_model.save(colab_model_write_path + 'stacked_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 12s - 12s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.87      0.94      0.91        51\n",
      "           2       0.99      0.99      0.99     72091\n",
      "           3       1.00      1.00      1.00       433\n",
      "           4       1.00      0.97      0.98       365\n",
      "           5       0.99      0.99      0.99     62503\n",
      "           6       0.98      0.99      0.99     51385\n",
      "           7       0.71      0.68      0.69        78\n",
      "           8       0.45      0.54      0.49        67\n",
      "           9       1.00      0.69      0.82        62\n",
      "          10       0.92      0.20      0.33       349\n",
      "          11       0.98      0.94      0.96      7418\n",
      "          12       1.00      0.60      0.75         5\n",
      "          13       0.75      0.67      0.71         9\n",
      "          15       0.88      0.76      0.81      1989\n",
      "          16       0.44      0.41      0.42        17\n",
      "          17       0.93      0.91      0.92      3272\n",
      "          18       1.00      0.80      0.89        15\n",
      "          19       0.95      0.99      0.97     10833\n",
      "          20       0.94      0.97      0.95      7055\n",
      "\n",
      "    accuracy                           0.98    218000\n",
      "   macro avg       0.84      0.75      0.78    218000\n",
      "weighted avg       0.98      0.98      0.98    218000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00         3\\n           1       0.87      0.94      0.91        51\\n           2       0.99      0.99      0.99     72091\\n           3       1.00      1.00      1.00       433\\n           4       1.00      0.97      0.98       365\\n           5       0.99      0.99      0.99     62503\\n           6       0.98      0.99      0.99     51385\\n           7       0.71      0.68      0.69        78\\n           8       0.45      0.54      0.49        67\\n           9       1.00      0.69      0.82        62\\n          10       0.92      0.20      0.33       349\\n          11       0.98      0.94      0.96      7418\\n          12       1.00      0.60      0.75         5\\n          13       0.75      0.67      0.71         9\\n          15       0.88      0.76      0.81      1989\\n          16       0.44      0.41      0.42        17\\n          17       0.93      0.91      0.92      3272\\n          18       1.00      0.80      0.89        15\\n          19       0.95      0.99      0.97     10833\\n          20       0.94      0.97      0.95      7055\\n\\n    accuracy                           0.98    218000\\n   macro avg       0.84      0.75      0.78    218000\\nweighted avg       0.98      0.98      0.98    218000\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_1, yhat_val))\n",
    "classification_report(y_test_1, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 13s - 13s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5801daf5d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 predict 수행\n",
    "# 모델 성능 - confusion matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test_1, y_pred=yhat_val)\n",
    "conf_mat\n",
    "\n",
    "disp = ConfusionMatrixDisplay(conf_mat)\n",
    "#disp = ConfusionMatrixDisplay(conf_mat)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
