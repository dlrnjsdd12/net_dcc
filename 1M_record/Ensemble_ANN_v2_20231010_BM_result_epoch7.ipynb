{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 18:13:16.213029: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 기본라이브러리 import\n",
    "#from google.colab import drive\n",
    "#import os, json, pickle\n",
    "#import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# 파이토치 라이브러리 import\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "#Keras Import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import ipaddress\n",
    "\n",
    "# 구글 드라이브 mount\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# 데이터 파일 위치\n",
    "#C:\\Users\\mariu\\내 드라이브\\Colab Notebooks\\Network\n",
    "colab_path = '/home/marius1406/'\n",
    "colab_write_path = \"/home/marius1406/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_path = \"/home/marius1406/\"\n",
    "df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False, nrows=1089999)\n",
    "#df = pd.read_csv(colab_path+\"NF-UQ-NIDS-total.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장판에서 사용\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'DNS_QUERY_ID','Label','Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "#cols = df.columns.drop(['IPV4_SRC_ADDR_1','IPV4_SRC_ADDR_2','Label','Attack','Dataset', 'Label_1','Attack_1','Dataset_1', 'Label_2','Attack_2','Dataset_2'])  #명목형변수, 레이블 변수 제외\n",
    "cols = df.columns.drop(['Label','Attack'])  #명목형변수, 레이블 변수 제외#cols = df.columns.drop(['Attack','Dataset'])  #명목형변수, 레이블 변수 제외\n",
    "X = df[cols]\n",
    "dummies = pd.get_dummies(df['Attack']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "Y = dummies.values\n",
    "\n",
    "#==================\n",
    "dummiesLabel = pd.get_dummies(df['Label']) # Classification\n",
    "y_1_label = df['Label'].values\n",
    "y_label = dummiesLabel.values\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "def extend_sparse(val):\n",
    "    if val in ['Analysis', 'Exploits', 'Fuzzers', 'Shellcode', 'Theft', 'Worms', 'mitm']: return 1\n",
    "    return 0\n",
    "\n",
    "y_1_attack = pd.DataFrame(df['Attack'])\n",
    "\n",
    "is_sparse = y_1_attack.applymap(extend_sparse)\n",
    "y_1_enforce = is_sparse.values\n",
    "y_enforce = pd.get_dummies(is_sparse['Attack']) # Classification\n",
    "\n",
    "#=======================\n",
    "\n",
    "def max_8G(val):\n",
    "    if (val > 1.0e+9): return 1.0e+9\n",
    "    return val\n",
    "\n",
    "#cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT']\n",
    "cols =['DST_TO_SRC_SECOND_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "'DST_TO_SRC_SECOND_BYTES_1', 'SRC_TO_DST_SECOND_BYTES_1', 'SRC_TO_DST_AVG_THROUGHPUT_1', 'DST_TO_SRC_AVG_THROUGHPUT_1',\n",
    "'DST_TO_SRC_SECOND_BYTES_2', 'SRC_TO_DST_SECOND_BYTES_2', 'SRC_TO_DST_AVG_THROUGHPUT_2', 'DST_TO_SRC_AVG_THROUGHPUT_2'] \n",
    "\n",
    "X[cols] = X[cols].applymap(max_8G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 4291722866\n",
      "L4_SRC_PORT 65535\n",
      "IPV4_DST_ADDR 4294967295\n",
      "L4_DST_PORT 65535\n",
      "PROTOCOL 254\n",
      "L7_PROTO 248.0\n",
      "IN_BYTES 34641563\n",
      "IN_PKTS 123763\n",
      "OUT_BYTES 129573662\n",
      "OUT_PKTS 87179\n",
      "TCP_FLAGS 223\n",
      "CLIENT_TCP_FLAGS 223\n",
      "SERVER_TCP_FLAGS 223\n",
      "FLOW_DURATION_MILLISECONDS 4294967\n",
      "DURATION_IN 105400\n",
      "DURATION_OUT 38547\n",
      "MIN_TTL 255\n",
      "MAX_TTL 255\n",
      "LONGEST_FLOW_PKT 7292\n",
      "SHORTEST_FLOW_PKT 1504\n",
      "MIN_IP_PKT_LEN 547\n",
      "MAX_IP_PKT_LEN 7292\n",
      "SRC_TO_DST_SECOND_BYTES 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES 6321251\n",
      "RETRANSMITTED_IN_PKTS 4774\n",
      "RETRANSMITTED_OUT_BYTES 2183347\n",
      "RETRANSMITTED_OUT_PKTS 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES 191858\n",
      "NUM_PKTS_128_TO_256_BYTES 7230\n",
      "NUM_PKTS_256_TO_512_BYTES 4921\n",
      "NUM_PKTS_512_TO_1024_BYTES 34443\n",
      "NUM_PKTS_1024_TO_1514_BYTES 86096\n",
      "TCP_WIN_MAX_IN 65535\n",
      "TCP_WIN_MAX_OUT 65535\n",
      "ICMP_TYPE 65280\n",
      "ICMP_IPV4_TYPE 255\n",
      "DNS_QUERY_ID 65535\n",
      "DNS_QUERY_TYPE 32769\n",
      "DNS_TTL_ANSWER 4294915672\n",
      "FTP_COMMAND_RET_CODE 550.0\n",
      "L4_SRC_PORT_1 65535\n",
      "IPV4_DST_ADDR_1 4294967295\n",
      "L4_DST_PORT_1 65535\n",
      "PROTOCOL_1 254\n",
      "L7_PROTO_1 248.0\n",
      "IN_BYTES_1 32341314\n",
      "IN_PKTS_1 123763\n",
      "OUT_BYTES_1 129573662\n",
      "OUT_PKTS_1 87179\n",
      "TCP_FLAGS_1 223\n",
      "CLIENT_TCP_FLAGS_1 223\n",
      "SERVER_TCP_FLAGS_1 223\n",
      "FLOW_DURATION_MILLISECONDS_1 4294967\n",
      "DURATION_IN_1 105400\n",
      "DURATION_OUT_1 38547\n",
      "MIN_TTL_1 255\n",
      "MAX_TTL_1 255\n",
      "LONGEST_FLOW_PKT_1 7292\n",
      "SHORTEST_FLOW_PKT_1 1504\n",
      "MIN_IP_PKT_LEN_1 547\n",
      "MAX_IP_PKT_LEN_1 7292\n",
      "SRC_TO_DST_SECOND_BYTES_1 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_1 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_1 6321251\n",
      "RETRANSMITTED_IN_PKTS_1 4774\n",
      "RETRANSMITTED_OUT_BYTES_1 2183347\n",
      "RETRANSMITTED_OUT_PKTS_1 1458\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_1 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_1 3406\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 18388\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 86096\n",
      "TCP_WIN_MAX_IN_1 65535\n",
      "TCP_WIN_MAX_OUT_1 65535\n",
      "ICMP_TYPE_1 65280\n",
      "ICMP_IPV4_TYPE_1 255\n",
      "DNS_QUERY_ID_1 65535\n",
      "DNS_QUERY_TYPE_1 32769\n",
      "DNS_TTL_ANSWER_1 4294915672\n",
      "FTP_COMMAND_RET_CODE_1 550.0\n",
      "L4_SRC_PORT_2 65535\n",
      "IPV4_DST_ADDR_2 4294967295\n",
      "L4_DST_PORT_2 65535\n",
      "PROTOCOL_2 254\n",
      "L7_PROTO_2 245.178\n",
      "IN_BYTES_2 33337052\n",
      "IN_PKTS_2 123763\n",
      "OUT_BYTES_2 129573662\n",
      "OUT_PKTS_2 87179\n",
      "TCP_FLAGS_2 223\n",
      "CLIENT_TCP_FLAGS_2 223\n",
      "SERVER_TCP_FLAGS_2 223\n",
      "FLOW_DURATION_MILLISECONDS_2 4294967\n",
      "DURATION_IN_2 105400\n",
      "DURATION_OUT_2 38547\n",
      "MIN_TTL_2 255\n",
      "MAX_TTL_2 255\n",
      "LONGEST_FLOW_PKT_2 7292\n",
      "SHORTEST_FLOW_PKT_2 1504\n",
      "MIN_IP_PKT_LEN_2 422\n",
      "MAX_IP_PKT_LEN_2 7292\n",
      "SRC_TO_DST_SECOND_BYTES_2 1000000000.0\n",
      "DST_TO_SRC_SECOND_BYTES_2 1000000000.0\n",
      "RETRANSMITTED_IN_BYTES_2 6321251\n",
      "RETRANSMITTED_IN_PKTS_2 4774\n",
      "RETRANSMITTED_OUT_BYTES_2 1109291\n",
      "RETRANSMITTED_OUT_PKTS_2 824\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 1000000000.0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 1000000000.0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 191858\n",
      "NUM_PKTS_128_TO_256_BYTES_2 7230\n",
      "NUM_PKTS_256_TO_512_BYTES_2 3446\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 18954\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 86096\n",
      "TCP_WIN_MAX_IN_2 65535\n",
      "TCP_WIN_MAX_OUT_2 65535\n",
      "ICMP_TYPE_2 65280\n",
      "ICMP_IPV4_TYPE_2 255\n",
      "DNS_QUERY_ID_2 65535\n",
      "DNS_QUERY_TYPE_2 32769\n",
      "DNS_TTL_ANSWER_2 4294915672\n",
      "FTP_COMMAND_RET_CODE_2 550.0\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scaler_train = preprocessing.StandardScaler()\n",
    "scaler_train = scaler_train.fit(X)\n",
    "X = pd.DataFrame(scaler_train.transform(X),index=np.arange(0,X.shape[0],1), columns = X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPV4_SRC_ADDR 0\n",
      "L4_SRC_PORT 0\n",
      "IPV4_DST_ADDR 0\n",
      "L4_DST_PORT 0\n",
      "PROTOCOL 0\n",
      "L7_PROTO 0\n",
      "IN_BYTES 0\n",
      "IN_PKTS 0\n",
      "OUT_BYTES 0\n",
      "OUT_PKTS 0\n",
      "TCP_FLAGS 0\n",
      "CLIENT_TCP_FLAGS 0\n",
      "SERVER_TCP_FLAGS 0\n",
      "FLOW_DURATION_MILLISECONDS 0\n",
      "DURATION_IN 0\n",
      "DURATION_OUT 0\n",
      "MIN_TTL 0\n",
      "MAX_TTL 0\n",
      "LONGEST_FLOW_PKT 0\n",
      "SHORTEST_FLOW_PKT 0\n",
      "MIN_IP_PKT_LEN 0\n",
      "MAX_IP_PKT_LEN 0\n",
      "SRC_TO_DST_SECOND_BYTES 0\n",
      "DST_TO_SRC_SECOND_BYTES 0\n",
      "RETRANSMITTED_IN_BYTES 0\n",
      "RETRANSMITTED_IN_PKTS 0\n",
      "RETRANSMITTED_OUT_BYTES 0\n",
      "RETRANSMITTED_OUT_PKTS 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT 0\n",
      "NUM_PKTS_UP_TO_128_BYTES 0\n",
      "NUM_PKTS_128_TO_256_BYTES 0\n",
      "NUM_PKTS_256_TO_512_BYTES 0\n",
      "NUM_PKTS_512_TO_1024_BYTES 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES 0\n",
      "TCP_WIN_MAX_IN 0\n",
      "TCP_WIN_MAX_OUT 0\n",
      "ICMP_TYPE 0\n",
      "ICMP_IPV4_TYPE 0\n",
      "DNS_QUERY_ID 0\n",
      "DNS_QUERY_TYPE 0\n",
      "DNS_TTL_ANSWER 0\n",
      "FTP_COMMAND_RET_CODE 0\n",
      "L4_SRC_PORT_1 0\n",
      "IPV4_DST_ADDR_1 0\n",
      "L4_DST_PORT_1 0\n",
      "PROTOCOL_1 0\n",
      "L7_PROTO_1 0\n",
      "IN_BYTES_1 0\n",
      "IN_PKTS_1 0\n",
      "OUT_BYTES_1 0\n",
      "OUT_PKTS_1 0\n",
      "TCP_FLAGS_1 0\n",
      "CLIENT_TCP_FLAGS_1 0\n",
      "SERVER_TCP_FLAGS_1 0\n",
      "FLOW_DURATION_MILLISECONDS_1 0\n",
      "DURATION_IN_1 0\n",
      "DURATION_OUT_1 0\n",
      "MIN_TTL_1 0\n",
      "MAX_TTL_1 0\n",
      "LONGEST_FLOW_PKT_1 0\n",
      "SHORTEST_FLOW_PKT_1 0\n",
      "MIN_IP_PKT_LEN_1 0\n",
      "MAX_IP_PKT_LEN_1 0\n",
      "SRC_TO_DST_SECOND_BYTES_1 0\n",
      "DST_TO_SRC_SECOND_BYTES_1 0\n",
      "RETRANSMITTED_IN_BYTES_1 0\n",
      "RETRANSMITTED_IN_PKTS_1 0\n",
      "RETRANSMITTED_OUT_BYTES_1 0\n",
      "RETRANSMITTED_OUT_PKTS_1 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_1 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_1 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_1 0\n",
      "NUM_PKTS_128_TO_256_BYTES_1 0\n",
      "NUM_PKTS_256_TO_512_BYTES_1 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_1 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_1 0\n",
      "TCP_WIN_MAX_IN_1 0\n",
      "TCP_WIN_MAX_OUT_1 0\n",
      "ICMP_TYPE_1 0\n",
      "ICMP_IPV4_TYPE_1 0\n",
      "DNS_QUERY_ID_1 0\n",
      "DNS_QUERY_TYPE_1 0\n",
      "DNS_TTL_ANSWER_1 0\n",
      "FTP_COMMAND_RET_CODE_1 0\n",
      "L4_SRC_PORT_2 0\n",
      "IPV4_DST_ADDR_2 0\n",
      "L4_DST_PORT_2 0\n",
      "PROTOCOL_2 0\n",
      "L7_PROTO_2 0\n",
      "IN_BYTES_2 0\n",
      "IN_PKTS_2 0\n",
      "OUT_BYTES_2 0\n",
      "OUT_PKTS_2 0\n",
      "TCP_FLAGS_2 0\n",
      "CLIENT_TCP_FLAGS_2 0\n",
      "SERVER_TCP_FLAGS_2 0\n",
      "FLOW_DURATION_MILLISECONDS_2 0\n",
      "DURATION_IN_2 0\n",
      "DURATION_OUT_2 0\n",
      "MIN_TTL_2 0\n",
      "MAX_TTL_2 0\n",
      "LONGEST_FLOW_PKT_2 0\n",
      "SHORTEST_FLOW_PKT_2 0\n",
      "MIN_IP_PKT_LEN_2 0\n",
      "MAX_IP_PKT_LEN_2 0\n",
      "SRC_TO_DST_SECOND_BYTES_2 0\n",
      "DST_TO_SRC_SECOND_BYTES_2 0\n",
      "RETRANSMITTED_IN_BYTES_2 0\n",
      "RETRANSMITTED_IN_PKTS_2 0\n",
      "RETRANSMITTED_OUT_BYTES_2 0\n",
      "RETRANSMITTED_OUT_PKTS_2 0\n",
      "SRC_TO_DST_AVG_THROUGHPUT_2 0\n",
      "DST_TO_SRC_AVG_THROUGHPUT_2 0\n",
      "NUM_PKTS_UP_TO_128_BYTES_2 0\n",
      "NUM_PKTS_128_TO_256_BYTES_2 0\n",
      "NUM_PKTS_256_TO_512_BYTES_2 0\n",
      "NUM_PKTS_512_TO_1024_BYTES_2 0\n",
      "NUM_PKTS_1024_TO_1514_BYTES_2 0\n",
      "TCP_WIN_MAX_IN_2 0\n",
      "TCP_WIN_MAX_OUT_2 0\n",
      "ICMP_TYPE_2 0\n",
      "ICMP_IPV4_TYPE_2 0\n",
      "DNS_QUERY_ID_2 0\n",
      "DNS_QUERY_TYPE_2 0\n",
      "DNS_TTL_ANSWER_2 0\n",
      "FTP_COMMAND_RET_CODE_2 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(col , X[col].isna().sum())\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_3sigma(val):\n",
    "    if (val < -3): return -3\n",
    "    if (val > 3): return 3\n",
    "    return val\n",
    "\n",
    "X = X.applymap(max_3sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = tf.argmax(dummies, axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_label, y_train_label, y_test_label = train_test_split(X, y_label, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_enforce, y_train_enforce, y_test_enforce = train_test_split(X, y_enforce, test_size=0.20, shuffle = True, random_state=33)\n",
    "x_train, x_test_1, y_train_1, y_test_1 = train_test_split(X, y1.numpy(), test_size=0.20, shuffle = True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_write_path = \"/home/marius1406/\"\n",
    "colab_model_write_path = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M\" + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_1 = tf.keras.Sequential([\\n  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation=\\'relu\\'),\\n  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dropout(0.3),\\n  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation=\\'relu\\'),\\n  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation=\\'softmax\\')\\n  ])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1\n",
    "#initializer = \"glorot_uniform\"\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu',name='dense_1a'),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1b'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1c'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu',name='dense_1d'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "  ])\n",
    "'''\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(128, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, input_dim=128, kernel_initializer=initializer, bias_initializer=\"zeros\", kernel_constraint=constraints,activation='relu'),\n",
    "  tf.keras.layers.Dense(Y.shape[1],input_dim=64, activation='softmax')\n",
    "  ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marius1406/20231010221352\n",
      "Epoch 1/100\n",
      "852/852 - 10s - loss: 0.2878 - accuracy: 0.9140 - val_loss: 0.1270 - val_accuracy: 0.9654 - 10s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "852/852 - 20s - loss: 0.1290 - accuracy: 0.9653 - val_loss: 0.1031 - val_accuracy: 0.9727 - 20s/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "852/852 - 11s - loss: 0.1105 - accuracy: 0.9708 - val_loss: 0.0938 - val_accuracy: 0.9753 - 11s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "852/852 - 14s - loss: 0.1012 - accuracy: 0.9734 - val_loss: 0.0869 - val_accuracy: 0.9771 - 14s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "852/852 - 15s - loss: 0.0947 - accuracy: 0.9749 - val_loss: 0.0852 - val_accuracy: 0.9774 - 15s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "852/852 - 14s - loss: 0.0906 - accuracy: 0.9761 - val_loss: 0.0807 - val_accuracy: 0.9787 - 14s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "852/852 - 17s - loss: 0.0876 - accuracy: 0.9767 - val_loss: 0.0793 - val_accuracy: 0.9792 - 17s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "852/852 - 23s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0764 - val_accuracy: 0.9796 - 23s/epoch - 27ms/step\n",
      "Epoch 9/100\n",
      "852/852 - 23s - loss: 0.0828 - accuracy: 0.9779 - val_loss: 0.0754 - val_accuracy: 0.9801 - 23s/epoch - 27ms/step\n",
      "Epoch 10/100\n",
      "852/852 - 19s - loss: 0.0818 - accuracy: 0.9782 - val_loss: 0.0751 - val_accuracy: 0.9793 - 19s/epoch - 22ms/step\n",
      "Epoch 11/100\n",
      "852/852 - 12s - loss: 0.0798 - accuracy: 0.9785 - val_loss: 0.0744 - val_accuracy: 0.9800 - 12s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "852/852 - 16s - loss: 0.0789 - accuracy: 0.9788 - val_loss: 0.0742 - val_accuracy: 0.9802 - 16s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "852/852 - 14s - loss: 0.0779 - accuracy: 0.9791 - val_loss: 0.0747 - val_accuracy: 0.9801 - 14s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "852/852 - 19s - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.0730 - val_accuracy: 0.9804 - 19s/epoch - 22ms/step\n",
      "Epoch 15/100\n",
      "852/852 - 18s - loss: 0.0761 - accuracy: 0.9794 - val_loss: 0.0741 - val_accuracy: 0.9808 - 18s/epoch - 22ms/step\n",
      "Epoch 16/100\n",
      "852/852 - 15s - loss: 0.0753 - accuracy: 0.9797 - val_loss: 0.0711 - val_accuracy: 0.9812 - 15s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "852/852 - 10s - loss: 0.0748 - accuracy: 0.9799 - val_loss: 0.0711 - val_accuracy: 0.9808 - 10s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "852/852 - 11s - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.0693 - val_accuracy: 0.9815 - 11s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "852/852 - 13s - loss: 0.0732 - accuracy: 0.9802 - val_loss: 0.0701 - val_accuracy: 0.9810 - 13s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "852/852 - 12s - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.0693 - val_accuracy: 0.9813 - 12s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "852/852 - 16s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0699 - val_accuracy: 0.9814 - 16s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "852/852 - 32s - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.0687 - val_accuracy: 0.9816 - 32s/epoch - 37ms/step\n",
      "Epoch 23/100\n",
      "852/852 - 26s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0685 - val_accuracy: 0.9818 - 26s/epoch - 30ms/step\n",
      "Epoch 24/100\n",
      "852/852 - 18s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0686 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "852/852 - 17s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9818 - 17s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "852/852 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "852/852 - 10s - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0671 - val_accuracy: 0.9820 - 10s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "852/852 - 11s - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0683 - val_accuracy: 0.9818 - 11s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "852/852 - 10s - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0684 - val_accuracy: 0.9813 - 10s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "852/852 - 15s - loss: 0.0694 - accuracy: 0.9812 - val_loss: 0.0669 - val_accuracy: 0.9821 - 15s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "852/852 - 13s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0676 - val_accuracy: 0.9819 - 13s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "852/852 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0659 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "852/852 - 14s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0664 - val_accuracy: 0.9824 - 14s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "852/852 - 20s - loss: 0.0681 - accuracy: 0.9815 - val_loss: 0.0653 - val_accuracy: 0.9826 - 20s/epoch - 23ms/step\n",
      "Epoch 35/100\n",
      "852/852 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0675 - val_accuracy: 0.9821 - 12s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "852/852 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0655 - val_accuracy: 0.9823 - 12s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "852/852 - 10s - loss: 0.0677 - accuracy: 0.9817 - val_loss: 0.0656 - val_accuracy: 0.9826 - 10s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "852/852 - 10s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0652 - val_accuracy: 0.9823 - 10s/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "852/852 - 18s - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0683 - val_accuracy: 0.9817 - 18s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "852/852 - 20s - loss: 0.0673 - accuracy: 0.9818 - val_loss: 0.0674 - val_accuracy: 0.9816 - 20s/epoch - 23ms/step\n",
      "Epoch 41/100\n",
      "852/852 - 26s - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.0653 - val_accuracy: 0.9828 - 26s/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "852/852 - 34s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0659 - val_accuracy: 0.9825 - 34s/epoch - 40ms/step\n",
      "Epoch 43/100\n",
      "852/852 - 30s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 30s/epoch - 35ms/step\n",
      "Epoch 44/100\n",
      "852/852 - 19s - loss: 0.0665 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9826 - 19s/epoch - 22ms/step\n",
      "Epoch 45/100\n",
      "852/852 - 21s - loss: 0.0665 - accuracy: 0.9819 - val_loss: 0.0654 - val_accuracy: 0.9825 - 21s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "852/852 - 13s - loss: 0.0664 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9827 - 13s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "852/852 - 10s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0659 - val_accuracy: 0.9825 - 10s/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "852/852 - 13s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0655 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "852/852 - 11s - loss: 0.0659 - accuracy: 0.9821 - val_loss: 0.0654 - val_accuracy: 0.9826 - 11s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "852/852 - 18s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0656 - val_accuracy: 0.9823 - 18s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "852/852 - 16s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0641 - val_accuracy: 0.9827 - 16s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "852/852 - 18s - loss: 0.0655 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9827 - 18s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "852/852 - 15s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0644 - val_accuracy: 0.9827 - 15s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "852/852 - 13s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9827 - 13s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "852/852 - 24s - loss: 0.0653 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9827 - 24s/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "852/852 - 14s - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9831 - 14s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "852/852 - 26s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.9825 - 26s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "852/852 - 26s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0642 - val_accuracy: 0.9826 - 26s/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "852/852 - 20s - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.0645 - val_accuracy: 0.9828 - 20s/epoch - 23ms/step\n",
      "Epoch 60/100\n",
      "852/852 - 17s - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.0642 - val_accuracy: 0.9829 - 17s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "852/852 - 10s - loss: 0.0645 - accuracy: 0.9826 - val_loss: 0.0644 - val_accuracy: 0.9828 - 10s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "852/852 - 12s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0646 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "852/852 - 13s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0642 - val_accuracy: 0.9829 - 13s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "852/852 - 13s - loss: 0.0644 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9826 - 13s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "852/852 - 18s - loss: 0.0640 - accuracy: 0.9826 - val_loss: 0.0636 - val_accuracy: 0.9829 - 18s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "852/852 - 12s - loss: 0.0644 - accuracy: 0.9824 - val_loss: 0.0647 - val_accuracy: 0.9827 - 12s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "852/852 - 18s - loss: 0.0642 - accuracy: 0.9826 - val_loss: 0.0633 - val_accuracy: 0.9830 - 18s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "852/852 - 11s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0635 - val_accuracy: 0.9829 - 11s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "852/852 - 10s - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9828 - 10s/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "852/852 - 13s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0627 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "852/852 - 16s - loss: 0.0638 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9830 - 16s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "852/852 - 15s - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0640 - val_accuracy: 0.9831 - 15s/epoch - 18ms/step\n",
      "Epoch 73/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0639 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "852/852 - 12s - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0632 - val_accuracy: 0.9831 - 12s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "852/852 - 10s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "852/852 - 10s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9831 - 10s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "852/852 - 12s - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0628 - val_accuracy: 0.9832 - 12s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "852/852 - 16s - loss: 0.0633 - accuracy: 0.9828 - val_loss: 0.0620 - val_accuracy: 0.9834 - 16s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "852/852 - 26s - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0635 - val_accuracy: 0.9831 - 26s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "852/852 - 17s - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9827 - 17s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "852/852 - 17s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0628 - val_accuracy: 0.9832 - 17s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "852/852 - 7s - loss: 0.0631 - accuracy: 0.9830 - val_loss: 0.0621 - val_accuracy: 0.9834 - 7s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "852/852 - 10s - loss: 0.0630 - accuracy: 0.9830 - val_loss: 0.0628 - val_accuracy: 0.9832 - 10s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "852/852 - 15s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0624 - val_accuracy: 0.9832 - 15s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "852/852 - 23s - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9833 - 23s/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "852/852 - 13s - loss: 0.0630 - accuracy: 0.9829 - val_loss: 0.0621 - val_accuracy: 0.9831 - 13s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "852/852 - 24s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0629 - val_accuracy: 0.9831 - 24s/epoch - 28ms/step\n",
      "Epoch 88/100\n",
      "852/852 - 31s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9832 - 31s/epoch - 36ms/step\n",
      "Epoch 89/100\n",
      "852/852 - 7s - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9833 - 7s/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "852/852 - 11s - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9834 - 11s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "852/852 - 13s - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.0630 - val_accuracy: 0.9833 - 13s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "852/852 - 27s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9834 - 27s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "852/852 - 28s - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0618 - val_accuracy: 0.9834 - 28s/epoch - 33ms/step\n",
      "Epoch 94/100\n",
      "852/852 - 25s - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0623 - val_accuracy: 0.9833 - 25s/epoch - 30ms/step\n",
      "Epoch 95/100\n",
      "852/852 - 10s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9823 - 10s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "852/852 - 12s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0619 - val_accuracy: 0.9836 - 12s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "852/852 - 27s - loss: 0.0627 - accuracy: 0.9830 - val_loss: 0.0624 - val_accuracy: 0.9836 - 27s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "852/852 - 8s - loss: 0.0623 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9835 - 8s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "852/852 - 9s - loss: 0.0621 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9834 - 9s/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "852/852 - 18s - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9835 - 18s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model_1.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_1 = colab_write_path + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(log_dir_1)\n",
    "monitor_1 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "            ]\n",
    "history_1  = model_1.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=1024, epochs=100)\n",
    "model_1.save(colab_model_write_path + 'model1.h5')\n",
    "#history_1  = model_1.fit(x_train,y_train,validation_split=0.2, callbacks=[monitor_1],verbose=2, batch_size=1024, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  model 2  with different structure\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_2a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=64, kernel_initializer=initializer, activation='relu',name='dense_2b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(256, input_dim=128, kernel_initializer=initializer, activation='relu',name='dense_2c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=256, kernel_initializer=initializer, activation='relu',name='dense_2d'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 14s - loss: 0.2063 - accuracy: 0.9384 - val_loss: 0.1091 - val_accuracy: 0.9693 - 14s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 15s - loss: 0.1104 - accuracy: 0.9704 - val_loss: 0.0928 - val_accuracy: 0.9750 - 15s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 12s - loss: 0.0971 - accuracy: 0.9739 - val_loss: 0.0835 - val_accuracy: 0.9780 - 12s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 16s - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.0814 - val_accuracy: 0.9785 - 16s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 12s - loss: 0.0865 - accuracy: 0.9769 - val_loss: 0.0774 - val_accuracy: 0.9796 - 12s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 13s - loss: 0.0833 - accuracy: 0.9778 - val_loss: 0.0785 - val_accuracy: 0.9796 - 13s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 13s - loss: 0.0815 - accuracy: 0.9782 - val_loss: 0.0755 - val_accuracy: 0.9798 - 13s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0793 - accuracy: 0.9787 - val_loss: 0.0725 - val_accuracy: 0.9802 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 12s - loss: 0.0780 - accuracy: 0.9791 - val_loss: 0.0717 - val_accuracy: 0.9808 - 12s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 13s - loss: 0.0767 - accuracy: 0.9793 - val_loss: 0.0705 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 12s - loss: 0.0757 - accuracy: 0.9796 - val_loss: 0.0700 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 12s - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.0705 - val_accuracy: 0.9809 - 12s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 12s - loss: 0.0741 - accuracy: 0.9799 - val_loss: 0.0699 - val_accuracy: 0.9812 - 12s/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 15s - loss: 0.0736 - accuracy: 0.9801 - val_loss: 0.0692 - val_accuracy: 0.9813 - 15s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 14s - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0691 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 13s - loss: 0.0721 - accuracy: 0.9805 - val_loss: 0.0671 - val_accuracy: 0.9821 - 13s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 14s - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9819 - 14s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.0695 - val_accuracy: 0.9813 - 13s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 12s - loss: 0.0704 - accuracy: 0.9809 - val_loss: 0.0670 - val_accuracy: 0.9817 - 12s/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 12s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0668 - val_accuracy: 0.9818 - 12s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0665 - val_accuracy: 0.9819 - 13s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 15s - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.0651 - val_accuracy: 0.9822 - 15s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 17s - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.0693 - val_accuracy: 0.9816 - 17s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 14s - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.0648 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 14s - loss: 0.0688 - accuracy: 0.9813 - val_loss: 0.0657 - val_accuracy: 0.9824 - 14s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 13s - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0653 - val_accuracy: 0.9823 - 13s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 12s - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.0642 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 11s - loss: 0.0679 - accuracy: 0.9816 - val_loss: 0.0644 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 12s - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0651 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 12s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9824 - 12s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 12s - loss: 0.0674 - accuracy: 0.9817 - val_loss: 0.0649 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 11s - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.0646 - val_accuracy: 0.9824 - 11s/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9817 - val_loss: 0.0647 - val_accuracy: 0.9825 - 12s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 12s - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0643 - val_accuracy: 0.9826 - 12s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 12s - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.0635 - val_accuracy: 0.9828 - 12s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 12s - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0650 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 12s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 11s - loss: 0.0660 - accuracy: 0.9821 - val_loss: 0.0642 - val_accuracy: 0.9827 - 11s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 12s - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.0641 - val_accuracy: 0.9827 - 12s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 12s - loss: 0.0658 - accuracy: 0.9823 - val_loss: 0.0635 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 11s - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.0630 - val_accuracy: 0.9828 - 11s/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 11s - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0639 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 12s - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0631 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 13s - loss: 0.0653 - accuracy: 0.9823 - val_loss: 0.0638 - val_accuracy: 0.9830 - 13s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9823 - val_loss: 0.0634 - val_accuracy: 0.9830 - 11s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0626 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 12s - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 11s - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.0628 - val_accuracy: 0.9834 - 11s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 12s - loss: 0.0646 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 11s - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0626 - val_accuracy: 0.9833 - 11s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 11s - loss: 0.0650 - accuracy: 0.9824 - val_loss: 0.0643 - val_accuracy: 0.9831 - 11s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0630 - val_accuracy: 0.9829 - 12s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 12s - loss: 0.0645 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9830 - 12s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 12s - loss: 0.0641 - accuracy: 0.9827 - val_loss: 0.0625 - val_accuracy: 0.9833 - 12s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "1704/1704 - 12s - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0631 - val_accuracy: 0.9832 - 12s/epoch - 7ms/step\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_2 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_2 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=1, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "            ]\n",
    "history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_2],verbose=2, batch_size=512, epochs=100)\n",
    "model_2.save(colab_model_write_path + 'model2.h5')\n",
    "\n",
    "#history_2  = model_2.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2, batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(512, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3a'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(256, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3c'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X.shape[1], kernel_initializer=initializer, activation='relu',name='dense_3d'),\n",
    "      tf.keras.layers.Dense(Y.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 22s - loss: 0.1728 - accuracy: 0.9499 - val_loss: 0.0947 - val_accuracy: 0.9748 - 22s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 21s - loss: 0.1002 - accuracy: 0.9733 - val_loss: 0.0837 - val_accuracy: 0.9779 - 21s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 22s - loss: 0.0899 - accuracy: 0.9761 - val_loss: 0.0802 - val_accuracy: 0.9786 - 22s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 21s - loss: 0.0851 - accuracy: 0.9774 - val_loss: 0.0785 - val_accuracy: 0.9797 - 21s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 22s - loss: 0.0819 - accuracy: 0.9781 - val_loss: 0.0752 - val_accuracy: 0.9803 - 22s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 20s - loss: 0.0795 - accuracy: 0.9788 - val_loss: 0.0746 - val_accuracy: 0.9801 - 20s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 20s - loss: 0.0770 - accuracy: 0.9792 - val_loss: 0.0728 - val_accuracy: 0.9806 - 20s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 20s - loss: 0.0756 - accuracy: 0.9796 - val_loss: 0.0732 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 20s - loss: 0.0746 - accuracy: 0.9797 - val_loss: 0.0702 - val_accuracy: 0.9805 - 20s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 23s - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.0695 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 23s - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.0690 - val_accuracy: 0.9811 - 23s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 22s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0688 - val_accuracy: 0.9817 - 22s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 20s - loss: 0.0706 - accuracy: 0.9807 - val_loss: 0.0695 - val_accuracy: 0.9815 - 20s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 21s - loss: 0.0700 - accuracy: 0.9809 - val_loss: 0.0691 - val_accuracy: 0.9814 - 21s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 21s - loss: 0.0693 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9815 - 21s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 21s - loss: 0.0691 - accuracy: 0.9811 - val_loss: 0.0673 - val_accuracy: 0.9816 - 21s/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 21s - loss: 0.0681 - accuracy: 0.9814 - val_loss: 0.0658 - val_accuracy: 0.9823 - 21s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 20s - loss: 0.0678 - accuracy: 0.9816 - val_loss: 0.0662 - val_accuracy: 0.9822 - 20s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 20s - loss: 0.0671 - accuracy: 0.9814 - val_loss: 0.0654 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 22s - loss: 0.0666 - accuracy: 0.9817 - val_loss: 0.0672 - val_accuracy: 0.9822 - 22s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 23s - loss: 0.0665 - accuracy: 0.9818 - val_loss: 0.0656 - val_accuracy: 0.9825 - 23s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 24s - loss: 0.0656 - accuracy: 0.9820 - val_loss: 0.0659 - val_accuracy: 0.9821 - 24s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 20s - loss: 0.0657 - accuracy: 0.9820 - val_loss: 0.0681 - val_accuracy: 0.9816 - 20s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 20s - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0655 - val_accuracy: 0.9824 - 20s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 20s - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.0658 - val_accuracy: 0.9820 - 20s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 23s - loss: 0.0649 - accuracy: 0.9823 - val_loss: 0.0668 - val_accuracy: 0.9824 - 23s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "1704/1704 - 24s - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0657 - val_accuracy: 0.9824 - 24s/epoch - 14ms/step\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_3.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_3 = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=8, verbose=2, mode='auto',restore_best_weights=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "history_3  = model_3.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_3],verbose=2, batch_size=512, epochs=100)\n",
    "model_3.save(colab_model_write_path + 'model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4b'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_4d'),\n",
    "      tf.keras.layers.Dense(y_train.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 9s - loss: 0.2432 - accuracy: 0.9265 - val_loss: 0.1163 - val_accuracy: 0.9687 - 9s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 9s - loss: 0.1272 - accuracy: 0.9651 - val_loss: 0.0988 - val_accuracy: 0.9741 - 9s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 8s - loss: 0.1102 - accuracy: 0.9701 - val_loss: 0.0887 - val_accuracy: 0.9766 - 8s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.1018 - accuracy: 0.9725 - val_loss: 0.0856 - val_accuracy: 0.9776 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 8s - loss: 0.0972 - accuracy: 0.9740 - val_loss: 0.0831 - val_accuracy: 0.9785 - 8s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 8s - loss: 0.0933 - accuracy: 0.9749 - val_loss: 0.0786 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 9s - loss: 0.0907 - accuracy: 0.9756 - val_loss: 0.0774 - val_accuracy: 0.9796 - 9s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 12s - loss: 0.0891 - accuracy: 0.9760 - val_loss: 0.0768 - val_accuracy: 0.9797 - 12s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 9s - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.0757 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 9s - loss: 0.0864 - accuracy: 0.9767 - val_loss: 0.0760 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 9s - loss: 0.0852 - accuracy: 0.9770 - val_loss: 0.0734 - val_accuracy: 0.9800 - 9s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 9s - loss: 0.0844 - accuracy: 0.9772 - val_loss: 0.0743 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0835 - accuracy: 0.9775 - val_loss: 0.0741 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 8s - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.0733 - val_accuracy: 0.9804 - 8s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 0.0823 - accuracy: 0.9777 - val_loss: 0.0718 - val_accuracy: 0.9806 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 8s - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.0718 - val_accuracy: 0.9809 - 8s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.0713 - val_accuracy: 0.9807 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 13s - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.0714 - val_accuracy: 0.9806 - 13s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 0.0801 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9809 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 8s - loss: 0.0798 - accuracy: 0.9783 - val_loss: 0.0704 - val_accuracy: 0.9812 - 8s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 10s - loss: 0.0792 - accuracy: 0.9785 - val_loss: 0.0699 - val_accuracy: 0.9811 - 10s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 9s - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.0700 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 0.0787 - accuracy: 0.9786 - val_loss: 0.0703 - val_accuracy: 0.9810 - 9s/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 9s - loss: 0.0783 - accuracy: 0.9787 - val_loss: 0.0690 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 0.0780 - accuracy: 0.9788 - val_loss: 0.0692 - val_accuracy: 0.9815 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 8s - loss: 0.0775 - accuracy: 0.9789 - val_loss: 0.0683 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 8s - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9817 - 8s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.0688 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 14s - loss: 0.0768 - accuracy: 0.9791 - val_loss: 0.0693 - val_accuracy: 0.9812 - 14s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 8s - loss: 0.0768 - accuracy: 0.9790 - val_loss: 0.0677 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 0.0766 - accuracy: 0.9792 - val_loss: 0.0681 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 8s - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.0674 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 0.0757 - accuracy: 0.9794 - val_loss: 0.0677 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 0.0759 - accuracy: 0.9793 - val_loss: 0.0673 - val_accuracy: 0.9816 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 8s - loss: 0.0758 - accuracy: 0.9793 - val_loss: 0.0682 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 11s - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.0680 - val_accuracy: 0.9814 - 11s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 0.0753 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 0.0751 - accuracy: 0.9795 - val_loss: 0.0670 - val_accuracy: 0.9819 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0678 - val_accuracy: 0.9816 - 11s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 11s - loss: 0.0750 - accuracy: 0.9794 - val_loss: 0.0675 - val_accuracy: 0.9821 - 11s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 11s - loss: 0.0747 - accuracy: 0.9796 - val_loss: 0.0672 - val_accuracy: 0.9818 - 11s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0672 - val_accuracy: 0.9817 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 0.0741 - accuracy: 0.9798 - val_loss: 0.0660 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 8s - loss: 0.0742 - accuracy: 0.9798 - val_loss: 0.0667 - val_accuracy: 0.9822 - 8s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 13s - loss: 0.0741 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9824 - 13s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.0658 - val_accuracy: 0.9824 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 9s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0659 - val_accuracy: 0.9819 - 9s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 8s - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0661 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 8s - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.0661 - val_accuracy: 0.9820 - 8s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 0.0736 - accuracy: 0.9798 - val_loss: 0.0655 - val_accuracy: 0.9822 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 9s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0653 - val_accuracy: 0.9823 - 9s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 0.0730 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0667 - val_accuracy: 0.9821 - 8s/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.0650 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 11s - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.0650 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 8s - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0655 - val_accuracy: 0.9825 - 8s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 8s - loss: 0.0723 - accuracy: 0.9803 - val_loss: 0.0653 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 9s - loss: 0.0726 - accuracy: 0.9802 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 11s - loss: 0.0725 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9826 - 11s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 9s - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9824 - 9s/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 8s - loss: 0.0728 - accuracy: 0.9803 - val_loss: 0.0648 - val_accuracy: 0.9823 - 8s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 8s - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0645 - val_accuracy: 0.9826 - 8s/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 9s - loss: 0.0721 - accuracy: 0.9804 - val_loss: 0.0643 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 0.0720 - accuracy: 0.9805 - val_loss: 0.0647 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 9s - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.0649 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 0.0716 - accuracy: 0.9804 - val_loss: 0.0653 - val_accuracy: 0.9823 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 11s - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9829 - 11s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 8s - loss: 0.0715 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 0.0715 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9828 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0643 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 8s - loss: 0.0714 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 8s/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 9s - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0651 - val_accuracy: 0.9825 - 9s/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 13s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0648 - val_accuracy: 0.9826 - 13s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 11s - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0643 - val_accuracy: 0.9827 - 11s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9808 - val_loss: 0.0643 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 10s - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0642 - val_accuracy: 0.9827 - 10s/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 8s - loss: 0.0710 - accuracy: 0.9806 - val_loss: 0.0645 - val_accuracy: 0.9828 - 8s/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.0639 - val_accuracy: 0.9830 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9806 - val_loss: 0.0642 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 0.0709 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0637 - val_accuracy: 0.9829 - 8s/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9807 - val_loss: 0.0638 - val_accuracy: 0.9830 - 8s/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 8s - loss: 0.0707 - accuracy: 0.9809 - val_loss: 0.0641 - val_accuracy: 0.9824 - 8s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 11s - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9831 - 11s/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.0640 - val_accuracy: 0.9827 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.0633 - val_accuracy: 0.9831 - 10s/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 8s - loss: 0.0702 - accuracy: 0.9809 - val_loss: 0.0627 - val_accuracy: 0.9832 - 8s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9829 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 0.0701 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9828 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 0.0706 - accuracy: 0.9810 - val_loss: 0.0639 - val_accuracy: 0.9826 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 13s - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0632 - val_accuracy: 0.9831 - 13s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 10s - loss: 0.0705 - accuracy: 0.9809 - val_loss: 0.0629 - val_accuracy: 0.9832 - 10s/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 8s - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.0634 - val_accuracy: 0.9831 - 8s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 9s - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.0634 - val_accuracy: 0.9831 - 9s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_4 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_4 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_4, histogram_freq=1)\n",
    "        ]\n",
    "history_4  = model_4.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor_4],verbose=2, batch_size=512, epochs=100)\n",
    "model_4.save(colab_model_write_path + 'model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "model_5 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5a'),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5b'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5c'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(64, input_dim=x_train.shape[1], kernel_initializer=initializer, activation='relu',name='dense_5d'),\n",
    "      tf.keras.layers.Dense(y_train_enforce.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1704/1704 - 11s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9993 - 11s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "1704/1704 - 10s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "1704/1704 - 9s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "1704/1704 - 9s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1704/1704 - 9s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1704/1704 - 10s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "1704/1704 - 9s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "1704/1704 - 10s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "1704/1704 - 10s - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "1704/1704 - 9s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1704/1704 - 10s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "1704/1704 - 9s - loss: 9.8441e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1704/1704 - 10s - loss: 9.3665e-04 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "1704/1704 - 9s - loss: 9.2064e-04 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1704/1704 - 9s - loss: 9.3356e-04 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1704/1704 - 9s - loss: 8.7414e-04 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1704/1704 - 10s - loss: 8.5468e-04 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "1704/1704 - 9s - loss: 8.3748e-04 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "1704/1704 - 10s - loss: 8.6668e-04 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "1704/1704 - 9s - loss: 7.5136e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "1704/1704 - 10s - loss: 8.0980e-04 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "1704/1704 - 9s - loss: 7.3481e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1704/1704 - 9s - loss: 6.9155e-04 - accuracy: 0.9998 - val_loss: 0.0045 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "1704/1704 - 9s - loss: 7.2576e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1704/1704 - 9s - loss: 6.4573e-04 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1704/1704 - 10s - loss: 7.3001e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "1704/1704 - 10s - loss: 6.0983e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "1704/1704 - 9s - loss: 6.4264e-04 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1704/1704 - 9s - loss: 6.1619e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1704/1704 - 9s - loss: 6.2433e-04 - accuracy: 0.9998 - val_loss: 0.0053 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "1704/1704 - 9s - loss: 6.3250e-04 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1704/1704 - 10s - loss: 5.6048e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "1704/1704 - 9s - loss: 5.4817e-04 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "1704/1704 - 9s - loss: 5.1804e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "1704/1704 - 9s - loss: 5.7661e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1704/1704 - 9s - loss: 5.4797e-04 - accuracy: 0.9999 - val_loss: 0.0085 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "1704/1704 - 9s - loss: 4.9753e-04 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "1704/1704 - 9s - loss: 5.4127e-04 - accuracy: 0.9999 - val_loss: 0.0097 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "1704/1704 - 10s - loss: 5.1966e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "1704/1704 - 9s - loss: 4.7119e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1704/1704 - 9s - loss: 5.0597e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1704/1704 - 10s - loss: 5.3273e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "1704/1704 - 10s - loss: 5.2568e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "1704/1704 - 10s - loss: 4.7804e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "1704/1704 - 10s - loss: 4.1050e-04 - accuracy: 0.9999 - val_loss: 0.0120 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "1704/1704 - 9s - loss: 4.3036e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1704/1704 - 9s - loss: 4.2457e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "1704/1704 - 9s - loss: 5.9950e-04 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1704/1704 - 10s - loss: 4.3468e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "1704/1704 - 9s - loss: 3.7293e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1704/1704 - 10s - loss: 4.0470e-04 - accuracy: 0.9999 - val_loss: 0.0087 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "1704/1704 - 9s - loss: 4.1268e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "1704/1704 - 9s - loss: 4.2829e-04 - accuracy: 0.9999 - val_loss: 0.0092 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "1704/1704 - 10s - loss: 3.5180e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "1704/1704 - 10s - loss: 3.9473e-04 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "1704/1704 - 10s - loss: 4.5839e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "1704/1704 - 10s - loss: 3.0135e-04 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "1704/1704 - 10s - loss: 4.2675e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "1704/1704 - 9s - loss: 3.2920e-04 - accuracy: 0.9999 - val_loss: 0.0233 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1704/1704 - 10s - loss: 5.3860e-04 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "1704/1704 - 10s - loss: 3.5807e-04 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "1704/1704 - 9s - loss: 3.6816e-04 - accuracy: 0.9999 - val_loss: 0.0187 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1704/1704 - 10s - loss: 4.3158e-04 - accuracy: 0.9999 - val_loss: 0.0179 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "1704/1704 - 10s - loss: 3.8634e-04 - accuracy: 0.9999 - val_loss: 0.0275 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "1704/1704 - 10s - loss: 4.6297e-04 - accuracy: 0.9999 - val_loss: 0.0335 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "1704/1704 - 10s - loss: 3.7752e-04 - accuracy: 0.9999 - val_loss: 0.0201 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "1704/1704 - 9s - loss: 4.2812e-04 - accuracy: 0.9999 - val_loss: 0.0134 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1704/1704 - 10s - loss: 3.7992e-04 - accuracy: 0.9999 - val_loss: 0.0262 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "1704/1704 - 9s - loss: 3.3662e-04 - accuracy: 0.9999 - val_loss: 0.0195 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "1704/1704 - 10s - loss: 3.5111e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "1704/1704 - 9s - loss: 3.5474e-04 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1704/1704 - 10s - loss: 3.6096e-04 - accuracy: 0.9999 - val_loss: 0.0129 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "1704/1704 - 10s - loss: 5.7303e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "1704/1704 - 9s - loss: 3.3251e-04 - accuracy: 0.9999 - val_loss: 0.0193 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1704/1704 - 9s - loss: 3.9361e-04 - accuracy: 0.9999 - val_loss: 0.0203 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "1704/1704 - 10s - loss: 3.1856e-04 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "1704/1704 - 10s - loss: 3.0138e-04 - accuracy: 0.9999 - val_loss: 0.0224 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "1704/1704 - 9s - loss: 4.1926e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1704/1704 - 14s - loss: 4.1826e-04 - accuracy: 0.9999 - val_loss: 0.0204 - val_accuracy: 0.9994 - 14s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1704/1704 - 9s - loss: 2.9279e-04 - accuracy: 0.9999 - val_loss: 0.0170 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1704/1704 - 9s - loss: 3.0474e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9994 - 9s/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "1704/1704 - 10s - loss: 3.6375e-04 - accuracy: 0.9999 - val_loss: 0.0261 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1704/1704 - 10s - loss: 3.9308e-04 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9992 - 10s/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "1704/1704 - 9s - loss: 3.3599e-04 - accuracy: 0.9999 - val_loss: 0.0535 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1704/1704 - 10s - loss: 4.3944e-04 - accuracy: 0.9999 - val_loss: 0.0341 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "1704/1704 - 9s - loss: 3.3641e-04 - accuracy: 0.9999 - val_loss: 0.0285 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1704/1704 - 9s - loss: 3.7667e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1704/1704 - 9s - loss: 3.3478e-04 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1704/1704 - 11s - loss: 3.2279e-04 - accuracy: 0.9999 - val_loss: 0.0254 - val_accuracy: 0.9994 - 11s/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "1704/1704 - 9s - loss: 3.8158e-04 - accuracy: 0.9999 - val_loss: 0.0329 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1704/1704 - 10s - loss: 2.9903e-04 - accuracy: 0.9999 - val_loss: 0.0514 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "1704/1704 - 10s - loss: 3.4784e-04 - accuracy: 0.9999 - val_loss: 0.0336 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "1704/1704 - 10s - loss: 3.5308e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9993 - 10s/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "1704/1704 - 9s - loss: 3.3192e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1704/1704 - 9s - loss: 4.5388e-04 - accuracy: 0.9999 - val_loss: 0.0309 - val_accuracy: 0.9993 - 9s/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "1704/1704 - 9s - loss: 6.0361e-04 - accuracy: 0.9999 - val_loss: 0.0196 - val_accuracy: 0.9994 - 9s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1704/1704 - 10s - loss: 3.1968e-04 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9994 - 10s/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_5 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_5 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_5, histogram_freq=1)\n",
    "        ]\n",
    "history_5  = model_5.fit(x_train,y_train_enforce,validation_data=(x_test,y_test_enforce), callbacks=[monitor_5],verbose=2, batch_size=512, epochs=100)\n",
    "model_5.save(colab_model_write_path + 'model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(colab_model_write_path + 'model1_1.h5')\n",
    "model_2.save(colab_model_write_path + 'model1_2.h5')\n",
    "model_3.save(colab_model_write_path + 'model1_3.h5')\n",
    "model_4.save(colab_model_write_path + 'model1_4.h5')\n",
    "model_5.save(colab_model_write_path + 'model1_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model 6 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# #type(y_train)\n",
    "# ydp= pd.DataFrame(y_train)\n",
    "# ydp = tf.argmax(ydp, axis=1)\n",
    "# #ydp = pd.DataFrame(ydp)\n",
    "# #ydp.value_counts\n",
    "# dicts = Counter(ydp.numpy())\n",
    "# dicts\n",
    "\n",
    "# MININUM_SAMPLES = 30000\n",
    "# MAXINUM_SAMPLES = 300000\n",
    "\n",
    "# sample_dict = {2: 793860,\n",
    "#          19: 119826,\n",
    "#          6: 564661,\n",
    "#          15: 21588,\n",
    "#          20: 77352,\n",
    "#          5: 687703,\n",
    "#          4: 3987,\n",
    "#          11: 82959,\n",
    "#          17: 36318,\n",
    "#          10: 3759,\n",
    "#          7: 999,\n",
    "#          9: 562,\n",
    "#          3: 4605,\n",
    "#          16: 233,\n",
    "#          1: 592,\n",
    "#          8: 710,\n",
    "#          13: 71,\n",
    "#          18: 92,\n",
    "#          0: 74,\n",
    "#          12: 45,\n",
    "#          14: 4}\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# #ros = RandomOverSampler(random_state=33)\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "#     sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  MININUM_SAMPLES:\n",
    "#     sample_dict[i] =  MININUM_SAMPLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 30000,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 30000,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 30000,\n",
       " 7: 30000,\n",
       " 9: 30000,\n",
       " 3: 30000,\n",
       " 16: 30000,\n",
       " 1: 30000,\n",
       " 8: 30000,\n",
       " 13: 30000,\n",
       " 18: 30000,\n",
       " 0: 30000,\n",
       " 12: 30000,\n",
       " 14: 30000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "# sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 300000,\n",
       " 19: 119826,\n",
       " 6: 300000,\n",
       " 15: 21588,\n",
       " 20: 77352,\n",
       " 5: 300000,\n",
       " 4: 3987,\n",
       " 11: 82959,\n",
       " 17: 36318,\n",
       " 10: 3759,\n",
       " 7: 999,\n",
       " 9: 562,\n",
       " 3: 4605,\n",
       " 16: 233,\n",
       " 1: 592,\n",
       " 8: 710,\n",
       " 13: 71,\n",
       " 18: 92,\n",
       " 0: 74,\n",
       " 12: 45,\n",
       " 14: 4}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 205290,\n",
       "         2: 288786,\n",
       "         5: 249311,\n",
       "         20: 28278,\n",
       "         19: 43885,\n",
       "         11: 29889,\n",
       "         17: 13051,\n",
       "         3: 1639,\n",
       "         15: 7863,\n",
       "         4: 1436,\n",
       "         10: 1354,\n",
       "         8: 256,\n",
       "         9: 185,\n",
       "         7: 373,\n",
       "         18: 31,\n",
       "         1: 214,\n",
       "         13: 17,\n",
       "         16: 86,\n",
       "         0: 38,\n",
       "         12: 13,\n",
       "         14: 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#type(y_train)\n",
    "ydp= pd.DataFrame(y_train)\n",
    "ydp = tf.argmax(ydp, axis=1)\n",
    "#ydp = pd.DataFrame(ydp)\n",
    "#ydp.value_counts\n",
    "dicts = Counter(ydp.numpy())\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (871999, 127) (871999, 21)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (555103, 127) (555103, 21)\n"
     ]
    }
   ],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_over,y_train_over = smote.fit_resample(x_train,y_train)\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "MININUM_SAMPLES = 10000\n",
    "MAXINUM_SAMPLES = 100000\n",
    "\n",
    "# sample_dict = {5: 687357,\n",
    "#          2: 794288,\n",
    "#          19: 119905,\n",
    "#          15: 21686,\n",
    "#          6: 564557,\n",
    "#          4: 4025,\n",
    "#          11: 82731,\n",
    "#          20: 77617,\n",
    "#          17: 36205,\n",
    "#          3: 4569,\n",
    "#          10: 3752,\n",
    "#          9: 542,\n",
    "#          7: 968,\n",
    "#          8: 694,\n",
    "#          1: 575,\n",
    "#          16: 239,\n",
    "#          0: 81,\n",
    "#          18: 94,\n",
    "#          13: 69,\n",
    "#          12: 42,\n",
    "#          14: 4}\n",
    "\n",
    "sample_dict = {6: 205290,\n",
    "         2: 288786,\n",
    "         5: 249311,\n",
    "         20: 28278,\n",
    "         19: 43885,\n",
    "         11: 29889,\n",
    "         17: 13051,\n",
    "         3: 1639,\n",
    "         15: 7863,\n",
    "         4: 1436,\n",
    "         10: 1354,\n",
    "         8: 256,\n",
    "         9: 185,\n",
    "         7: 373,\n",
    "         18: 31,\n",
    "         1: 214,\n",
    "         13: 17,\n",
    "         16: 86,\n",
    "         0: 38,\n",
    "         12: 13,\n",
    "         14: 4}\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=33)\n",
    "for i in range(21):\n",
    "  if sample_dict[i] >  MAXINUM_SAMPLES:\n",
    "    sample_dict[i] =  MAXINUM_SAMPLES\n",
    "\n",
    "ros = RandomUnderSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_under, y_train_under = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "# for i in range(21):\n",
    "#   if sample_dict[i] <  16:\n",
    "#     sample_dict[i] =  16\n",
    "\n",
    "# ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "for i in range(21):\n",
    "  if sample_dict[i] <  MININUM_SAMPLES:\n",
    "    sample_dict[i] =  MININUM_SAMPLES\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = sample_dict, random_state=33)\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train_under, y_train_under)\n",
    "\n",
    "# sm = SMOTE(sampling_strategy = sample_dict, random_state=33)\n",
    "# X_train_over, y_train_over = sm.fit_resample(X_train_over, y_train_over)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 rd model for stack\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=33)\n",
    "constraints = None\n",
    "\n",
    "#6 rd model for stack\n",
    "model_6 = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6a'),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6b'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6c'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(64, input_dim=X_train_over.shape[1], kernel_initializer=initializer, activation='relu',name='dense_6d'),\n",
    "      tf.keras.layers.Dense(y_train_over.shape[1],activation='softmax')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1085/1085 - 10s - loss: 0.4190 - accuracy: 0.8622 - val_loss: 0.1915 - val_accuracy: 0.9446 - 10s/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "1085/1085 - 8s - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1437 - val_accuracy: 0.9617 - 8s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "1085/1085 - 8s - loss: 0.1844 - accuracy: 0.9437 - val_loss: 0.1276 - val_accuracy: 0.9676 - 8s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "1085/1085 - 9s - loss: 0.1657 - accuracy: 0.9494 - val_loss: 0.1276 - val_accuracy: 0.9701 - 9s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "1085/1085 - 9s - loss: 0.1553 - accuracy: 0.9531 - val_loss: 0.1107 - val_accuracy: 0.9716 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1085/1085 - 8s - loss: 0.1465 - accuracy: 0.9555 - val_loss: 0.1217 - val_accuracy: 0.9720 - 8s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "1085/1085 - 9s - loss: 0.1415 - accuracy: 0.9571 - val_loss: 0.1092 - val_accuracy: 0.9733 - 9s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "1085/1085 - 8s - loss: 0.1382 - accuracy: 0.9581 - val_loss: 0.1119 - val_accuracy: 0.9725 - 8s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "1085/1085 - 8s - loss: 0.1342 - accuracy: 0.9590 - val_loss: 0.1153 - val_accuracy: 0.9727 - 8s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "1085/1085 - 8s - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1051 - val_accuracy: 0.9747 - 8s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1085/1085 - 8s - loss: 0.1297 - accuracy: 0.9604 - val_loss: 0.1044 - val_accuracy: 0.9743 - 8s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "1085/1085 - 9s - loss: 0.1272 - accuracy: 0.9611 - val_loss: 0.1036 - val_accuracy: 0.9743 - 9s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1085/1085 - 10s - loss: 0.1258 - accuracy: 0.9614 - val_loss: 0.1045 - val_accuracy: 0.9742 - 10s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1085/1085 - 9s - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1062 - val_accuracy: 0.9747 - 9s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "1085/1085 - 9s - loss: 0.1230 - accuracy: 0.9623 - val_loss: 0.1045 - val_accuracy: 0.9750 - 9s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1085/1085 - 8s - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.1155 - val_accuracy: 0.9726 - 8s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "1085/1085 - 9s - loss: 0.1202 - accuracy: 0.9631 - val_loss: 0.1079 - val_accuracy: 0.9754 - 9s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1085/1085 - 8s - loss: 0.1196 - accuracy: 0.9632 - val_loss: 0.1032 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "1085/1085 - 11s - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1034 - val_accuracy: 0.9751 - 11s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "1085/1085 - 8s - loss: 0.1176 - accuracy: 0.9637 - val_loss: 0.0993 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "1085/1085 - 8s - loss: 0.1171 - accuracy: 0.9639 - val_loss: 0.0999 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "1085/1085 - 8s - loss: 0.1156 - accuracy: 0.9641 - val_loss: 0.1006 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "1085/1085 - 8s - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.0978 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "1085/1085 - 8s - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.0991 - val_accuracy: 0.9761 - 8s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "1085/1085 - 8s - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.1017 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "1085/1085 - 7s - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.0966 - val_accuracy: 0.9766 - 7s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "1085/1085 - 8s - loss: 0.1114 - accuracy: 0.9652 - val_loss: 0.1054 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "1085/1085 - 8s - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1019 - val_accuracy: 0.9755 - 8s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "1085/1085 - 9s - loss: 0.1110 - accuracy: 0.9654 - val_loss: 0.0986 - val_accuracy: 0.9765 - 9s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1085/1085 - 9s - loss: 0.1107 - accuracy: 0.9656 - val_loss: 0.0987 - val_accuracy: 0.9749 - 9s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "1085/1085 - 8s - loss: 0.1094 - accuracy: 0.9659 - val_loss: 0.1004 - val_accuracy: 0.9746 - 8s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9659 - val_loss: 0.0910 - val_accuracy: 0.9766 - 8s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1085/1085 - 9s - loss: 0.1089 - accuracy: 0.9661 - val_loss: 0.0982 - val_accuracy: 0.9767 - 9s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "1085/1085 - 8s - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.1018 - val_accuracy: 0.9751 - 8s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "1085/1085 - 8s - loss: 0.1082 - accuracy: 0.9659 - val_loss: 0.0920 - val_accuracy: 0.9768 - 8s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "1085/1085 - 8s - loss: 0.1074 - accuracy: 0.9662 - val_loss: 0.0954 - val_accuracy: 0.9770 - 8s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1085/1085 - 7s - loss: 0.1064 - accuracy: 0.9668 - val_loss: 0.0957 - val_accuracy: 0.9769 - 7s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "1085/1085 - 7s - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.0974 - val_accuracy: 0.9765 - 7s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "1085/1085 - 8s - loss: 0.1063 - accuracy: 0.9666 - val_loss: 0.0905 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "1085/1085 - 8s - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.0969 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "1085/1085 - 8s - loss: 0.1051 - accuracy: 0.9670 - val_loss: 0.0943 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "1085/1085 - 9s - loss: 0.1052 - accuracy: 0.9668 - val_loss: 0.0956 - val_accuracy: 0.9770 - 9s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1085/1085 - 8s - loss: 0.1046 - accuracy: 0.9673 - val_loss: 0.1010 - val_accuracy: 0.9747 - 8s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "1085/1085 - 9s - loss: 0.1045 - accuracy: 0.9672 - val_loss: 0.0937 - val_accuracy: 0.9766 - 9s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "1085/1085 - 8s - loss: 0.1038 - accuracy: 0.9674 - val_loss: 0.0895 - val_accuracy: 0.9771 - 8s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1085/1085 - 8s - loss: 0.1039 - accuracy: 0.9675 - val_loss: 0.0934 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9674 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "1085/1085 - 8s - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.0939 - val_accuracy: 0.9762 - 8s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "1085/1085 - 8s - loss: 0.1027 - accuracy: 0.9676 - val_loss: 0.0912 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "1085/1085 - 8s - loss: 0.1024 - accuracy: 0.9679 - val_loss: 0.0930 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "1085/1085 - 9s - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.0929 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "1085/1085 - 8s - loss: 0.1022 - accuracy: 0.9678 - val_loss: 0.0942 - val_accuracy: 0.9761 - 8s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1085/1085 - 9s - loss: 0.1019 - accuracy: 0.9679 - val_loss: 0.0939 - val_accuracy: 0.9761 - 9s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1085/1085 - 8s - loss: 0.1014 - accuracy: 0.9681 - val_loss: 0.0909 - val_accuracy: 0.9762 - 8s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "1085/1085 - 7s - loss: 0.1016 - accuracy: 0.9679 - val_loss: 0.0947 - val_accuracy: 0.9756 - 7s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9682 - val_loss: 0.0896 - val_accuracy: 0.9771 - 8s/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "1085/1085 - 8s - loss: 0.1000 - accuracy: 0.9683 - val_loss: 0.0886 - val_accuracy: 0.9772 - 8s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "1085/1085 - 8s - loss: 0.1005 - accuracy: 0.9683 - val_loss: 0.0883 - val_accuracy: 0.9768 - 8s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1085/1085 - 8s - loss: 0.0998 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "1085/1085 - 8s - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.0933 - val_accuracy: 0.9764 - 8s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "1085/1085 - 8s - loss: 0.0997 - accuracy: 0.9685 - val_loss: 0.0921 - val_accuracy: 0.9758 - 8s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1085/1085 - 8s - loss: 0.0987 - accuracy: 0.9687 - val_loss: 0.0840 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "1085/1085 - 8s - loss: 0.0992 - accuracy: 0.9687 - val_loss: 0.0926 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "1085/1085 - 8s - loss: 0.0984 - accuracy: 0.9689 - val_loss: 0.0934 - val_accuracy: 0.9742 - 8s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9779 - 8s/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "1085/1085 - 8s - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.0879 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0921 - val_accuracy: 0.9759 - 8s/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "1085/1085 - 8s - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.0925 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0913 - val_accuracy: 0.9773 - 8s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1085/1085 - 8s - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.0864 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "1085/1085 - 8s - loss: 0.0974 - accuracy: 0.9690 - val_loss: 0.0918 - val_accuracy: 0.9766 - 8s/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "1085/1085 - 8s - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9765 - 8s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9692 - val_loss: 0.0850 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "1085/1085 - 9s - loss: 0.0969 - accuracy: 0.9694 - val_loss: 0.0883 - val_accuracy: 0.9782 - 9s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1085/1085 - 8s - loss: 0.0961 - accuracy: 0.9694 - val_loss: 0.0846 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "1085/1085 - 8s - loss: 0.0964 - accuracy: 0.9695 - val_loss: 0.0855 - val_accuracy: 0.9778 - 8s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "1085/1085 - 8s - loss: 0.0962 - accuracy: 0.9696 - val_loss: 0.0915 - val_accuracy: 0.9756 - 8s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "1085/1085 - 8s - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.0859 - val_accuracy: 0.9782 - 8s/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "1085/1085 - 10s - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.0877 - val_accuracy: 0.9776 - 10s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "1085/1085 - 8s - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.0887 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "1085/1085 - 8s - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.0872 - val_accuracy: 0.9769 - 8s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9701 - val_loss: 0.0898 - val_accuracy: 0.9777 - 8s/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "1085/1085 - 8s - loss: 0.0950 - accuracy: 0.9696 - val_loss: 0.0867 - val_accuracy: 0.9775 - 8s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.0891 - val_accuracy: 0.9760 - 8s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9699 - val_loss: 0.0894 - val_accuracy: 0.9767 - 8s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "1085/1085 - 8s - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.0859 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "1085/1085 - 8s - loss: 0.0949 - accuracy: 0.9700 - val_loss: 0.0843 - val_accuracy: 0.9785 - 8s/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "1085/1085 - 8s - loss: 0.0945 - accuracy: 0.9701 - val_loss: 0.0845 - val_accuracy: 0.9786 - 8s/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "1085/1085 - 8s - loss: 0.0942 - accuracy: 0.9700 - val_loss: 0.0869 - val_accuracy: 0.9780 - 8s/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "1085/1085 - 9s - loss: 0.0937 - accuracy: 0.9703 - val_loss: 0.0865 - val_accuracy: 0.9768 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1085/1085 - 8s - loss: 0.0938 - accuracy: 0.9703 - val_loss: 0.0863 - val_accuracy: 0.9777 - 8s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0886 - val_accuracy: 0.9773 - 8s/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "1085/1085 - 8s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.0921 - val_accuracy: 0.9744 - 8s/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "1085/1085 - 8s - loss: 0.0932 - accuracy: 0.9704 - val_loss: 0.0864 - val_accuracy: 0.9770 - 8s/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "1085/1085 - 8s - loss: 0.0937 - accuracy: 0.9704 - val_loss: 0.0868 - val_accuracy: 0.9776 - 8s/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0839 - val_accuracy: 0.9781 - 8s/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "1085/1085 - 7s - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.0842 - val_accuracy: 0.9784 - 7s/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "1085/1085 - 8s - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0870 - val_accuracy: 0.9769 - 8s/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "1085/1085 - 7s - loss: 0.0926 - accuracy: 0.9706 - val_loss: 0.0887 - val_accuracy: 0.9749 - 7s/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "1085/1085 - 8s - loss: 0.0925 - accuracy: 0.9706 - val_loss: 0.0820 - val_accuracy: 0.9792 - 8s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "log_dir_6 = colab_write_path + \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_6 = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=100, verbose=1, mode='auto',restore_best_weights=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir_6, histogram_freq=1)\n",
    "        ]\n",
    "history_6  = model_6.fit(X_train_over,y_train_over,validation_data=(x_test,y_test), callbacks=[monitor_6],verbose=2, batch_size=512, epochs=100)\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_model_write_path\n",
    "model_6.save(colab_model_write_path + 'model1_6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "https://abstractask.tistory.com/105\n",
    "\n",
    "Model #1, Model #2, Model #3, + OverSampling/UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "# for both logistic and nueral\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "#\t\tcolab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "\t\t#model_4.save(colab_path + 'model4.h5')\n",
    "\t\tif i != 5 and i != 3: #Model4와 Binary 배제\n",
    "\t\t\tfilename = colab_model_write_path + 'model1_' + str(i + 1) + '.h5'\n",
    "\t\t\t# load model from file\n",
    "\t\t\tmodel = load_model(filename,custom_objects=None)\n",
    "\t\t\t# add to list of members\n",
    "\t\t\tall_models.append(model)\n",
    "\t\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "#neural\n",
    "\n",
    "def define_stacked_model(members):\n",
    "\tinitializer = tf.keras.initializers.GlorotUniform(seed=64)\n",
    "\tconstraints = None\n",
    "\n",
    "  # update all layers in all models to not be trainable\n",
    "\tfor i in range(len(members)):\n",
    "\t\tmodel = members[i]\n",
    "\t\tfor layer in model.layers:\n",
    "\t\t\t# make not trainable\n",
    "\t\t\tlayer.trainable = False\n",
    "\t\t\t# rename to avoid 'unique layer name' issue\n",
    "\t\t\tlayer._name = 'ensemble_' + str(i + 1) + '_' + layer.name\n",
    "\n",
    "\n",
    "\t# define multi-headed input\n",
    "\tensemble_visible = [model.input for model in members]\n",
    "\t# concatenate merge output from each model\n",
    "\tensemble_outputs = [model.output for model in members]\n",
    "\tmerge = concatenate(ensemble_outputs)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_ea\")(merge)\n",
    "\tmerge = Dense(128, kernel_initializer=initializer, activation='relu',name=\"dense_eb\")(merge)\n",
    "\toutput = Dense(Y.shape[1], kernel_initializer=initializer, activation='softmax',name=\"dense_ec\")(merge)\n",
    "\tmodel = Model(inputs=ensemble_visible, outputs=output)\n",
    "\t# plot graph of ensemble\n",
    "\tplot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "\t# compile\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "#neural\n",
    "import datetime\n",
    "\n",
    "\n",
    "#colab_path = \"gdrive/My Drive/Colab Notebooks/Network/models/\"\n",
    "log_dir = colab_write_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "monitor_7= [\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            ]\n",
    "\n",
    "def fit_stacked_model(model, inputX, inputy_enc):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# encode output data\n",
    "#\tinputy_enc = to_categorical(inputy)\n",
    "\t# fit model\n",
    "\thistory_7=model.fit(X, inputy_enc, epochs=7, verbose=2,callbacks=[monitor_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a stacked model\n",
    "#neural\n",
    "def predict_stacked_model(model, inputX):\n",
    "\t# prepare input data\n",
    "\tX = [inputX for _ in range(len(model.input))]\n",
    "\t# make prediction\n",
    "\treturn model.predict(X, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 18:14:23.696072: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded /home/marius1406/20231010221344/model1_1.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_2.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_3.h5\n",
      ">loaded /home/marius1406/20231010221344/model1_5.h5\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "#neural\n",
    "\n",
    "colab_model_write_path = colab_write_path + \"20231010221344/\"\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "n_members = 6\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_2a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_3a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_1a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2a (Dense)    (None, 64)           8192        ['dense_2a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3a (Dense)    (None, 512)          65536       ['dense_3a_input[0][0]']         \n",
      "                                                                                                  \n",
      " dense_5a_input (InputLayer)    [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1a (Dense)    (None, 64)           8192        ['dense_1a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2b (Dense)    (None, 128)          8320        ['ensemble_2_dense_2a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_11 (Dropout  (None, 512)         0           ['ensemble_3_dense_3a[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dense_5a (Dense)    (None, 256)          32768       ['dense_5a_input[0][0]']         \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1b (Dense)    (None, 128)          8320        ['ensemble_1_dense_1a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_8 (Dropout)  (None, 128)         0           ['ensemble_2_dense_2b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3b (Dense)    (None, 256)          131328      ['ensemble_3_dropout_11[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_5b (Dense)    (None, 128)          32896       ['ensemble_4_dense_5a[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_6 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1b[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2c (Dense)    (None, 256)          33024       ['ensemble_2_dropout_8[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_12 (Dropout  (None, 256)         0           ['ensemble_3_dense_3b[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_17 (Dropout  (None, 128)         0           ['ensemble_4_dense_5b[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1c (Dense)    (None, 128)          16512       ['ensemble_1_dropout_6[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_9 (Dropout)  (None, 256)         0           ['ensemble_2_dense_2c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3c (Dense)    (None, 128)          32896       ['ensemble_3_dropout_12[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_5c (Dense)    (None, 128)          16512       ['ensemble_4_dropout_17[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_1_dropout_7 (Dropout)  (None, 128)         0           ['ensemble_1_dense_1c[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_2d (Dense)    (None, 128)          32896       ['ensemble_2_dropout_9[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_3_dropout_13 (Dropout  (None, 128)         0           ['ensemble_3_dense_3c[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_4_dropout_18 (Dropout  (None, 128)         0           ['ensemble_4_dense_5c[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_1_dense_1d (Dense)    (None, 64)           8256        ['ensemble_1_dropout_7[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_2_dropout_10 (Dropout  (None, 128)         0           ['ensemble_2_dense_2d[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " ensemble_3_dense_3d (Dense)    (None, 128)          16512       ['ensemble_3_dropout_13[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_4_dense_5d (Dense)    (None, 64)           8256        ['ensemble_4_dropout_18[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_1_dense_2 (Dense)     (None, 21)           1365        ['ensemble_1_dense_1d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_2_dense_3 (Dense)     (None, 21)           2709        ['ensemble_2_dropout_10[0][0]']  \n",
      "                                                                                                  \n",
      " ensemble_3_dense_4 (Dense)     (None, 21)           2709        ['ensemble_3_dense_3d[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_4_dense_6 (Dense)     (None, 2)            130         ['ensemble_4_dense_5d[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 65)           0           ['ensemble_1_dense_2[0][0]',     \n",
      "                                                                  'ensemble_2_dense_3[0][0]',     \n",
      "                                                                  'ensemble_3_dense_4[0][0]',     \n",
      "                                                                  'ensemble_4_dense_6[0][0]']     \n",
      "                                                                                                  \n",
      " dense_ea (Dense)               (None, 128)          8448        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_eb (Dense)               (None, 128)          16512       ['dense_ea[0][0]']               \n",
      "                                                                                                  \n",
      " dense_ec (Dense)               (None, 21)           2709        ['dense_eb[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 494,998\n",
      "Trainable params: 27,669\n",
      "Non-trainable params: 467,329\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define ensemble model\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.utils import plot_model\n",
    "#neural\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "27250/27250 - 78s - loss: 0.0677 - accuracy: 0.9839 - 78s/epoch - 3ms/step\n",
      "Epoch 2/7\n",
      "27250/27250 - 79s - loss: 0.0610 - accuracy: 0.9845 - 79s/epoch - 3ms/step\n",
      "Epoch 3/7\n",
      "27250/27250 - 78s - loss: 0.0602 - accuracy: 0.9845 - 78s/epoch - 3ms/step\n",
      "Epoch 4/7\n",
      "27250/27250 - 78s - loss: 0.0596 - accuracy: 0.9846 - 78s/epoch - 3ms/step\n",
      "Epoch 5/7\n",
      "27250/27250 - 83s - loss: 0.0594 - accuracy: 0.9845 - 83s/epoch - 3ms/step\n",
      "Epoch 6/7\n",
      "27250/27250 - 80s - loss: 0.0591 - accuracy: 0.9846 - 80s/epoch - 3ms/step\n",
      "Epoch 7/7\n",
      "27250/27250 - 80s - loss: 0.0593 - accuracy: 0.9846 - 80s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "fit_stacked_model(stacked_model, x_train,y_train)\n",
    "stacked_model.save(colab_model_write_path + 'stacked_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 12s - 12s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.74      0.94      0.83        51\n",
      "           2       0.99      0.99      0.99     72091\n",
      "           3       1.00      1.00      1.00       433\n",
      "           4       1.00      0.97      0.98       365\n",
      "           5       0.99      0.99      0.99     62503\n",
      "           6       0.98      0.99      0.99     51385\n",
      "           7       0.52      0.63      0.57        78\n",
      "           8       0.45      0.27      0.34        67\n",
      "           9       0.78      0.74      0.76        62\n",
      "          10       0.97      0.19      0.31       349\n",
      "          11       0.98      0.94      0.96      7418\n",
      "          12       1.00      0.40      0.57         5\n",
      "          13       1.00      0.22      0.36         9\n",
      "          15       0.88      0.75      0.81      1989\n",
      "          16       0.44      0.24      0.31        17\n",
      "          17       0.91      0.92      0.92      3272\n",
      "          18       1.00      0.60      0.75        15\n",
      "          19       0.96      0.98      0.97     10833\n",
      "          20       0.94      0.97      0.95      7055\n",
      "\n",
      "    accuracy                           0.98    218000\n",
      "   macro avg       0.83      0.69      0.72    218000\n",
      "weighted avg       0.98      0.98      0.98    218000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00         3\\n           1       0.74      0.94      0.83        51\\n           2       0.99      0.99      0.99     72091\\n           3       1.00      1.00      1.00       433\\n           4       1.00      0.97      0.98       365\\n           5       0.99      0.99      0.99     62503\\n           6       0.98      0.99      0.99     51385\\n           7       0.52      0.63      0.57        78\\n           8       0.45      0.27      0.34        67\\n           9       0.78      0.74      0.76        62\\n          10       0.97      0.19      0.31       349\\n          11       0.98      0.94      0.96      7418\\n          12       1.00      0.40      0.57         5\\n          13       1.00      0.22      0.36         9\\n          15       0.88      0.75      0.81      1989\\n          16       0.44      0.24      0.31        17\\n          17       0.91      0.92      0.92      3272\\n          18       1.00      0.60      0.75        15\\n          19       0.96      0.98      0.97     10833\\n          20       0.94      0.97      0.95      7055\\n\\n    accuracy                           0.98    218000\\n   macro avg       0.83      0.69      0.72    218000\\nweighted avg       0.98      0.98      0.98    218000\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_1, yhat_val))\n",
    "classification_report(y_test_1, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813/6813 - 12s - 12s/epoch - 2ms/step\n",
      "Stacked Test Accuracy: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f63772b2510>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 predict 수행\n",
    "# 모델 성능 - confusion matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# make predictions and evaluate\n",
    "#neural\n",
    "yhat = predict_stacked_model(stacked_model, x_test_1)\n",
    "yhat_val = tf.argmax(yhat, axis=1)\n",
    "acc = accuracy_score(y_test_1, yhat_val)\n",
    "print('Stacked Test Accuracy: %.4f' % acc)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test_1, y_pred=yhat_val)\n",
    "conf_mat\n",
    "\n",
    "disp = ConfusionMatrixDisplay(conf_mat)\n",
    "#disp = ConfusionMatrixDisplay(conf_mat)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
